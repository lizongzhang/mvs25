[
  {
    "objectID": "chap6slide.html",
    "href": "chap6slide.html",
    "title": "Chapter 6 主成分分析",
    "section": "",
    "text": "注意：本讲义供学习交流使用，请勿用于商业用途"
  },
  {
    "objectID": "Rintro.html#大纲",
    "href": "Rintro.html#大纲",
    "title": "R快速入门",
    "section": "大纲",
    "text": "大纲\n\n1.1 R主界面\n1.2 安装包\n1.3 项目的创建与管理\n1.4 R代码学习方法建议\n1.5 常用R代码"
  },
  {
    "objectID": "Rintro.html#rstudio的界面",
    "href": "Rintro.html#rstudio的界面",
    "title": "R快速入门",
    "section": "1.1 RStudio的界面",
    "text": "1.1 RStudio的界面"
  },
  {
    "objectID": "Rintro.html#安装包",
    "href": "Rintro.html#安装包",
    "title": "R快速入门",
    "section": "1.2 安装包",
    "text": "1.2 安装包\n\ntidyverse\n\n一系列用于数据导入、清洗、转换、可视化与建模的 R 包"
  },
  {
    "objectID": "Rintro.html#项目的创建与管理",
    "href": "Rintro.html#项目的创建与管理",
    "title": "R快速入门",
    "section": "1.3 项目的创建与管理",
    "text": "1.3 项目的创建与管理\n\n创建项目的好处\n\n项目创建后，所有相对路径都以项目文件夹为根目录\n不再需要使用 setwd() 指定工作目录，减少路径错误\n便于协作与再现\n团队成员只需克隆项目文件夹，即可重现整个分析过程"
  },
  {
    "objectID": "Rintro.html#r代码学习方法建议",
    "href": "Rintro.html#r代码学习方法建议",
    "title": "R快速入门",
    "section": "1.4 R代码学习方法建议",
    "text": "1.4 R代码学习方法建议\n学习代码: 参数项(需要修改的/不需要改动的)\n录入代码\n查看函数帮助\nAI工具的使用"
  },
  {
    "objectID": "Rintro.html#r常用代码",
    "href": "Rintro.html#r常用代码",
    "title": "R快速入门",
    "section": "1.5 R常用代码",
    "text": "1.5 R常用代码"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "课程安排和考核",
    "section": "",
    "text": "Table 1: 课程时间表\n\n\n\n\n\n周\n日期\n安排\n\n\n\n\n第1周\n20250904\n第1章 课程介绍和R操作回顾\n\n\n第2周\n20250911\n第4章 聚类分析 I\n\n\n第3周\n20250918\n第4章 聚类分析 II\n\n\n第4周\n20250925\n第5章 判别分析 案例讨论I\n\n\n第5周\n20251002\n国庆放假\n\n\n第6周\n20251009\n第6章 主成分分析\n\n\n第7周\n20251015\n第4-6章 习题讲评 测验及讲评 (上机开卷)\n\n\n第8周\n20251023\n第7章 因子分析I 案例讨论II\n\n\n第9周\n20251030\n第8章 对应分析\n\n\n第10周\n20251106\n第9章 典型相关分析 案例讨论III\n\n\n第11周\n20251113\n复习答疑\n\n\n第12周\n20251120\n小组作业汇报\n\n\n\n\n\n\nSee Table 1."
  },
  {
    "objectID": "schedule.html#封面",
    "href": "schedule.html#封面",
    "title": "课程安排和考核",
    "section": "封面",
    "text": "封面\n题目 班级 学号 姓名"
  },
  {
    "objectID": "schedule.html#前言",
    "href": "schedule.html#前言",
    "title": "课程安排和考核",
    "section": "1 前言",
    "text": "1 前言\n研究背景、选题动机、研究目标、要研究的问题\n\n研究背景：简述研究对象的现实背景\n选题动机：结合个人经验、兴趣或课程要求说明为什么选择这个主题\n研究目标：具体化（识别群体、寻找主要因素、建立判别规则）\n研究问题：本研究要回答什么问题"
  },
  {
    "objectID": "schedule.html#数据概况",
    "href": "schedule.html#数据概况",
    "title": "课程安排和考核",
    "section": "2 数据概况",
    "text": "2 数据概况\n介绍数据来源、数据收集过程、解释变量的含义\n\n数据来源：说明数据的出处\n数据收集：解释数据是如何收集的，异常值、缺失值的处理等\n变量解释：变量的名称，含义，类型、单位、描述性统计量的报告。\n\n数据要求参见“小组作业”, 不可使用虚拟数据\n运用聚类/判别/主成分/因子/对应/典型相关分析方法，至少运用4中方法"
  },
  {
    "objectID": "schedule.html#聚类分析",
    "href": "schedule.html#聚类分析",
    "title": "课程安排和考核",
    "section": "3 聚类分析",
    "text": "3 聚类分析\n3.1 分析目的\n\n明确聚类的意图：划分群体、发现模式\n\n3.2 方法选择\n\n层次聚类或K-means聚类\n说明选择理由（样本量、可解释性）\n\n3.3 分析过程\n\n变量标准化方法\n聚类方法和距离度量（欧氏距离、最短距离法）\n聚类数目确定依据（树状图、拐点法）\n\n3.4 结果与解释\n\n用树状图或散点图展示结果\n描述每类的特征（平均值、分布差异）"
  },
  {
    "objectID": "schedule.html#判别分析",
    "href": "schedule.html#判别分析",
    "title": "课程安排和考核",
    "section": "4 判别分析",
    "text": "4 判别分析\n4.1 分析目的\n\n根据已知分组建立判别函数，用于分类\n\n4.2 方法选择\n\nFisher判别或逐步判别法\n判别变量选择标准（Wilks’ Lambda）\n\n4.3 分析过程\n\n建立判别函数，给出系数\n交叉验证或留一法评价判别正确率\n\n4.4 结果与解释\n\n判别准确率表格\n分析误判情况和原因"
  },
  {
    "objectID": "schedule.html#主成分分析",
    "href": "schedule.html#主成分分析",
    "title": "课程安排和考核",
    "section": "5 主成分分析",
    "text": "5 主成分分析\n5.1 分析目的\n\n降维、提取主要信息\n\n5.2 分析过程\n\n相关矩阵/协方差矩阵\n特征值&gt;1原则、累计贡献率≥85%\n碎石图展示拐点\n\n5.3 结果解释\n\n主成分载荷矩阵解释变量含义\n给出主成分得分函数"
  },
  {
    "objectID": "schedule.html#因子分析",
    "href": "schedule.html#因子分析",
    "title": "课程安排和考核",
    "section": "6 因子分析",
    "text": "6 因子分析\n6.1 分析目的\n\n探索潜在因子，简化变量结构\n\n6.2 分析过程\n\nKMO和Bartlett检验结果\n因子提取方法：主成分法、最大似然法\n因子旋转\n\n6.3 结果解释\n\n因子载荷表\n命名各因子"
  },
  {
    "objectID": "schedule.html#对应分析",
    "href": "schedule.html#对应分析",
    "title": "课程安排和考核",
    "section": "7 对应分析",
    "text": "7 对应分析\n7.1 分析目的\n\n探索两个类别变量的关联关系，将列联表降维至二维空间，用图形直观展示类别间的亲疏关系。\n\n7.2 分析过程\n\n构建行×列列联表，进行卡方独立性检验；\n若显著，进行对应分析，提取前两维；\n绘制对应图展示行、列类别的位置关系。\n\n7.3 结果解释\n\n对应图中点距离越近，说明该类别组合越常出现；\n可识别相似类别的聚集和差异"
  },
  {
    "objectID": "schedule.html#典型相关分析",
    "href": "schedule.html#典型相关分析",
    "title": "课程安排和考核",
    "section": "8 典型相关分析",
    "text": "8 典型相关分析\n8.1 分析目的\n\n研究两组连续变量之间的整体相关性，提取相关性最强的线性组合。\n\n8.2 分析过程\n\n将变量划分为两组，计算协方差矩阵；\n进行典型相关分析，得到典型相关系数及显著性检验（如Wilks’ Lambda）；\n保留显著的前1–2对典型变量。\n\n8.3 结果解释\n\n报告第一对典型变量的系数和载荷；\n解读两组变量的关系"
  },
  {
    "objectID": "schedule.html#结论和展望",
    "href": "schedule.html#结论和展望",
    "title": "课程安排和考核",
    "section": "9 结论和展望",
    "text": "9 结论和展望\n\n总结主要发现\n研究不足\n展望未来研究方向\n课程感想"
  },
  {
    "objectID": "schedule.html#答题要求",
    "href": "schedule.html#答题要求",
    "title": "课程安排和考核",
    "section": "答题要求",
    "text": "答题要求\n\n项目命名: 文件夹及压缩包统一命名为：学号姓名（无空格），例如：20210008张三；提交压缩包为 20210008张三.zip。\nR代码文件，按题号分节。每题先写实现该小题的R代码，每小题代码下方用文字简要回答题目要求。\n提交说明: 将整个项目文件夹压缩为 学号姓名.zip。 通过电子邮件发送压缩包到指定提交邮箱lizongzhang9@qq.com。 邮件主题：多元统计测验 学号姓名\n\n\n\n第1题\n\n\n\n  点击下载数据文件: 第1题: metro16.xlsx \n\n\n第2题\n\n\n\n  点击下载数据文件: 第2题: bankloan.xlsx \n\n\n第3题\n\n\n\n\n\n答案\n\nSolutions"
  },
  {
    "objectID": "chap6.html",
    "href": "chap6.html",
    "title": "第6章",
    "section": "",
    "text": "Chap 6 讲义\n主成分分析 R代码\nPCA实例: NFL球员R代码\nPCA explained visually"
  },
  {
    "objectID": "chap6.html#第6章-主成分分析",
    "href": "chap6.html#第6章-主成分分析",
    "title": "第6章",
    "section": "",
    "text": "Chap 6 讲义\n主成分分析 R代码\nPCA实例: NFL球员R代码\nPCA explained visually"
  },
  {
    "objectID": "chap6.html#b站视频",
    "href": "chap6.html#b站视频",
    "title": "第6章",
    "section": "B站视频",
    "text": "B站视频\n主成分分析在R中的实现——prcomp函数的运用 例题6.1\n主成分分析的应用——31省区居民消费分析 习题6.7讲评\n主成分分析的可视化工具——相关圈和散点图的绘制 例题6.1 {target=“_blank”}"
  },
  {
    "objectID": "chap7.html",
    "href": "chap7.html",
    "title": "第7章",
    "section": "",
    "text": "chap 7 讲义\n 因子分析 R代码\n 主观态度因子分析\n 汽车性能因子分析"
  },
  {
    "objectID": "chap7.html#第7章-因子分析",
    "href": "chap7.html#第7章-因子分析",
    "title": "第7章",
    "section": "",
    "text": "chap 7 讲义\n 因子分析 R代码\n 主观态度因子分析\n 汽车性能因子分析"
  },
  {
    "objectID": "L5svm.html#非线性情况核技巧-the-kernel-trick",
    "href": "L5svm.html#非线性情况核技巧-the-kernel-trick",
    "title": "L5 SVM",
    "section": "非线性情况：核技巧 (The Kernel Trick)",
    "text": "非线性情况：核技巧 (The Kernel Trick)\n\n现实中的数据常常无法用一条直线分开。\nSVM 对此提供了一个非常巧妙的解决方案，称为核技巧。\n\n桌面上混杂着两种豆子，你无法用一把尺子将它们分开（二维空间）。\n但如果你猛地一抖桌布，让一部分豆子飞起来，这时你就可以轻松地用一个水平的纸板（一个平面）将空中的豆子和桌面上的豆子分开（三维空间）。\n\n核技巧：通过数学变换，将数据从低维空间映射到高维空间，使得原本线性不可分的数据在高维空间中变得线性可分。而这个过程非常高效，我们甚至不需要知道数据在高维空间中的具体坐标。\n\n:::"
  },
  {
    "objectID": "L5svm.html#核函数",
    "href": "L5svm.html#核函数",
    "title": "L5 SVM",
    "section": "5.1 核函数",
    "text": "5.1 核函数\n\nkernel（核函数）：决定SVM如何将数据映射到高维空间。常用选项（R中写法）：\n“linear”：线性核，适合线性可分或特征很多的数据。\n“radial”：径向基核（RBF），适合大多数情况，能处理非线性关系。\n“polynomial”：多项式核，适合有多项式边界的数据。\n“sigmoid”：S型核，较少用。\n\n核函数选取建议\n\n优先尝试”radial”（RBF）核，适应性强，大多数数据都适用。\n特征非常多时可先试”linear”核。"
  },
  {
    "objectID": "L5svm.html#cost参数",
    "href": "L5svm.html#cost参数",
    "title": "L5 SVM",
    "section": "5.2 Cost参数",
    "text": "5.2 Cost参数\n\ncost：惩罚参数C，控制训练误差和模型复杂度的权衡，其取值理论上可以是任意正数。\n\ncost: 一般从1开始，常用[0.1, 1, 10, 100]等。\nC大：对误分类容忍度低，间隔小，易过拟合。\nC小：对误分类容忍度高，间隔大，易欠拟合。"
  },
  {
    "objectID": "L5svm.html#gamma参数",
    "href": "L5svm.html#gamma参数",
    "title": "L5 SVM",
    "section": "5.3 Gamma参数",
    "text": "5.3 Gamma参数\n\ngamma：RBF和多项式核的参数，控制单个样本的影响范围。\n\ngamma大：影响范围小，模型复杂，易过拟合。\ngamma小：影响范围大，模型简单，易欠拟合。\ngamma: RBF核时，默认 1/特征数；可以尝试[0.001, 0.01, 0.1, 1]等。"
  },
  {
    "objectID": "L5svm.html#调参方法",
    "href": "L5svm.html#调参方法",
    "title": "L5 SVM",
    "section": "5.4 调参方法",
    "text": "5.4 调参方法\n\n网格搜索（Grid Search）+ 交叉验证（Cross Validation）\n自动搜索最优参数\n\ncaret::train()\ne1071::tune()"
  },
  {
    "objectID": "L5svm.html#调参经验",
    "href": "L5svm.html#调参经验",
    "title": "L5 SVM",
    "section": "5.5 调参经验",
    "text": "5.5 调参经验\n\n数据标准化：SVM对特征尺度敏感，建议先做标准化。\ngamma与cost的平衡：一般先fix一个参数，调另一个，再联合微调。\n经验区间：实际中cost/gamma变化1-2个数量级后模型表现变化会很明显，通常不用范围太宽。\n可视化决策边界：低维数据可画分类边界观察调参效果。\n初学者推荐\n\nkernel=“radial”\ncost=1\ngamma=1/特征数\n遇到过拟合/欠拟合时，分别降低/增大cost和gamma。"
  },
  {
    "objectID": "ldaR.html",
    "href": "ldaR.html",
    "title": "5 LDA在R中的实现",
    "section": "",
    "text": "本章介绍R中的判别分析工具。"
  },
  {
    "objectID": "ldaR.html#考察数据分布",
    "href": "ldaR.html#考察数据分布",
    "title": "5 LDA在R中的实现",
    "section": "1.1 考察数据分布",
    "text": "1.1 考察数据分布\n\nlibrary(psych)\n\n#调用数据iris\ndata(iris)\n\n#Correlation ellipses \n#The narrower the ellipse\n#the greater the correlation between the variables\n\npairs.panels(iris[1:4],\n            gap = 0,\n            bg = c(\"red\", \"green\", \"blue\")[iris$Species],\n            pch = 21)"
  },
  {
    "objectID": "ldaR.html#检验lda分析的假设是否成立",
    "href": "ldaR.html#检验lda分析的假设是否成立",
    "title": "5 LDA在R中的实现",
    "section": "1.2 检验LDA分析的假设是否成立",
    "text": "1.2 检验LDA分析的假设是否成立\n\n1.2.1 多元正态性检验\nMardia检验\n原假设:数据服从多元正态分布\n备择假设:数据不服从多元正态分布\n\n# 多元正态性检验（Mardia测试）\nMVN::mardia(iris[1:50, 1:4])\n\n             Test Statistic   p.value     Method\n1 Mardia Skewness 25.664345 0.1771859 asymptotic\n2 Mardia Kurtosis  1.294992 0.1953229 asymptotic\n\nMVN::mardia(iris[51:100, 1:4])\n\n             Test  Statistic   p.value     Method\n1 Mardia Skewness 25.1850115 0.1944445 asymptotic\n2 Mardia Kurtosis -0.5718664 0.5674125 asymptotic\n\nMVN::mardia(iris[101:150, 1:4])\n\n             Test  Statistic   p.value     Method\n1 Mardia Skewness 26.2705982 0.1570597 asymptotic\n2 Mardia Kurtosis  0.1526142 0.8787025 asymptotic\n\n\n\n\n1.2.2 检验不同类别的协方差矩阵是否相等\nBox’s M检验：检验多个类别的协方差矩阵是否相等\n\n原假设：所有类别的协方差矩阵相等\n备择假设：至少有一个类别的协方差矩阵与其他类别不同\n\n\nlibrary(biotools)\nboxM(iris[1:4], iris$Species)\n\n\n    Box's M-test for Homogeneity of Covariance Matrices\n\ndata:  iris[1:4]\nChi-Sq (approx.) = 140.94, df = 20, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "ldaR.html#估计",
    "href": "ldaR.html#估计",
    "title": "5 LDA在R中的实现",
    "section": "2.1 估计",
    "text": "2.1 估计\n\n#加载包MASS(Modern Applied Statistics with S) \n#https://www.stats.ox.ac.uk/pub/MASS4/\n\nlibrary(MASS)\n\n#估计linear discriminant model \n\n# 写法一：\nlinear &lt;- lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, iris)\nlinear\n\nCall:\nlda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, \n    data = iris)\n\nPrior probabilities of groups:\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\nGroup means:\n           Sepal.Length Sepal.Width Petal.Length Petal.Width\nsetosa            5.006       3.428        1.462       0.246\nversicolor        5.936       2.770        4.260       1.326\nvirginica         6.588       2.974        5.552       2.026\n\nCoefficients of linear discriminants:\n                    LD1         LD2\nSepal.Length  0.8293776 -0.02410215\nSepal.Width   1.5344731 -2.16452123\nPetal.Length -2.2012117  0.93192121\nPetal.Width  -2.8104603 -2.83918785\n\nProportion of trace:\n   LD1    LD2 \n0.9912 0.0088 \n\n# 写法二：\nlinear &lt;- lda(Species ~., iris)\n\n\n#查看ld的属性\nattributes(linear)\n\n$names\n [1] \"prior\"   \"counts\"  \"means\"   \"scaling\" \"lev\"     \"svd\"     \"N\"      \n [8] \"call\"    \"terms\"   \"xlevels\"\n\n$class\n[1] \"lda\"\n\nlinear$prior\n\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\nlinear$counts\n\n    setosa versicolor  virginica \n        50         50         50 \n\nlinear$means\n\n           Sepal.Length Sepal.Width Petal.Length Petal.Width\nsetosa            5.006       3.428        1.462       0.246\nversicolor        5.936       2.770        4.260       1.326\nvirginica         6.588       2.974        5.552       2.026\n\nlinear$scaling\n\n                    LD1         LD2\nSepal.Length  0.8293776 -0.02410215\nSepal.Width   1.5344731 -2.16452123\nPetal.Length -2.2012117  0.93192121\nPetal.Width  -2.8104603 -2.83918785"
  },
  {
    "objectID": "ldaR.html#预测",
    "href": "ldaR.html#预测",
    "title": "5 LDA在R中的实现",
    "section": "2.2 预测",
    "text": "2.2 预测\n\n#保存判别函数的预测结果\np &lt;- predict(linear, iris)\n\npredict_class &lt;- p$class\npredict_class\n\n  [1] setosa     setosa     setosa     setosa     setosa     setosa    \n  [7] setosa     setosa     setosa     setosa     setosa     setosa    \n [13] setosa     setosa     setosa     setosa     setosa     setosa    \n [19] setosa     setosa     setosa     setosa     setosa     setosa    \n [25] setosa     setosa     setosa     setosa     setosa     setosa    \n [31] setosa     setosa     setosa     setosa     setosa     setosa    \n [37] setosa     setosa     setosa     setosa     setosa     setosa    \n [43] setosa     setosa     setosa     setosa     setosa     setosa    \n [49] setosa     setosa     versicolor versicolor versicolor versicolor\n [55] versicolor versicolor versicolor versicolor versicolor versicolor\n [61] versicolor versicolor versicolor versicolor versicolor versicolor\n [67] versicolor versicolor versicolor versicolor virginica  versicolor\n [73] versicolor versicolor versicolor versicolor versicolor versicolor\n [79] versicolor versicolor versicolor versicolor versicolor virginica \n [85] versicolor versicolor versicolor versicolor versicolor versicolor\n [91] versicolor versicolor versicolor versicolor versicolor versicolor\n [97] versicolor versicolor versicolor versicolor virginica  virginica \n[103] virginica  virginica  virginica  virginica  virginica  virginica \n[109] virginica  virginica  virginica  virginica  virginica  virginica \n[115] virginica  virginica  virginica  virginica  virginica  virginica \n[121] virginica  virginica  virginica  virginica  virginica  virginica \n[127] virginica  virginica  virginica  virginica  virginica  virginica \n[133] virginica  versicolor virginica  virginica  virginica  virginica \n[139] virginica  virginica  virginica  virginica  virginica  virginica \n[145] virginica  virginica  virginica  virginica  virginica  virginica \nLevels: setosa versicolor virginica\n\n#预测新个案\nnew_case &lt;- data.frame(Sepal.Length = c(5.1,5.9,6.6),\n                       Sepal.Width = c(3.5,2.8,2.9),\n                       Petal.Length = c(1.5,4.3,5.6),\n                       Petal.Width = c(0.25,1.3,2.1))\n\nnew_class &lt;- predict(linear, new_case)\nnew_class\n\n$class\n[1] setosa     versicolor virginica \nLevels: setosa versicolor virginica\n\n$posterior\n        setosa   versicolor    virginica\n1 1.000000e+00 1.117074e-20 3.314219e-40\n2 2.963609e-20 9.998273e-01 1.727265e-04\n3 4.169387e-42 3.505610e-05 9.999649e-01\n\n$x\n        LD1        LD2\n1  7.701156 -0.3491879\n2 -1.823849  0.7749274\n3 -6.199781 -0.5182489"
  },
  {
    "objectID": "ldaR.html#评估预测效果",
    "href": "ldaR.html#评估预测效果",
    "title": "5 LDA在R中的实现",
    "section": "2.3 评估预测效果",
    "text": "2.3 评估预测效果\n\n#绘制观测组别和预测组别的列联表\ntab &lt;- table(Actual = iris$Species, Predicted = predict_class)\ntab\n\n            Predicted\nActual       setosa versicolor virginica\n  setosa         50          0         0\n  versicolor      0         48         2\n  virginica       0          1        49\n\n#计算预测正确率\nsum(diag(tab))/sum(tab)\n\n[1] 0.98"
  },
  {
    "objectID": "ldaR.html#单个判别函数得分的直方图",
    "href": "ldaR.html#单个判别函数得分的直方图",
    "title": "5 LDA在R中的实现",
    "section": "3.1 单个判别函数得分的直方图",
    "text": "3.1 单个判别函数得分的直方图\n\n#判别函数得分的histogram\nlibrary(MASS)\n\n#保存预测结果\np &lt;- predict(linear, iris)\n\n\n#提取预测结果中存储的判别得分\nldahist(p$x[,1], iris$Species)\n\n\n\n\n\n\n\nldahist(p$x[,2], iris$Species)"
  },
  {
    "objectID": "ldaR.html#两个判别函数得分的二维图",
    "href": "ldaR.html#两个判别函数得分的二维图",
    "title": "5 LDA在R中的实现",
    "section": "3.2 两个判别函数得分的二维图",
    "text": "3.2 两个判别函数得分的二维图\n\n# Enable the r-universe repo\noptions(repos = c(\n    fawda123 = 'https://fawda123.r-universe.dev',\n    CRAN = 'https://cloud.r-project.org'))\n\n# Install ggord\ninstall.packages('ggord', repos = c('https://fawda123.r-universe.dev', 'https://cloud.r-project.org'))\n\n\n#Bi-plot\nlibrary(devtools)\nlibrary(ggord)\n\nlinear &lt;- lda(Species ~., iris)\nggord(linear, iris$Species)\n\n\n\n\n\n\n\nlinear$scaling\n\n                    LD1         LD2\nSepal.Length  0.8293776 -0.02410215\nSepal.Width   1.5344731 -2.16452123\nPetal.Length -2.2012117  0.93192121\nPetal.Width  -2.8104603 -2.83918785\n\n\n\n椭圆\n\n统计意义：\n\n椭圆基于类别样本在LD1和LD2上的协方差矩阵绘制，反映该类别数据的分散程度和形状。\n每个椭圆围住该类别的大部分数据点（通常95%），中心点是类别的均值（质心）。\n\n中心：椭圆的中心是该类别在LD1和LD2上的平均得分，反映类别在判别空间的“位置”。\n大小：椭圆越大，说明该类别样本在LD1和LD2上的分散程度越高（方差大）；椭圆越小，样本越集中。\n形状：椭圆的形状由协方差矩阵决定：\n\n接近圆形：LD1和LD2的方差相似，特征间相关性低。\n拉长：某个方向（LD1或LD2）方差较大，或特征间相关性高。\n\n方向：椭圆的倾斜方向反映LD1和LD2的协方差，倾斜说明两轴得分有相关性。\n分类效果：\n\n椭圆分离：如果椭圆分得很开（如“金牌”和“银牌”不重叠），说明LDA有效区分了类别。\n椭圆重叠：如果椭圆重叠，说明类别在LD1和LD2上难以区分，可能因为数据不满足LDA假设（正态分布或同协方差矩阵）。\nggord图中的三个椭圆表示每个类别在LD1和LD2判别函数空间中的数据分布范围（通常是95%置信椭圆）。\n椭圆的形状和大小反映类别的协方差和分散程度，位置反映类别均值，重叠情况反映LDA的分类效果。\n圆形椭圆：LD1和LD2的方差相似，且两者相关性低（协方差接近0）。\n拉长椭圆：LD1和LD2的方差差异大，或两者有较强相关性（协方差较大）。\n\n\n\n\n箭头\n\n帮助理解哪些原始变量（特征）对LDA的分类最重要\n方向解读：\n\n如果箭头指向LD1正方向（如右方），说明该变量值增加会使样本的LD1得分增加。\n如果箭头接近垂直于LD1，说明该变量主要影响LD2。\n如果箭头与某类别椭圆的方向一致，说明该变量对该类别的区分作用强。\n\n长度解读：\n\n长箭头表示该变量对分类贡献大，可能是区分三个梯度的关键特征。\n短箭头表示变量影响小，可能对分类帮助有限"
  },
  {
    "objectID": "ldaR.html#分类边界的可视化-partition-plot",
    "href": "ldaR.html#分类边界的可视化-partition-plot",
    "title": "5 LDA在R中的实现",
    "section": "3.3 分类边界的可视化 Partition plot",
    "text": "3.3 分类边界的可视化 Partition plot\n\nLDA边界\n\nlibrary(klaR)\npartimat(Species ~., data = iris, method = \"lda\")\n\n\n\n\n\n\n\n\n\niris %&gt;% \n  group_by(Species) %&gt;%\n  summarise(across(everything(), mean))\n\n# A tibble: 3 × 5\n  Species    Sepal.Length Sepal.Width Petal.Length Petal.Width\n  &lt;fct&gt;             &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1 setosa             5.01        3.43         1.46       0.246\n2 versicolor         5.94        2.77         4.26       1.33 \n3 virginica          6.59        2.97         5.55       2.03 \n\n\n\n\nQDA边界,标记判别错误的个案\n\npartimat(Species ~ ., data = iris, method = \"qda\", \n         col.correct = \"green3\", col.wrong = \"red\")\n\n\n\n\n\n\n\n\n\npartimat() 创建分类边界的可视化图，展示每个特征对（如 Sepal.Length vs. Sepal.Width）的分类区域。\n每个子图显示 QDA 的决策边界，颜色或填充表示不同类别（Species: setosa, versicolor, virginica）。\n典型子图结构\n\nX轴和Y轴：两个特征（例如 Sepal.Length vs. Petal.Length）。\n颜色/填充区域：每个类别（setosa, versicolor, virginica）用不同颜色填充，代表 QDA 预测的分类区域。\n决策边界：曲线或非线性边界，分离不同类别区域。\n数据点：散点表示实际观测值，颜色对应其真实类别，用于验证边界准确性。\n表观错误率（apparent error rate，training error），即在训练集上模型的错误分类比例\n\n类别分离：setosa 与 versicolor/virginica 的分离较好，versicolor 和 virginica 边界较模糊，QDA 的非线性边界比 LDA 更贴合数据。\n协方差影响：QDA 允许每个类别的协方差矩阵不同，边界形状反映了数据分布的真实复杂性（例如 virginica 的 petall 特征方差较大）。\n误分类区域：重叠区域（versicolor/virginica）可能显示混合颜色，提示分类不确定性。"
  },
  {
    "objectID": "4R.html",
    "href": "4R.html",
    "title": "4 聚类分析在R中的实现",
    "section": "",
    "text": "本章介绍R中的聚类分析工具。\n#安装和加载包\n#install.packages(\"ggplot2\")\n#install.packages(\"tidyverse\")\n#install.packages(\"dendextend\")\n#install.packages(\"purrr\")\n#install.packages(\"readr\")\n#install.packages(\"readxl\")\n\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(dendextend)\nlibrary(purrr)"
  },
  {
    "objectID": "4R.html#逐步运行",
    "href": "4R.html#逐步运行",
    "title": "4 聚类分析在R中的实现",
    "section": "逐步运行",
    "text": "逐步运行\n\nStep 1: 计算两点之间的距离 dist()\n\n#请查看dist帮助\ndist_match &lt;- dist(match)\ndist_match\n\n           1         2         3         4         5         6         7\n2   4.242641                                                            \n3  10.488088 13.490738                                                  \n4  12.409674 10.488088 14.071247                                        \n5  13.638182 15.165751 20.199010 24.859606                              \n6  14.899664 13.928388 23.958297 23.494680  8.602325                    \n7  17.349352 13.964240 26.702060 20.322401 18.138357 10.246951          \n8  23.021729 26.191602 13.190906 25.612497 28.319605 34.058773 38.223030\n9  23.430749 24.556058 14.866069 17.916473 33.778692 36.180105 36.110940\n10 22.494444 20.099751 22.494444 10.488088 33.615473 31.144823 25.670995\n11 26.000000 25.019992 34.322005 33.970576 15.937377 11.224972 16.763055\n12 29.171904 29.883106 21.000000 22.113344 39.458839 41.436699 40.570926\n           8         9        10        11\n2                                         \n3                                         \n4                                         \n5                                         \n6                                         \n7                                         \n8                                         \n9  15.264338                              \n10 31.208973 19.261360                    \n11 42.825226 46.054316 40.323690          \n12 19.824228  6.164414 20.615528 51.019604\n\n\n\n\nStep 2 : 系统聚类 hclust()\n\n#请查看hclust帮助\n\nhc_match &lt;- hclust(dist_match, \"complete\")\n\n\n\nStep 3 : 指定类数 cutree()\n\ncluster_assignments &lt;- cutree(hc_match, k = 2)\ncluster_assignments\n\n [1] 1 1 2 2 1 1 1 2 2 2 1 2\n\n#将分类结果追加到数据集中\nmatch_cluster &lt;- mutate(match, cluster = cluster_assignments )\nmatch_cluster\n\n# A tibble: 12 × 4\n      ID     x     y cluster\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1     1    -1     1       1\n 2     2    -2    -3       1\n 3     3     8     6       2\n 4     4     7    -8       2\n 5     5   -12     8       1\n 6     6   -15     0       1\n 7     7   -13   -10       1\n 8     8    15    16       2\n 9     9    21     2       2\n10    10    12   -15       2\n11    11   -25     1       1\n12    12    26     0       2\n\n#聚类结果可视化\nmatch_cluster %&gt;% \n  ggplot(aes(x, y, col = factor(cluster)))+\n  geom_point(size = 6)+\n  geom_text(aes(label = ID, hjust = - 1, size = 4))\n\n\n\n\n\n\n\n\n\n\nStep 4 : 统计每一类的个案个数count()\n\ncount(match_cluster, cluster)\n\n# A tibble: 2 × 2\n  cluster     n\n    &lt;int&gt; &lt;int&gt;\n1       1     6\n2       2     6\n\n\n\n\nStep 5 : 绘制树状图Dendrogram\n\n#绘制树状图\nplot(hc_match)\n\n\n\n\n\n\n\n#所有个案从水平线出发\nplot(hc_match, hang = -1)\n#给分支添加矩形框\nrect.hclust(hc_match, k = 2, border = 2)\n\n\n\n\n\n\n\n#给分支添加不同的颜色,指定切开的高度h= 或者指定组数k=\n\n#加载包\nlibrary(dendextend)\ndend_match &lt;- as.dendrogram(hc_match)\ndend_match_40 &lt;- color_branches(dend_match, h = 40)\n\nLoading required namespace: colorspace\n\nplot(dend_match_40)\n\n\n\n\n\n\n\n\n\n\nStep 6 : 计算各组均值\n\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\nmatch_cluster %&gt;% \n  group_by(cluster) %&gt;% \n  summarise_all(list(mean))\n\n# A tibble: 2 × 4\n  cluster    ID     x      y\n    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1       1  5.33 -11.3 -0.5  \n2       2  7.67  14.8  0.167"
  },
  {
    "objectID": "4R.html#管道符",
    "href": "4R.html#管道符",
    "title": "4 聚类分析在R中的实现",
    "section": "管道符 %>%",
    "text": "管道符 %&gt;%\n\nStep 1-6\n\nlibrary(tidyverse)\n\n#将聚类结果保存到cluster_assignments\ncluster_assignments &lt;-match %&gt;%\n  dist() %&gt;% \n  hclust(\"complete\") %&gt;% \n  cutree(2)\n\n#将聚类结果cluster_assignments追加到数据集match_cluster\nmatch_cluster &lt;- match %&gt;% mutate(cluster =\n                                    cluster_assignments)\n#聚类结果可视化\nmatch_cluster%&gt;% \n  ggplot(aes(x,y,col = factor(cluster)))+\n  geom_point(size = 6) \n\n\n\n\n\n\n\n#统计每个组别有多少个案\ncount(match_cluster, cluster) \n\n# A tibble: 2 × 2\n  cluster     n\n    &lt;int&gt; &lt;int&gt;\n1       1     6\n2       2     6\n\n#绘制树状图\nmatch %&gt;%\n  dist() %&gt;% \n  hclust(\"complete\") %&gt;%\n  plot()\n\n\n\n\n\n\n\n#树状图的分支上色\nlibrary(dendextend)\nmatch %&gt;%\n  dist() %&gt;% \n  hclust(\"complete\") %&gt;%\n  as.dendrogram() %&gt;% \n  color_branches(h = 40) %&gt;% \n  plot()\n\n\n\n\n\n\n\nmatch %&gt;%\n  dist() %&gt;% \n  hclust(\"complete\") %&gt;%\n  as.dendrogram() %&gt;% \n  color_branches(k = 3) %&gt;% \n  plot()\n\n\n\n\n\n\n\n\n\n\n不同聚类方案下的树状图\n\n#绘制三种连接法linkage method下的树状图\nmatch %&gt;%\n  dist() %&gt;% \n  hclust(\"complete\") %&gt;%\n  as.dendrogram() %&gt;% \n  color_branches(k = 2) %&gt;% \n  plot(main = \"Complete Linkage\")\n\n\n\n\n\n\n\nmatch %&gt;%\n  dist() %&gt;% \n  hclust(\"single\") %&gt;%\n  as.dendrogram() %&gt;% \n  color_branches(k = 2) %&gt;% \n  plot(main = \"Single Linkage\")\n\n\n\n\n\n\n\nmatch %&gt;%\n  dist() %&gt;% \n  hclust(\"average\") %&gt;%\n  as.dendrogram() %&gt;% \n  color_branches(k = 2) %&gt;% \n  plot(main = \"Average Linkage\")"
  },
  {
    "objectID": "4R.html#kmeans",
    "href": "4R.html#kmeans",
    "title": "4 聚类分析在R中的实现",
    "section": "kmeans()",
    "text": "kmeans()\n\n#k-means估计\nmodel &lt;- kmeans(match, centers = 3)\n\n#查看model中保存的对象\nattributes(model)\n\n$names\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n$class\n[1] \"kmeans\"\n\n#查看model中保存的聚类结果\nmodel$cluster\n\n [1] 1 1 2 2 1 1 1 2 2 2 3 2\n\n#将model中保存的聚类结果追加到数据框match_kmeans\nmatch_kmeans &lt;- mutate(match, cluster = model$cluster)"
  },
  {
    "objectID": "4R.html#确定k-elbow-plot",
    "href": "4R.html#确定k-elbow-plot",
    "title": "4 聚类分析在R中的实现",
    "section": "确定k: elbow plot",
    "text": "确定k: elbow plot\n\n#加载包purrr\nlibrary(purrr)\n\n#查看within-cluster sum of squares\nmodel$tot.withinss\n\n[1] 1295.8\n\n# Use map_dbl to run many models with varying value of k (centers)\ntot_withinss &lt;- map_dbl(1:10,  function(k){\n  model &lt;- kmeans(match, k)\n  model$tot.withinss\n})\n\n# map_dbl(1:10, function(k) {...}): 这一部分使用 map_dbl() 函数，对 1 到 10 的整数进行循环迭代，其中 k 是循环变量，对应不同的聚类数。对于每个 k 值，它会执行以下操作：\n# \n# model &lt;- kmeans(match, k): 使用 kmeans() 函数进行 K 均值聚类，其中 match 是输入的数据集，k 是聚类数。这一步创建了一个 K 均值聚类模型 model。\n# \n# model$tot.withinss: 从聚类模型 model 中获取总内部平方和 tot.withinss 的值，它表示每个点到其所属簇的距离的平方和。\n\n\n\n# Generate a data frame containing both k and tot_withinss\nelbow_df &lt;- data.frame(\n  k = 1:10,\n  tot_withinss = tot_withinss\n)\nelbow_df\n\n    k tot_withinss\n1   1    3632.9167\n2   2    1561.1667\n3   3     973.1833\n4   4     797.1667\n5   5     462.2500\n6   6     321.3333\n7   7     252.3333\n8   8     198.6667\n9   9     133.0000\n10 10      28.0000\n\n# Plot the elbow plot\nggplot(elbow_df, aes(k, tot_withinss)) +\n  geom_line() +\n  scale_x_continuous(breaks = 1:10)"
  },
  {
    "objectID": "4R.html#逐步运行-1",
    "href": "4R.html#逐步运行-1",
    "title": "4 聚类分析在R中的实现",
    "section": "逐步运行",
    "text": "逐步运行\n\ndist_customers &lt;- dist(customers)\nhc_customers &lt;- hclust(dist_customers)\nclust_customers &lt;- cutree(hc_customers, h = 15000)\nsegment_customers &lt;- mutate(customers, cluster = clust_customers)\n\n# Count the number of customers that fall into each cluster\ncount(segment_customers, cluster)\n\n# A tibble: 4 × 2\n  cluster     n\n    &lt;int&gt; &lt;int&gt;\n1       1     5\n2       2    29\n3       3     5\n4       4     6\n\n# Color the dendrogram based on the height cutoff\nlibrary(dendextend)\ndend_customers &lt;- as.dendrogram(hc_customers)\ndend_colored &lt;- color_branches(dend_customers, h = 15000)\n\n# Plot the colored dendrogram\nplot(dend_colored)\n\n\n\n\n\n\n\n# Calculate the mean for each category\nsegment_customers %&gt;% \n  group_by(cluster) %&gt;% \n  summarise_all(list(mean))\n\n# A tibble: 4 × 5\n  cluster    ID   Milk Grocery Frozen\n    &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1       1  16.2 16950   12891.   991.\n2       2  21.9  2513.   5229.  1796.\n3       3  18.6 10452.  22551.  1355.\n4       4  37.5  1250.   3917. 10889."
  },
  {
    "objectID": "4R.html#管道符-1",
    "href": "4R.html#管道符-1",
    "title": "4 聚类分析在R中的实现",
    "section": "管道符 %>%",
    "text": "管道符 %&gt;%\n\nsegment_customers &lt;- customers %&gt;% \n  dist() %&gt;% \n  hclust() %&gt;% \n  cutree(h = 15000) %&gt;% \n  mutate(customers, cluster = .)\n\ncustomers %&gt;% \n  dist() %&gt;% \n  hclust() %&gt;%  \n  as.dendrogram() %&gt;% \n  color_branches(h = 15000) %&gt;% \n  plot()\n\n\n\n\n\n\n\ncount(segment_customers, cluster)\n\n# A tibble: 4 × 2\n  cluster     n\n    &lt;int&gt; &lt;int&gt;\n1       1     5\n2       2    29\n3       3     5\n4       4     6\n\n#报告各类均值\nsegment_customers %&gt;% \n  select(2:5) %&gt;% \n  group_by(cluster) %&gt;% \n  summarise_all(list(mean))\n\n# A tibble: 4 × 4\n  cluster   Milk Grocery Frozen\n    &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1       1 16950   12891.   991.\n2       2  2513.   5229.  1796.\n3       3 10452.  22551.  1355.\n4       4  1250.   3917. 10889.\n\n#分组直方图\nsegment_customers %&gt;% \n  ggplot(aes(Milk, fill = factor(cluster)))+\n  geom_histogram()+\n  facet_wrap(~cluster, ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n#分组箱线图\nsegment_customers %&gt;% \n  ggplot(aes(Milk, fill = factor(cluster)))+\n  geom_boxplot()+\n  facet_wrap(~cluster, ncol = 1)\n\n\n\n\n\n\n\nboxplot(segment_customers$Frozen ~ segment_customers$cluster,\n        horizontal = T,\n        col = 5,\n        las = 1)"
  },
  {
    "objectID": "svmR.html",
    "href": "svmR.html",
    "title": "5 SVM在R中的实现",
    "section": "",
    "text": "本章介绍R中的SVM\n\n安装包\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"MASS\")\ninstall.packages(\"klaR\")\ninstall.packages(\"devtools\")\ninstall.packages(\"psych\")\ninstall.packages(\"MVN\")\ninstall.packages(\"e1071\")\n\n\n\n加载包\n\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(biotools)\nlibrary(MVN)\nlibrary(e1071)\n\n\n\n1 SVM模型的建立\n\n# 取两个变量做演示\niris_sub &lt;- iris[, c(\"Sepal.Length\", \"Sepal.Width\", \"Species\")]\n\n# 建立 SVM 模型（径向基核函数 RBF）\nsvm_model &lt;- svm(Species ~ ., data = iris_sub, \n                 kernel = \"radial\", \n                 cost = 1, \n                 gamma = 0.5)\n\n\n\n2 SVM模型的可视化\n\n# 生成网格点用于预测\nxrange &lt;- seq(min(iris_sub$Sepal.Length) - 0.5, \n              max(iris_sub$Sepal.Length) + 0.5, \n              by = 0.02)\n\nyrange &lt;- seq(min(iris_sub$Sepal.Width) - 0.5, \n              max(iris_sub$Sepal.Width) + 0.5, \n              by = 0.02)\n\ngrid &lt;- expand.grid(Sepal.Length = xrange, \n                    Sepal.Width = yrange)\n\n# 对网格点分类预测\ngrid$Species &lt;- predict(svm_model, grid)\n\n\n# 画出分类区域和样本点\nggplot() +\n  geom_tile(data = grid, \n            aes(x = Sepal.Length, \n                y = Sepal.Width, \n                fill = Species), \n            alpha = 0.3) +\n  geom_point(data = iris_sub, \n             aes(x = Sepal.Length, \n                 y = Sepal.Width, \n                 color = Species), \n             size = 2) +\n  labs(title = \"SVM on Iris Dataset (3-class)\",\n       x = \"Sepal Length\", \n       y = \"Sepal Width\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3 计算预测准确率\n\npred &lt;- predict(svm_model, iris_sub)\n\naccuracy &lt;- mean(pred == iris_sub$Species)\n\nprint(paste(\"Accuracy:\", round(accuracy * 100, 2), \"%\"))\n\n[1] \"Accuracy: 82 %\"\n\n\n\n\n4 改进SVM模型\n\n\n4.1 调整参数\n\nsvm_model_tuned &lt;- svm(Species ~ ., \n                       data = iris_sub,\n                       kernel = \"radial\", \n                       cost = 10, \n                       gamma = 0.8)\n\npred_tuned &lt;- predict(svm_model_tuned, iris_sub)\n\naccuracy_tuned &lt;- mean(pred_tuned == iris_sub$Species)\n\nprint(paste(\"Tuned Accuracy:\", round(accuracy_tuned * 100, 2), \"%\"))\n\n[1] \"Tuned Accuracy: 82 %\"\n\n\n\n\n4.2 使用不同核函数（线性核）\n\nsvm_model_linear &lt;- svm(Species ~ ., \n                        data = iris_sub,\n                        kernel = \"linear\", \n                        cost = 10)\n\npred_linear &lt;- predict(svm_model_linear, \n                       iris_sub)\n\naccuracy_linear &lt;- mean(pred_linear == iris_sub$Species)\n\nprint(paste(\"Linear Kernel Accuracy:\", round(accuracy_linear * 100, 2),\n            \"%\"))\n\n[1] \"Linear Kernel Accuracy: 82 %\"\n\n\n\n\n4.3 数据预处理（标准化）\n\niris_sub_scaled &lt;- iris_sub\n\niris_sub_scaled[, 1:2] &lt;- scale(iris_sub_scaled[, 1:2])\n\nsvm_model_scaled &lt;- svm(Species ~ ., \n                        data = iris_sub_scaled,\n                        kernel = \"radial\", \n                        cost = 1, \n                        gamma = 0.5)\n\npred_scaled &lt;- predict(svm_model_scaled, iris_sub_scaled)\n\naccuracy_scaled &lt;- mean(pred_scaled == iris_sub_scaled$Species)\n\nprint(paste(\"Scaled Data Accuracy:\", round(accuracy_scaled * 100, 2),\n            \"%\"))\n\n[1] \"Scaled Data Accuracy: 82 %\"\n\n\n\n\n4.4 交叉验证选择最佳参数\n\ntune_result &lt;- tune(svm, Species ~ ., \n                    data = iris_sub,\n                    ranges = list(cost = 10^(-1:2), \n                                  gamma = c(0.1, 0.5, 1)))\n\nbest_model &lt;- tune_result$best.model\n\npred_best &lt;- predict(best_model, iris_sub)\n\naccuracy_best &lt;- mean(pred_best == iris_sub$Species)\n\nprint(paste(\"Best Model Accuracy:\", round(accuracy_best * 100, 2),\n            \"%\"))\n\n[1] \"Best Model Accuracy: 80 %\"\n\n# 输出最佳参数\nprint(tune_result$best.parameters)\n\n  cost gamma\n5  0.1   0.5\n\n# 输出调参结果\nprint(tune_result)\n\n\nParameter tuning of 'svm':\n\n- sampling method: 10-fold cross validation \n\n- best parameters:\n cost gamma\n  0.1   0.5\n\n- best performance: 0.2133333 \n\n# 画出最佳模型的分类区域和样本点\ngrid$Species &lt;- predict(best_model, grid)\nggplot() +\n  geom_tile(data = grid, \n            aes(x = Sepal.Length, \n                y = Sepal.Width, \n                fill = Species), \n            alpha = 0.3) +\n  geom_point(data = iris_sub, \n             aes(x = Sepal.Length, \n                 y = Sepal.Width, \n                 color = Species), \n             size = 2) +\n  labs(title = \"Tuned SVM on Iris Dataset (3-class)\",\n       x = \"Sepal Length\", y = \"Sepal Width\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n4.5. 使用更多特征\n\n# 前文仅用两个特征做可视化，实际可用全部特征\n# 由于可视化限制，无法直接展示多维特征空间的分类边界，但可以通过准确率来评估模型性能\n\nsvm_model_full &lt;- svm(Species ~ ., \n                      data = iris,\n                      kernel = \"radial\", \n                      cost = 1, \n                      gamma = 0.5)\n\npred_full &lt;- predict(svm_model_full, iris)\n\naccuracy_full &lt;- mean(pred_full == iris$Species)\n\nprint(paste(\"Full Feature Set Accuracy:\", \n            round(accuracy_full * 100, 2), \"%\"))\n\n[1] \"Full Feature Set Accuracy: 97.33 %\""
  },
  {
    "objectID": "projects.html#project-2",
    "href": "projects.html#project-2",
    "title": "Projects",
    "section": "Project 2",
    "text": "Project 2"
  },
  {
    "objectID": "projects.html#project-3",
    "href": "projects.html#project-3",
    "title": "Projects",
    "section": "Project 3",
    "text": "Project 3"
  },
  {
    "objectID": "pcadraft.html#主成分分析概述",
    "href": "pcadraft.html#主成分分析概述",
    "title": "主成分分析（PCA）",
    "section": "1. 主成分分析概述",
    "text": "1. 主成分分析概述\n主成分分析（Principal Component Analysis, PCA）是一种降维（dimension reduction）方法， 通过线性变换将原始变量组合为若干个新的、不相关的综合变量（主成分）， 以保留数据中最主要的变异信息。\n数学思想简要\n设原始数据矩阵为 ( X_{n p} )，包含 ( n ) 个样本、( p ) 个变量。\nPCA 的核心思想是：\n\n对中心化后的数据 ( X ) 求协方差矩阵 ( S )；\n求解特征值分解： [ S = V V’ ] 其中 ( ) 为特征值对角矩阵，( V ) 为特征向量矩阵；\n将原始变量线性组合得到主成分： [ Z = X V ] 每个主成分都是原始变量的线性组合，并按方差大小排序（第一主成分方差最大）。\n\n换言之，PCA寻找一个新的坐标系，使得数据在前几个坐标方向上的方差最大， 从而实现信息压缩。"
  },
  {
    "objectID": "pcadraft.html#应用场景",
    "href": "pcadraft.html#应用场景",
    "title": "主成分分析（PCA）",
    "section": "2. 应用场景",
    "text": "2. 应用场景\n主成分分析常用于：\n\n数据降维：减少变量数量，降低模型复杂度；\n多指标综合评价：将多个指标合成为少数几个综合得分；\n可视化探索：用前两个主成分展示高维数据结构；\n去除多重共线性：在回归分析中改善解释变量间相关性。\n\n典型应用包括： - 经济指标综合评价； - 基因表达数据分析； - 图像识别与特征提取； - 环境与社会调查数据分析。"
  },
  {
    "objectID": "pcadraft.html#对数据的要求",
    "href": "pcadraft.html#对数据的要求",
    "title": "主成分分析（PCA）",
    "section": "3. 对数据的要求",
    "text": "3. 对数据的要求\nPCA 的前提假设与数据要求包括：\n\n变量量纲一致性：通常需要对数据进行标准化处理；\n线性关系假设：PCA 基于变量的线性组合；\n连续型变量：PCA 主要适用于定量数据；\n变量间存在一定相关性：若变量间完全独立，则PCA意义有限。"
  },
  {
    "objectID": "pcadraft.html#实例iris-数据集的主成分分析",
    "href": "pcadraft.html#实例iris-数据集的主成分分析",
    "title": "主成分分析（PCA）",
    "section": "4. 实例：iris 数据集的主成分分析",
    "text": "4. 实例：iris 数据集的主成分分析\n4.1 数据准备"
  },
  {
    "objectID": "chap5slide.html",
    "href": "chap5slide.html",
    "title": "Chapter 5 判别分析",
    "section": "",
    "text": "注意：本讲义供学习交流使用，请勿用于商业用途"
  },
  {
    "objectID": "teamwork.html",
    "href": "teamwork.html",
    "title": "小组作业",
    "section": "",
    "text": "分组\n每组3人，由组长填写在线问卷，提交分组信息：https://www.wjx.top/vm/m1mykgE.aspx# \n每组 2–3 人，自由组合，每组需确定一名组长，负责统筹、协调、整合报告。\n\n\n小组作业目标\n\n掌握多元统计方法在现实中的综合应用\n提升数据收集、清理、分析和解释能力\n培养团队合作、PPT制作、口头汇报能力\n\n\n\n选题要求\n基于兴趣选题，来源于现实生活，选择身边真实可获得的数据\n\n\n数据要求\n\n截面数据\n样本容量建议 ≥ 60, 最好超过100\n至少8个以上定量变量\n至少3个以上定性变量\n不可使用虚拟数据\n\n\n\n方法运用\n至少使用 4 种不同的多元统计方法，可选：聚类分析、判别分析、主成分分析、因子分析、对应分析、典型相关分析\n\n\n讨论课安排\n\n讨论小组作业中遇到的问题、答疑、改进\n\n选题和数据 (第4周)\n聚类分析、判别分析 (第7周)\n主成分分析、因子分析 (第10周)\n对应分析、典型相关分析 (第11周)\n\n\n\n\n第1次讨论课:选题和数据\n\n选题: 简要介绍选题，并解释为什么选择这个主题？它如何源于现实生活或个人兴趣？\n数据来源渠道：从哪里获取数据？（如问卷调查，Kaggle, 知网统计数据, 中国家庭追踪调查CFPS, 中国家庭金融调查CHFS, 中国教育追踪调查CEPS, 爬虫等）\n变量类型：列出准备收集的变量（至少8个定量变量，3个定性变量）\n样本容量规划：如何确保样本容量≥60（最好&gt;100）\n遇到的困难, 需要老师提供什么帮助？\n\n\n\n第2次讨论课: 聚类/判别/主成分分析\n\n聚类分析\n判别分析\n主成分分析\n遇到的困难, 需要老师提供什么帮助？\n\n\n\n小组作业汇报\n\n课堂汇报时间：第12周周四2025-11-20, 汇报时长7分钟\nPPT页数：20-25 页\n重点展示：研究问题、数据概况、分析方法和核心结论\n\n\n\nQ&A\nQ：如何选题？\nA：从兴趣出发，考虑数据的可获得性。\n\n乐高玩具——微信小程序：积木箱\nAPP：JUMP，航旅纵横、携程，大众点评，贝壳等\n网站：boss直聘，易车\n必应/google搜索 关键词 + 数据/dataset\n参考选题\n\n微信公众号狗熊会&gt;案例图书&gt;精品案例&gt;No.1探索性数据分析: 谁在看直播——基于RFM的粉丝聚类\n微信公众号狗熊会&gt;案例图书&gt;精品案例&gt;No4.机器学习:基于KNN的B站“哈尔滨旅游”视频热度分析\n\n\nQ：问卷调查如何收集定量变量？\nA：填空题。需要考虑被访者能否容易回答，数据质量是否可靠。\n\n每月消费，生活费，每周学习时长，运动时长等，数据波动较大，精确度较差\n手机：购置价格、型号、内存、何时购买、内存使用、下一部手机购买的预期等\nAPP使用情况"
  },
  {
    "objectID": "chap8.html",
    "href": "chap8.html",
    "title": "第8章",
    "section": "",
    "text": "chap 8 讲义\n对应分析 R代码\n多重对应分析 R代码"
  },
  {
    "objectID": "chap9.html",
    "href": "chap9.html",
    "title": "第9章",
    "section": "",
    "text": "第9章 典型相关分析\nchap 9 讲义\n典型相关分析 R代码\nDeepSeek辅助统计分析和R运用\n\n\nR软件操作\n典型相关分析计算步骤\n典型相关分析在R中的实现 ——CCA::cc()函数的运用\n典型相关分析的可视化工具\n\n\n本章作业\n利用教材例题9.1的数据，进行典型相关分析，完成以下任务：\n\n列出每一对典型变量对应的典型相关系数\n第一对典型变量的标准化典型系数。\n对典型相关系数进行统计显著性检验（整体检验每一个典型函数是否显著）。\n绘制至少两幅图（任选两种或更多），并解释图中所反映的信息。"
  },
  {
    "objectID": "chap4slide.html",
    "href": "chap4slide.html",
    "title": "Chapter 4 聚类分析",
    "section": "",
    "text": "注意：本讲义供学习交流使用，请勿用于商业用途"
  },
  {
    "objectID": "L4kmodes.html#k-modes算法",
    "href": "L4kmodes.html#k-modes算法",
    "title": "L4 K-modes聚类分析",
    "section": "K-modes算法",
    "text": "K-modes算法\n\n初始化：随机选择K个个案作为初始簇中心\n分配步骤：计算每个样本与K个簇中心的距离（匹配差异系数），将样本分配到距离最近的簇\n更新步骤：对于每个簇，重新计算簇中心（众数）\n重复分配和更新步骤，直到簇中心不再变化或达到最大迭代次数"
  },
  {
    "objectID": "L4kmodes.html#k-modes优缺点",
    "href": "L4kmodes.html#k-modes优缺点",
    "title": "L4 K-modes聚类分析",
    "section": "K-modes优缺点",
    "text": "K-modes优缺点\n\n优点\n\n适用于定性数据\n计算效率高，易于实现\n能处理大规模数据集\n\n缺点\n\n需要预先指定K值\n对初始类中心敏感，可能陷入局部最优\n仅适用于定性变量，无法处理混合数据类型\n结果解释性较差，难以理解簇的含义"
  },
  {
    "objectID": "L4kmodes.html#数据",
    "href": "L4kmodes.html#数据",
    "title": "L4 K-modes聚类分析",
    "section": "数据",
    "text": "数据"
  },
  {
    "objectID": "L4kmodes.html#第1步-随机选择3个个案作为初始聚类中心",
    "href": "L4kmodes.html#第1步-随机选择3个个案作为初始聚类中心",
    "title": "L4 K-modes聚类分析",
    "section": "第1步: 随机选择3个个案作为初始聚类中心",
    "text": "第1步: 随机选择3个个案作为初始聚类中心"
  },
  {
    "objectID": "L4kmodes.html#第2步-计算个案1与cluster1的匹配差异系数",
    "href": "L4kmodes.html#第2步-计算个案1与cluster1的匹配差异系数",
    "title": "L4 K-modes聚类分析",
    "section": "第2步: 计算个案1与cluster1的匹配差异系数",
    "text": "第2步: 计算个案1与cluster1的匹配差异系数"
  },
  {
    "objectID": "L4kmodes.html#第2步-计算个案1与cluster2的匹配差异系数",
    "href": "L4kmodes.html#第2步-计算个案1与cluster2的匹配差异系数",
    "title": "L4 K-modes聚类分析",
    "section": "第2步: 计算个案1与cluster2的匹配差异系数",
    "text": "第2步: 计算个案1与cluster2的匹配差异系数"
  },
  {
    "objectID": "L4kmodes.html#第2步-计算每个个案与每个聚类中性的匹配差异系数",
    "href": "L4kmodes.html#第2步-计算每个个案与每个聚类中性的匹配差异系数",
    "title": "L4 K-modes聚类分析",
    "section": "第2步: 计算每个个案与每个聚类中性的匹配差异系数",
    "text": "第2步: 计算每个个案与每个聚类中性的匹配差异系数"
  },
  {
    "objectID": "L4kmodes.html#第3步-将个案分配到最近的簇",
    "href": "L4kmodes.html#第3步-将个案分配到最近的簇",
    "title": "L4 K-modes聚类分析",
    "section": "第3步: 将个案分配到最近的簇",
    "text": "第3步: 将个案分配到最近的簇"
  },
  {
    "objectID": "L4kmodes.html#第3步-将个案分配到最近的簇-1",
    "href": "L4kmodes.html#第3步-将个案分配到最近的簇-1",
    "title": "L4 K-modes聚类分析",
    "section": "第3步: 将个案分配到最近的簇",
    "text": "第3步: 将个案分配到最近的簇"
  },
  {
    "objectID": "L4kmodes.html#第4步-对于每个簇重新计算簇中心众数",
    "href": "L4kmodes.html#第4步-对于每个簇重新计算簇中心众数",
    "title": "L4 K-modes聚类分析",
    "section": "第4步: 对于每个簇，重新计算簇中心（众数）",
    "text": "第4步: 对于每个簇，重新计算簇中心（众数）"
  },
  {
    "objectID": "L4kmodes.html#第1轮聚类结果",
    "href": "L4kmodes.html#第1轮聚类结果",
    "title": "L4 K-modes聚类分析",
    "section": "第1轮聚类结果",
    "text": "第1轮聚类结果"
  },
  {
    "objectID": "L4kmodes.html#重新计算簇中心",
    "href": "L4kmodes.html#重新计算簇中心",
    "title": "L4 K-modes聚类分析",
    "section": "重新计算簇中心",
    "text": "重新计算簇中心"
  },
  {
    "objectID": "L4kmodes.html#重新计算个案与簇中心的匹配差异系数",
    "href": "L4kmodes.html#重新计算个案与簇中心的匹配差异系数",
    "title": "L4 K-modes聚类分析",
    "section": "重新计算个案与簇中心的匹配差异系数",
    "text": "重新计算个案与簇中心的匹配差异系数"
  },
  {
    "objectID": "L4kmodes.html#重新确定个案归属于哪个簇",
    "href": "L4kmodes.html#重新确定个案归属于哪个簇",
    "title": "L4 K-modes聚类分析",
    "section": "重新确定个案归属于哪个簇",
    "text": "重新确定个案归属于哪个簇\n直到簇中心不再变化或达到最大迭代次数"
  },
  {
    "objectID": "L4kmodes.html#r包klar",
    "href": "L4kmodes.html#r包klar",
    "title": "L4 K-modes聚类分析",
    "section": "R包：klaR",
    "text": "R包：klaR\nklaR package"
  },
  {
    "objectID": "L4kmodes.html#变量含义",
    "href": "L4kmodes.html#变量含义",
    "title": "L4 K-modes聚类分析",
    "section": "变量含义",
    "text": "变量含义"
  },
  {
    "objectID": "L4kmodes.html#k-prototypes算法",
    "href": "L4kmodes.html#k-prototypes算法",
    "title": "L4 K-modes聚类分析",
    "section": "k-prototypes算法",
    "text": "k-prototypes算法\n距离度量\n\\[\nd(x_i, z_j) = \\sum_{k \\in \\text{numerical}}(x_{ik} - z_{jk})^2 +\n\\gamma \\sum_{l \\in \\text{categorical}} \\delta(x_{il}, z_{jl})\n\\]\n\n数值变量使用平方欧氏距离\n分类变量使用匹配/不匹配距离（相同=0，不同=1）\nγ 为权重系数，用于平衡数值和分类变量"
  },
  {
    "objectID": "L4kmodes.html#聚类步骤",
    "href": "L4kmodes.html#聚类步骤",
    "title": "L4 K-modes聚类分析",
    "section": "聚类步骤",
    "text": "聚类步骤\n\n初始化：随机选择K个原型（簇中心），数值部分取均值，分类部分取众数。\n分配簇：将每个样本分配给距离最近的簇（使用上面的混合距离度量）。\n更新簇中心：\n\n数值变量 → 取簇内均值\n分类变量 → 取簇内众数\n\n迭代，直到簇分配不再变化或达到最大迭代次数。"
  },
  {
    "objectID": "L4kmodes.html#r包clustmixtype",
    "href": "L4kmodes.html#r包clustmixtype",
    "title": "L4 K-modes聚类分析",
    "section": "R包：clustMixType",
    "text": "R包：clustMixType\nclustMixType package"
  },
  {
    "objectID": "case.html",
    "href": "case.html",
    "title": "小组作业",
    "section": "",
    "text": "每组3人，由组长填写在线问卷，提交分组信息：https://www.wjx.top/vm/e3AyWsR.aspx#"
  },
  {
    "objectID": "case.html#小组作业",
    "href": "case.html#小组作业",
    "title": "小组作业",
    "section": "小组作业",
    "text": "小组作业\n\n选取自己感兴趣的问题，收集数据，运用第4-9章的方法分析数据，提炼研究结论。\n第12周汇报，每组不超过10分钟。\n提交文件：汇报PDF文档，R项目文件(含代码，数据文件等)"
  },
  {
    "objectID": "case.html#第6周讨论课安排",
    "href": "case.html#第6周讨论课安排",
    "title": "小组作业",
    "section": "第6周讨论课安排",
    "text": "第6周讨论课安排\n\n讨论课前准备\n\n数据要求：将数据导入R。\n运用第4-6章方法。\n遇到的问题和困难。\n请带笔记本电脑。\n\n\n\n发言时间表和讨论时间表(见QQ群文件)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "多元统计25秋",
    "section": "",
    "text": "欢迎访问《多元统计》课程网站！"
  },
  {
    "objectID": "index.html#教材",
    "href": "index.html#教材",
    "title": "多元统计25秋",
    "section": "教材",
    "text": "教材\n\n多元统计分析——基于R（第2版，费宇，中国人民大学出版社）.\n下载教材配套数据文件(QQ课程群)"
  },
  {
    "objectID": "index.html#软件准备",
    "href": "index.html#软件准备",
    "title": "多元统计25秋",
    "section": "软件准备",
    "text": "软件准备\nR和R Studio的下载\nR和RStudio的安装\n若无法安装R和R Studio, 请观看：\n不用安装就能用的RStudio——RStudio Cloud"
  },
  {
    "objectID": "index.html#r基础",
    "href": "index.html#r基础",
    "title": "多元统计25秋",
    "section": "R基础",
    "text": "R基础\nR语言与统计应用课程网站"
  },
  {
    "objectID": "index.html#参考书",
    "href": "index.html#参考书",
    "title": "多元统计25秋",
    "section": "参考书",
    "text": "参考书\n下载"
  },
  {
    "objectID": "index.html#教学视频",
    "href": "index.html#教学视频",
    "title": "多元统计25秋",
    "section": "教学视频",
    "text": "教学视频\nR数据分析实战"
  },
  {
    "objectID": "index.html#教学平台",
    "href": "index.html#教学平台",
    "title": "多元统计25秋",
    "section": "教学平台",
    "text": "教学平台\n\nQQ群：提交作业，提问答疑\n\n91速课(https://www.91suke.com)：发布作业，提交作业，测验，考勤等\n在91速课中设置姓名和学号的方法"
  },
  {
    "objectID": "index.html#课程考核",
    "href": "index.html#课程考核",
    "title": "多元统计25秋",
    "section": "课程考核",
    "text": "课程考核\n\n平时成绩：50%\n\n个人作业：15%\n小组作业(案例分析)：20%\n测验：10%\n考勤： 5%\n\n期末考查：课程论文 50%\n\n\n\n\n\nclick here"
  },
  {
    "objectID": "kmodesR.html",
    "href": "kmodesR.html",
    "title": "K-modes & K-prototypes R代码",
    "section": "",
    "text": "点击下载数据文件: supermarket.xlsx \n\n加载必要的包\n\n#install.packages(\"klaR\")\nlibrary(klaR)\nlibrary(tidyverse)\nlibrary(readr)\n\n\n\n导入数据并预处理\n\n重命名\n将定量变量转成factor\n剔除含有缺失值的个案\n将tibble转成data.frame\n\n\n# 读取数据\nlibrary(readxl)\nsupermarket &lt;- read_excel(\"supermarket.xlsx\")\n\n# 数据预处理\nsupermarket &lt;- supermarket %&gt;%\n  rename(Marital = `Marital status`, Settlement = `Settlement size`) %&gt;%\n  mutate(\n    Age_group = cut(Age, breaks = c(0,20,30,40,50,60,70,80), right = FALSE, \n                    labels = c(\"[0,20)\",\"[20,30)\", \"[30,40)\", \"[40,50)\", \"[50,60)\", \"[60,70)\", \"[70,80)\")),\n    Income_group = cut(Income, breaks = c(0, 50000, 100000, 150000, 200000, 250000, 300000, 350000), \n                       right = FALSE, labels = c(\"[0,50k)\", \"[50k,100k)\", \"[100k,150k)\", \"[150k,200k)\", \n                                                 \"[200k,250k)\", \"[250k,300k)\", \"[300k,350k+)\"))\n  ) %&gt;%\n  select(Sex, Marital, Age_group, Education, Income_group, Occupation, Settlement) %&gt;%\n  mutate(across(.cols = everything(), .fns = as.factor)) %&gt;%\n  na.omit() %&gt;% \n  as.data.frame()\n\n\n\n重新命名因子水平\n\nsupermarket$Sex &lt;- factor(supermarket$Sex, levels = c(0, 1), labels = c(\"Male\", \"Female\"))\nsupermarket$Marital &lt;- factor(supermarket$Marital, levels = c(0, 1), labels = c(\"Single\", \"Non-single\"))\nsupermarket$Education &lt;- factor(supermarket$Education, levels = c(0, 1, 2, 3), \n                                labels = c(\"Other/Unknown\", \"High School\", \"University\", \"Graduate School\"))\nsupermarket$Occupation &lt;- factor(supermarket$Occupation, levels = c(0, 1, 2), \n                                 labels = c(\"Unemployed/Unskilled\", \"Skilled Employee/Official\", \n                                            \"Management/Self-employed/Highly Qualified\"))\nsupermarket$Settlement &lt;- factor(supermarket$Settlement, levels = c(0, 1, 2), \n                                 labels = c(\"Small City\", \"Mid-sized City\", \"Big City\"))\n\n\n\n使用kmodes函数进行聚类分析\nkmodes() 是一种 基于随机初始化簇中心的聚类算法。\n每次运行时，初始簇中心是随机选择的，所以可能得到不同的聚类结果。\n使用 set.seed(123) 可以固定随机数生成器的状态，保证每次运行结果一致（可重复）。\n\nset.seed(123)\nkmodes_result &lt;- kmodes(supermarket, modes = 4, iter.max = 10)\n\n# 保存聚类结果\nsupermarket$Cluster &lt;- as.factor(kmodes_result$cluster)\n\n\n\n查看聚类结果\n\n# 查看每个聚类的众数\nkmodes_result$modes\n\n     Sex    Marital Age_group   Education Income_group\n1   Male     Single   [30,40) High School   [50k,100k)\n2 Female Non-single   [20,30) High School  [100k,150k)\n3 Female Non-single   [50,60)  University  [150k,200k)\n4   Male     Single   [30,40) High School  [100k,150k)\n                 Occupation     Settlement\n1      Unemployed/Unskilled     Small City\n2 Skilled Employee/Official     Small City\n3 Skilled Employee/Official Mid-sized City\n4 Skilled Employee/Official Mid-sized City\n\n# 查看每个观测值的聚类分配\n# kmodes_result$cluster\n# 查看每个聚类的大小\nkmodes_result$size\n\ncluster\n  1   2   3   4 \n434 719 172 675 \n\n# 查看每个聚类的分布\ntable(supermarket$Cluster)\n\n\n  1   2   3   4 \n434 719 172 675 \n\n\n\n\n概括每个类别的特征\n\ncluster_summary &lt;- supermarket %&gt;%\n  group_by(Cluster) %&gt;%\n  summarise(\n    Sex = names(which.max(table(Sex))),\n    Marital = names(which.max(table(Marital))),\n    Age_group = names(which.max(table(Age_group))),\n    Education = names(which.max(table(Education))),\n    Income_group = names(which.max(table(Income_group))),\n    Occupation = names(which.max(table(Occupation))),\n    Settlement = names(which.max(table(Settlement))),\n    Size = n()\n  )\n\n# 输出簇特征\ncluster_summary\n\n# A tibble: 4 × 9\n  Cluster Sex    Marital  Age_group Education Income_group Occupation Settlement\n  &lt;fct&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;     \n1 1       Male   Single   [30,40)   High Sch… [50k,100k)   Unemploye… Small City\n2 2       Female Non-sin… [20,30)   High Sch… [100k,150k)  Skilled E… Small City\n3 3       Female Non-sin… [50,60)   Universi… [150k,200k)  Skilled E… Mid-sized…\n4 4       Male   Single   [30,40)   High Sch… [100k,150k)  Skilled E… Mid-sized…\n# ℹ 1 more variable: Size &lt;int&gt;\n\n\n\n\n可视化聚类结果\n\n# 可视化：年龄组和收入组的簇分布\nggplot(supermarket, aes(x = Age_group, fill = Cluster)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Age Group Distribution by Cluster\", x = \"Age Group\", y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\nggplot(supermarket, aes(x = Income_group, fill = Cluster)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Income Group Distribution by Cluster\", x = \"Income Group\", y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n解释聚类结果\n\n簇1：主要为年轻（[20,30)）、单身男性，高中教育，低收入（[0,50k)），失业/无技能，居住在小城市。\n簇2：主要为中年（[30,40)）、已婚女性，大学教育，中等收入（[100k,150k)），熟练雇员，居住在中型城市。\n簇3：主要为老年（[50,60)）、已婚混合性别，大学/研究生教育，高收入（[150k,200k)），高素质职业，居住在大城市。\n簇4：可能为过渡群体，例如中年单身，高中/大学教育，中等收入，混合职业和居住地。\n\n\n\nk-prototypes 聚类分析\n\n# 指定图形的中文字体\npar(family  = 'STKaiti')\n#install.packages(\"showtext\")\nlibrary(showtext)\nshowtext_auto()\n\nlibrary(clustMixType)\n\n# 读取数据\nsupermarket &lt;- read_csv(\"supermarket.csv\")\n\n# 数据预处理\n# 读取数据\nsupermarket &lt;- read_csv(\"supermarket.csv\")\n\n# 数据预处理\nsupermarket &lt;- supermarket %&gt;%\n  rename(Marital = `Marital status`, Settlement = `Settlement size`) %&gt;%\n  select(Sex, Marital, Education, Occupation, Settlement, Income, Age) %&gt;%\n  mutate(across(c(Sex, Marital, Education, Occupation, Settlement), \n                as.factor)) %&gt;%\n  na.omit() %&gt;% \n  as.data.frame()\n\n# 设置随机种子\nset.seed(123)\n\n# 选择混合类型变量\nmix_data &lt;- supermarket %&gt;%\n  select(Age, Income, Sex, Marital, Education, Occupation, Settlement)\n\n# 运行 k-prototypes 聚类，设定 4 个簇\nkproto_result &lt;- kproto(mix_data, k = 4, verbose = TRUE)\n\n# NAs in variables:\n       Age     Income        Sex    Marital  Education Occupation Settlement \n         0          0          0          0          0          0          0 \n0 observation(s) with NAs.\n\nEstimated lambda: 1357318162 \n\n# 查看聚类中心\nkproto_result$centers\n\n       Age   Income Sex Marital Education Occupation Settlement\n1 31.69527 101157.4   1       1         1          1          0\n2 43.93720 197277.5   0       1         1          2          1\n3 36.19811 104039.5   0       0         1          1          0\n4 39.33551 140742.7   0       0         1          1          2\n\n# 每个样本的簇标签\nhead(kproto_result$cluster)\n\n1 2 3 4 5 6 \n4 4 3 4 4 4 \n\n# 各簇样本数量\ntable(kproto_result$cluster)\n\n\n  1   2   3   4 \n804 207 530 459 \n\n# 将簇标签添加到原始数据\nsupermarket$Cluster &lt;- as.factor(kproto_result$cluster)\n\n\n# 1️⃣ 数值变量在各簇的均值\nnum_summary &lt;- supermarket %&gt;%\n  group_by(Cluster) %&gt;%\n  summarise(\n    Mean_Age = mean(Age),\n    Mean_Income = mean(Income),\n    .groups = \"drop\"\n  )\nprint(num_summary)\n\n# A tibble: 4 × 3\n  Cluster Mean_Age Mean_Income\n  &lt;fct&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n1 1           31.7     101157.\n2 2           43.9     197277.\n3 3           36.2     104039.\n4 4           39.3     140743.\n\n# 2️⃣ 分类变量在各簇的分布\ncat_vars &lt;- c(\"Sex\",\"Marital\",\"Education\",\"Occupation\",\"Settlement\")\n\ncat_summary &lt;- supermarket %&gt;%\n  group_by(Cluster) %&gt;%\n  summarise(across(all_of(cat_vars), ~paste(names(sort(table(.), decreasing = TRUE))[1])), \n            .groups = \"drop\")\nprint(cat_summary)\n\n# A tibble: 4 × 6\n  Cluster Sex   Marital Education Occupation Settlement\n  &lt;fct&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;     \n1 1       1     1       1         1          0         \n2 2       0     1       1         2          1         \n3 3       0     0       1         1          0         \n4 4       0     0       1         1          2         \n\n# 3️⃣ 可视化各簇样本数量\ncluster_count &lt;- supermarket %&gt;%\n  count(Cluster)\n\nggplot(cluster_count, aes(x = Cluster, y = n, fill = Cluster)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"各簇样本数量\", x = \"簇编号\", y = \"样本数量\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n# 4️⃣ 可视化分类变量在各簇的分布（气泡图示例）\n# 将分类变量展开\nsupermarket_long &lt;- supermarket %&gt;%\n  pivot_longer(cols = all_of(cat_vars), names_to = \"Variable\", values_to = \"Category\")\n\nggplot(supermarket_long, aes(x = Variable, fill = Category)) +\n  geom_bar(position = \"fill\") +\n  facet_wrap(~Cluster) +\n  labs(title = \"各簇分类变量分布\", y = \"比例\", x = \"分类变量\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Pastel1\")"
  },
  {
    "objectID": "chap1.html",
    "href": "chap1.html",
    "title": "第1章",
    "section": "",
    "text": "Chap 1 讲义\nR Introduction\nR中的常用统计分析工具\n\nUseful links\n\nggplot2 Aesthetic specifications https://ggplot2.tidyverse.org/articles/ggplot2-specs.html\nHTML COLOR CODES https://htmlcolorcodes.com\nColors in R http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf"
  },
  {
    "objectID": "chap1.html#讨论题1",
    "href": "chap1.html#讨论题1",
    "title": "第1章",
    "section": "讨论题1",
    "text": "讨论题1\n阅读下述推文\n微信公众号狗熊会&gt;案例图书&gt;精品案例&gt;No.1探索性数据分析: 谁在看直播——基于RFM的粉丝聚类\n微信公众号狗熊会&gt;案例图书&gt;精品案例&gt;No4.机器学习:基于KNN的B站“哈尔滨旅游”视频热度分析\n1.1 数据来源？\n1.2 样本容量？\n1.3 研究中使用了哪些变量？\n1.4 使用了哪些统计方法？\n1.5 得出哪些有价值的结论？"
  },
  {
    "objectID": "chap1.html#学习素材",
    "href": "chap1.html#学习素材",
    "title": "第1章",
    "section": "学习素材",
    "text": "学习素材\n狗熊会(微信公众号) https://www.xiong99.com.cn/\nUCLA Data Analysis Examples https://stats.oarc.ucla.edu/other/dae/\nThe Data And Story Library https://dasl.datadescription.com/"
  },
  {
    "objectID": "chap1.html#数据库",
    "href": "chap1.html#数据库",
    "title": "第1章",
    "section": "数据库",
    "text": "数据库\nCSMAR 国泰安经济金融数据库 http://www.gtarsc.com/Home\n中国家庭追踪调查 CFPS http://www.isss.pku.edu.cn/cfps/\n中国家庭金融调查数据 CHFS https://chfs.swufe.edu.cn\n中国健康与养老数据追踪调查数据CHARLS http://charls.pku.edu.cn\n暨南大学社会调查中心 https://sdc-iesr.jnu.edu.cn\n Kaggle https://www.kaggle.com/"
  },
  {
    "objectID": "chap1.html#r相关",
    "href": "chap1.html#r相关",
    "title": "第1章",
    "section": "R相关",
    "text": "R相关\nCRAN Task Views https://cran.r-project.org/web/views/\nMost Downloaded R Packages https://www.r-pkg.org/\nRStudio Cloud https://rstudio.cloud/"
  },
  {
    "objectID": "4solutions.html",
    "href": "4solutions.html",
    "title": "4 聚类分析习题答案",
    "section": "",
    "text": "P75, textbook ex4.1\n将ex4.1.csv另存为ex4.1.xlsx，再导入。\n  点击下载数据文件: ex4.1.xlsx \n\n#安装包\n#install.packages(\"tidyverse\")\n#install.packages(\"dendextend\")\n#install.packages(\"cluster\")\n#install.packages(\"purrr\")\n#install.packages(\"readr\")\n#install.packages(\"readxl\")\n\n\n#导入数据\nlibrary(readxl)\nlibrary(tidyverse)\nex4_1 &lt;- read_excel(\"ex4.1.xlsx\") %&gt;% as.data.frame()\n\n#给数据框添加行名\nrownames(ex4_1) &lt;- ex4_1$brand\n\n# Agglomerative Nesting (Hierarchical Clustering)\n# 加载包cluster\nlibrary(cluster)\nex4_1.hc &lt;- agnes(ex4_1, # 数据框\n                     stand = TRUE, # 对变量进行标准化变换\n                     metric = \"euclidean\", # 个案之间的距离测度\n                     method = \"ward\" # 类间距离定义\n)\n\n#查看聚类模型\nex4_1.hc\n\nCall:    agnes(x = ex4_1, metric = \"euclidean\", stand = TRUE, method = \"ward\") \nAgglomerative coefficient:  0.8360097 \nOrder of objects:\n [1] Budweiser     Coors         Hamms         Heilemans-old Coorslicht   \n [6] Ionenbrau     Michelos-lich Aucsberger    Schlitz       Strchs-bohemi\n[11] Old-milnaukee Kronensourc   Heineken      Kkirin        Secrs        \n[16] Miller-lite   Schlite-light Sudeiser-lich Pabst-extral  Olympia-gold \nHeight (summary):\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.6316  1.4611  2.1845  3.1149  3.6032 10.7767 \n\nAvailable components:\n[1] \"order\"     \"height\"    \"ac\"        \"merge\"     \"diss\"      \"call\"     \n[7] \"method\"    \"order.lab\" \"data\"     \n\n#查看agglomerative coefficient聚合系数，越接近于1，代表聚类结构越强\nex4_1.hc$ac\n\n[1] 0.8360097\n\n#保存聚类结果\nex4_1$cluster &lt;- cutree(ex4_1.hc, k=3)\n\n\n#绘制树状图dendrogram\n# install.package(\"factoextra\")\nlibrary(factoextra)\n\nfviz_dend(ex4_1.hc)\n\n\n\n\n\n\n\nfviz_dend(ex4_1.hc, k= 3, cex = 0.6)\n\n\n\n\n\n\n\n\n\n# 自定义树状图分支及标签颜色、字体、添加矩形框\nfviz_dend(ex4_1.hc, \n          k = 3, # 分三类\n          cex = 0.7, # 标签字体\n          k_colors = c(4,5,6),#分支颜色\n          color_labels_by_k = TRUE, # 标签上色\n          rect = TRUE, # 添加矩形框 \n          rect_fill = TRUE, #矩形框底色\n          lower_rect = -6, #矩形框下沿\n          lwd = 1.2, #线条宽度\n          ggtheme = theme_minimal() #主题色\n)\n\n\n\n\n\n\n\n# 圆形树状图\nfviz_dend(ex4_1.hc, \n          k = 3, # 分三类\n          cex = 0.5, # 标签字体\n          k_colors = c(4,5,6),#分支颜色\n          color_labels_by_k = TRUE, # 标签上色\n          lwd = 1.2, #线条宽度\n          type = \"circular\", #圆形\n          ggtheme = theme_gray() #主题\n)\n\n\n\n\n\n\n\n# 支流树状图\nfviz_dend(ex4_1.hc, \n          k = 3, # 分三类\n          cex = 0.7, # 标签字体\n          k_colors = c(4,5,6),#分支颜色\n          color_labels_by_k = TRUE, # 标签上色\n          type = \"phylogenic\", # 支流\n          ggtheme = theme_bw() #主题\n)\n\n\n\n\n\n\n\n\n\ndend.ward &lt;- ex4_1 %&gt;% \n  select(热量:价格) %&gt;% \n  scale() %&gt;% \n  dist() %&gt;% \n  hclust(\"ward.D\")%&gt;% \n  as.dendrogram()\n\n\ndend.average &lt;- ex4_1 %&gt;% \n  select(热量:价格) %&gt;% \n  scale() %&gt;% \n  dist() %&gt;% \n  hclust(\"average\") %&gt;% \n  as.dendrogram() \n\n\nlibrary(dendextend)\ntanglegram(dend.ward,dend.average,\n           k_labels = 3,\n           k_branches = 3,\n           main_left = \"ward.D linkage\",\n           main_right = \"average linkage\",\n           sort = T,\n           margin_inner = 6,\n           type = \"t\",\n           highlight_distinct_edges = F,\n           highlight_branches_lwd = F,\n           main = paste(\"entanglement =\", \n                        round(entanglement(\n                          dend.ward,dend.average), 2)),\n           cex_main = 1.2\n)\n\n\n\n\n\n\n\n\n\n#完全一致的分类结果，缠绕系数等于0\ndend.ward2 &lt;- ex4_1 %&gt;% \n  select(热量:价格) %&gt;% \n  scale() %&gt;% \n  dist() %&gt;% \n  hclust(\"ward.D2\") %&gt;% \n  as.dendrogram() \n\ntanglegram(dend.ward,dend.ward2,\n           k_labels = 3,\n           k_branches = 3,\n           main_left = \"Ward.D Linkage\",\n           main_right = \"Ward.D2 Linkage\",\n           margin_inner = 6,\n           highlight_distinct_edges = F,\n           highlight_branches_lwd = F,\n           main = paste(\"entanglement =\", \n                        round(entanglement(\n                          dend.ward,dend.ward2,), 2)),\n           cex_main = 1.2\n)\n\n\n\n\n\n\n\n\n\n\nP75, textbook ex4.3\n  点击下载数据文件: ex4.3.xlsx \n\n#避免ex4.3.csv导入时汉字会变乱码的问题\n#在Excel中将教材配套的ex4.3.csv另存为ex4.3.xlsx\n#导入\"ex4.3.xlsx\"文件\nlibrary(readxl)\nlibrary(tidyverse)\n\nex4_3 &lt;- read_excel(\"ex4.3.xlsx\") %&gt;% \n  as.data.frame() %&gt;% #保存为数据框\n  rename(city = ...1, so2 = x1, no2 = x2, pm10 = x3,\n         co = x4, o3 = x5, pm2.5 = x6, good = x7)\n\nNew names:\n• `` -&gt; `...1`\n\n#创建数据框elbow, 9行2列，列名分别为k和tot_withinss\n#用于存放分类数k，分2-10类\n#以及within-group sum of squares（tot_withinss），组内平方和\n#用于绘制elbow plot, tot_withinss下降最快处，即K值\n\nelbow &lt;- data.frame(matrix(ncol = 2, nrow = 9))\ncolnames(elbow) &lt;- c('k', 'tot_withinss')\n\n#K均值聚类,k= 2,3,4,5,6,..10\nfor (i in (2:10)) {\n  ex4_3_kmeans &lt;- \n    ex4_3 %&gt;%\n    select(so2:good) %&gt;% \n    scale() %&gt;% \n    kmeans(centers = i)\n  ex4_3[, paste0(\"cluster\",i)] &lt;- ex4_3_kmeans$cluster\n  print(paste(\"Number of Clusters:\", i))\n  print(ex4_3_kmeans$tot.withinss)\n  print(table(ex4_3_kmeans$cluster))\n  elbow[i-1,1] &lt;- i\n  elbow[i-1,2] &lt;- ex4_3_kmeans$tot.withinss\n}\n\n[1] \"Number of Clusters: 2\"\n[1] 425.6854\n\n 1  2 \n65 48 \n[1] \"Number of Clusters: 3\"\n[1] 307.9599\n\n 1  2  3 \n56 22 35 \n[1] \"Number of Clusters: 4\"\n[1] 258.7375\n\n 1  2  3  4 \n44 27 17 25 \n[1] \"Number of Clusters: 5\"\n[1] 222.7558\n\n 1  2  3  4  5 \n26 22 32 16 17 \n[1] \"Number of Clusters: 6\"\n[1] 195.3154\n\n 1  2  3  4  5  6 \n26 15 18 26 11 17 \n[1] \"Number of Clusters: 7\"\n[1] 182.1412\n\n 1  2  3  4  5  6  7 \n20 28  7  7 25 10 16 \n[1] \"Number of Clusters: 8\"\n[1] 171.5312\n\n 1  2  3  4  5  6  7  8 \n11 20 16 16 18  9 12 11 \n[1] \"Number of Clusters: 9\"\n[1] 157.6378\n\n 1  2  3  4  5  6  7  8  9 \n16 17 10  5 20  6 16  5 18 \n[1] \"Number of Clusters: 10\"\n[1] 148.2836\n\n 1  2  3  4  5  6  7  8  9 10 \n10 10  7 17 13  8 15  6  6 21 \n\n\n\n# Plot the elbow plot\nggplot(elbow, aes(k, tot_withinss)) +\n  geom_line() +\n  scale_x_continuous(breaks = 1:10)\n\n\n\n\n\n\n\n#分3类\ntable(ex4_3$cluster3)\n\n\n 1  2  3 \n56 22 35 \n\n#列出每组有哪些城市\nfor (i in 1:3) {\n  print(ex4_3$city[ex4_3$cluster3 == i]) \n}\n\n [1] \"北京\"     \"秦皇岛\"   \"大同\"     \"呼和浩特\" \"包头\"     \"沈阳\"    \n [7] \"鞍山\"     \"抚顺\"     \"锦州\"     \"长春\"     \"吉林\"     \"哈尔滨\"  \n[13] \"上海\"     \"南京\"     \"无锡\"     \"常州\"     \"苏州\"     \"南通\"    \n[19] \"连云港\"   \"扬州\"     \"镇江\"     \"杭州\"     \"湖州\"     \"绍兴\"    \n[25] \"合肥\"     \"芜湖\"     \"马鞍山\"   \"南昌\"     \"青岛\"     \"枣庄\"    \n[31] \"潍坊\"     \"济宁\"     \"日照\"     \"开封\"     \"三门峡\"   \"武汉\"    \n[37] \"宜昌\"     \"荆州\"     \"长沙\"     \"株洲\"     \"湘潭\"     \"广州\"    \n[43] \"重庆\"     \"成都\"     \"自贡\"     \"泸州\"     \"德阳\"     \"南充\"    \n[49] \"宜宾\"     \"铜川\"     \"宝鸡\"     \"延安\"     \"兰州\"     \"西宁\"    \n[55] \"石嘴山\"   \"乌鲁木齐\"\n [1] \"天津\"   \"石家庄\" \"唐山\"   \"邯郸\"   \"保定\"   \"太原\"   \"阳泉\"   \"长治\"  \n [9] \"临汾\"   \"徐州\"   \"济南\"   \"淄博\"   \"泰安\"   \"郑州\"   \"洛阳\"   \"平顶山\"\n[17] \"安阳\"   \"焦作\"   \"西安\"   \"咸阳\"   \"渭南\"   \"银川\"  \n [1] \"赤峰\"     \"大连\"     \"本溪\"     \"齐齐哈尔\" \"牡丹江\"   \"宁波\"    \n [7] \"温州\"     \"福州\"     \"厦门\"     \"泉州\"     \"九江\"     \"烟台\"    \n[13] \"岳阳\"     \"常德\"     \"张家界\"   \"韶关\"     \"深圳\"     \"珠海\"    \n[19] \"汕头\"     \"湛江\"     \"南宁\"     \"柳州\"     \"桂林\"     \"北海\"    \n[25] \"海口\"     \"攀枝花\"   \"绵阳\"     \"贵阳\"     \"遵义\"     \"昆明\"    \n[31] \"曲靖\"     \"玉溪\"     \"拉萨\"     \"金昌\"     \"克拉玛依\"\n\nclusterdf &lt;- data.frame(matrix(ncol = 2, nrow = 3))\ncolnames(clusterdf) &lt;- c('cluster', 'area')\n\nfor(i in 1:3){\n  clusterdf[i,1] = i\n  clusterdf[i,2] = \n    paste(ex4_3$city[ex4_3$cluster3 == i],collapse = \",\")\n}\n\nclusterdf %&gt;% \n  as_tibble() %&gt;% \n  view()\n\n\n#计算各组污染指标的均值\nex4_3 %&gt;% \n  select(so2:good, cluster3) %&gt;% \n  group_by(cluster3) %&gt;% \n  summarise_all(list(mean)) %&gt;% \n  arrange(desc(good)) #descending\n\n# A tibble: 3 × 8\n  cluster3   so2   no2  pm10    co    o3 pm2.5  good\n     &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1        3  14.2  26.5  58.7  1.37  135.  34.2  329.\n2        1  19.8  40.6  83.9  1.80  163.  49.4  257.\n3        2  32.9  48.3 122.   2.81  196.  69.2  176.\n\n#绘制各组污染指标的箱线图\nfor(i in 2:8){\n  print(\n    ggplot(ex4_3, aes(ex4_3[,i], col = 1,\n                      fill = factor(cluster3)))+\n      geom_boxplot()+\n      facet_wrap(~cluster3,ncol = 1)+\n      labs(x = colnames(ex4_3)[i]))\n  Sys.sleep(1) #图片切换的时长\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow = c(2,4),mai = c(0.6,0.6,0.2,0.1),cex = 0.7)\nfor (i in 2:8) {\n  y &lt;- ex4_3[[i]]\n  boxplot(y ~ ex4_3$cluster3, col = c(3,4,5),\n          main = colnames(ex4_3)[i])\n}\n\n\n\n\n\n\n\n\n\n#绘制各组污染指标的直方图\n\nfor(i in 2:8){\n  print(\n    ggplot(ex4_3, aes(ex4_3[,i], col = 1,\n                      fill = factor(cluster3)))+\n      geom_histogram()+\n      facet_wrap(~cluster3,ncol = 1)+\n      labs(x = colnames(ex4_3)[i]))\n  Sys.sleep(1)\n}\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`."
  },
  {
    "objectID": "pcaR.html",
    "href": "pcaR.html",
    "title": "6 PCA在R中的实现",
    "section": "",
    "text": "本章介绍R中的主成分分析。"
  },
  {
    "objectID": "pcaR.html#kmo",
    "href": "pcaR.html#kmo",
    "title": "6 PCA在R中的实现",
    "section": "1.1 KMO",
    "text": "1.1 KMO\n\nlibrary(psych)\nKMO(eg6_1)\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = eg6_1)\nOverall MSA =  0.8\nMSA for each item = \n数学 物理 化学 语文 历史 英语 \n0.80 0.83 0.76 0.84 0.81 0.78"
  },
  {
    "objectID": "pcaR.html#bartletts-test",
    "href": "pcaR.html#bartletts-test",
    "title": "6 PCA在R中的实现",
    "section": "1.2 Bartlett’s Test",
    "text": "1.2 Bartlett’s Test\n\nbartlett.test(eg6_1)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  eg6_1\nBartlett's K-squared = 13.025, df = 5, p-value = 0.02315"
  },
  {
    "objectID": "pcaR.html#相关图-variable-correlation-circle",
    "href": "pcaR.html#相关图-variable-correlation-circle",
    "title": "6 PCA在R中的实现",
    "section": "5.1 相关图 variable correlation circle",
    "text": "5.1 相关图 variable correlation circle\n\n用于理解主成分与原始变量的关系、概括主成分的含义\n正相关的变量指向一个方向\n负相关的变量指向相反的方向\n原始变量的箭头长度(cos2)越长（越接近圆圈），代表该变量对主成分的贡献越大。\n原始变量的箭头长度越短（越接近圆心），代表该变量对主成分的贡献越小。\n\n\nlibrary(factoextra)\n\neg6_1.pr &lt;- prcomp(eg6_1, scale = TRUE)\n\neg6_1.pr$rotation[,1:2] #查看前两个主成分的载荷\n\n            PC1       PC2\n数学  0.4120520 0.3759773\n物理  0.3811779 0.3567060\n化学  0.3321347 0.5626165\n语文 -0.4611846 0.2785231\n历史 -0.4205876 0.4147836\n英语 -0.4301372 0.4065022\n\n\ncos2越高，代表主成分对该原始变量的代表性越好\n\nfviz_pca_var(eg6_1.pr, \n             col.var = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\") , \n             repel = TRUE # Avoid text overlapping\n)"
  },
  {
    "objectID": "pcaR.html#主成分得分",
    "href": "pcaR.html#主成分得分",
    "title": "6 PCA在R中的实现",
    "section": "5.2 主成分得分",
    "text": "5.2 主成分得分\n\nlibrary(factoextra)\n\nfviz_pca_ind(eg6_1.pr)\n\n\n\n\n\n\n\n#不要遮挡标签\nfviz_pca_ind(eg6_1.pr, repel = TRUE)\n\n\n\n\n\n\n\n\n\n#给点加上颜色，第1主成分得分映射颜色\n#查看第1主成分得分低或者得分高的个案，理解第一主成分的含义\nfviz_pca_ind(eg6_1.pr, \n             repel = TRUE,\n             col.ind = eg6_1.pr$x[,1])\n\n\n\n\n\n\n\n#给点加上颜色，第2主成分得分映射颜色\nfviz_pca_ind(eg6_1.pr, repel = TRUE,\n             col.ind = eg6_1.pr$x[,2])"
  },
  {
    "objectID": "nfl.html",
    "href": "nfl.html",
    "title": "NFL球员PCA分析",
    "section": "",
    "text": "install.packages(\"tidyverse\")\ninstall.packages(\"factoextra\")\ninstall.packages(\"MASS\")\ninstall.packages(\"psych\")"
  },
  {
    "objectID": "nfl.html#不同位置球员的主成分得分比较",
    "href": "nfl.html#不同位置球员的主成分得分比较",
    "title": "NFL球员PCA分析",
    "section": "不同位置球员的主成分得分比较",
    "text": "不同位置球员的主成分得分比较\n\n# 绘制PC1主成分得分按位置分组的箱线图\ncombine.pcscore %&gt;%\n  ggplot(aes(x = fct_reorder(position, PC1, .fun = median, .desc = TRUE), \n             y = PC1, fill = position)) +\n  scale_fill_brewer(palette = \"Set3\") +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"不同位置球员PC1主成分得分分布\", x = \"position\", y = \"PC1得分\")\n\n\n\n\n\n\n\n# 绘制PC2主成分得分按位置分组的箱线图\ncombine.pcscore %&gt;%\n  ggplot(aes(x = fct_reorder(position, PC2, .fun = median, .desc = TRUE), \n             y = PC2, fill = position)) +\n  scale_fill_brewer(palette = \"Pastel1\") +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"不同位置球员PC2主成分得分分布\", y = \"PC2得分\")\n\n\n\n\n\n\n\n\n\n# 方差分析：不同位置的PC1得分是否有显著差异\nanova_pc1 &lt;- aov(PC1 ~ position, data = combine.pcscore)\nsummary(anova_pc1)\n\n              Df Sum Sq Mean Sq F value Pr(&gt;F)    \nposition      19  14133   743.9    1046 &lt;2e-16 ***\nResiduals   2865   2037     0.7                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# 方差分析：不同位置的PC2得分是否有显著差异\nanova_pc2 &lt;- aov(PC2 ~ position, data = combine.pcscore)\nsummary(anova_pc2)\n\n              Df Sum Sq Mean Sq F value Pr(&gt;F)    \nposition      19  497.8  26.198   38.33 &lt;2e-16 ***\nResiduals   2865 1958.1   0.683                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "nfl.html#基于主成分得分的聚类分析",
    "href": "nfl.html#基于主成分得分的聚类分析",
    "title": "NFL球员PCA分析",
    "section": "基于主成分得分的聚类分析",
    "text": "基于主成分得分的聚类分析\n\n# k-means聚类（以2类为例）\nset.seed(123)\nkm &lt;- kmeans(combine.pcscore[, c(\"PC1\", \"PC2\")], centers = 3)\ncombine.pcscore$cluster &lt;- as.factor(km$cluster)\n\n# 可视化聚类结果\nggplot(combine.pcscore, aes(PC1, PC2, color = cluster)) +\n  geom_point() +\n  labs(title = \"基于主成分得分的球员聚类\")"
  },
  {
    "objectID": "nfl.html#聚类与位置的对应关系",
    "href": "nfl.html#聚类与位置的对应关系",
    "title": "NFL球员PCA分析",
    "section": "聚类与位置的对应关系",
    "text": "聚类与位置的对应关系\n\nprop.table(table(combine.pcscore$position, combine.pcscore$cluster), 1)\n\n      \n                 1           2           3\n  C    0.930434783 0.000000000 0.069565217\n  CB   0.000000000 0.996784566 0.003215434\n  DE   0.132616487 0.021505376 0.845878136\n  DT   0.790513834 0.000000000 0.209486166\n  EDGE 0.000000000 0.000000000 1.000000000\n  FB   0.051948052 0.116883117 0.831168831\n  FS   0.000000000 0.991869919 0.008130081\n  ILB  0.007692308 0.153846154 0.838461538\n  LB   0.000000000 1.000000000 0.000000000\n  LS   0.000000000 0.000000000 1.000000000\n  OG   0.969827586 0.000000000 0.030172414\n  OL   1.000000000 0.000000000 0.000000000\n  OLB  0.004166667 0.262500000 0.733333333\n  OT   0.945054945 0.000000000 0.054945055\n  QB   0.083333333 0.250000000 0.666666667\n  RB   0.000000000 0.881632653 0.118367347\n  S    0.000000000 1.000000000 0.000000000\n  SS   0.000000000 0.962616822 0.037383178\n  TE   0.051546392 0.061855670 0.886597938\n  WR   0.000000000 0.956363636 0.043636364\n\n\n\n1号聚类（Cluster 1）\n\n主要特征： 高度集中于内线和进攻线球员： OL（进攻线）: 100% OG（进攻护锋）: 97% OT（进攻截锋）: 95% C（中锋）: 93% DT（防守截锋）: 79%\n这些位置典型特征是体型大、力量强，符合PCA能力分型的“体型/力量主导”类别。\n\n2号聚类（Cluster 2）\n\n主要特征： 集中于速度型和二线防守球员： CB（角卫）: 99.7% FS（游动安全卫）: 99% LB（线卫）: 100% S（安全卫）: 100% SS（强侧安全卫）: 96% WR（外接手）: 96% RB（跑卫）: 88%\n这些位置通常身材相对较小，速度、灵活性、爆发力强，对应“敏捷/速度主导”能力分型。\n\n3号聚类（Cluster 3）\n\n主要特征： 集中于力量+爆发型或多面手球员： EDGE（冲传手）: 100% LS（长传手）: 100% DE（防守端锋）: 85% FB（近卫跑卫）: 83% ILB（内线卫）: 84% OLB（外线卫）: 73% TE（近端锋）: 89% QB（四分卫）: 67% DE、FB、TE、QB、OLB、ILB等为多功能或力量/爆发型球员，显示这些球员的身体素质在主成分空间中更接近第三类。\n这些位置球员兼具力量、体型和一定灵活性，属于“力量/多面手型”分型。"
  },
  {
    "objectID": "chap4.html",
    "href": "chap4.html",
    "title": "第4章",
    "section": "",
    "text": "系统聚类和Kmeans聚类 讲义\n系统聚类和K-means聚类 R代码\nK-modes & K-prototypes 聚类讲义\nK-modes & K-prototypes R代码"
  },
  {
    "objectID": "chap4.html#题目1",
    "href": "chap4.html#题目1",
    "title": "第4章",
    "section": "题目1",
    "text": "题目1"
  },
  {
    "objectID": "chap4.html#拓展资源",
    "href": "chap4.html#拓展资源",
    "title": "第4章",
    "section": "拓展资源",
    "text": "拓展资源\n如何从中国知网下载统计数据？\n八爪鱼客户端抓取网页数据？\n如何用Excel整理提取的网页数据？"
  },
  {
    "objectID": "decathlon.html",
    "href": "decathlon.html",
    "title": "十项全能运动员判别分析",
    "section": "",
    "text": "install.packages(\"ggplot2\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"MASS\")\ninstall.packages(\"klaR\")\ninstall.packages(\"devtools\")\ninstall.packages(\"psych\")\ninstall.packages(\"MVN\")\ninstall.packages(\"biotools\")"
  },
  {
    "objectID": "decathlon.html#判别函数得分直方图",
    "href": "decathlon.html#判别函数得分直方图",
    "title": "十项全能运动员判别分析",
    "section": "判别函数得分直方图",
    "text": "判别函数得分直方图\n\nldahist(model.predict$x[,1], model.predict$class)\n\n\n\n\n\n\n\nldahist(model.predict$x[,2], model.predict$class)"
  },
  {
    "objectID": "decathlon.html#标记错误的个案",
    "href": "decathlon.html#标记错误的个案",
    "title": "十项全能运动员判别分析",
    "section": "标记错误的个案",
    "text": "标记错误的个案\n\ndecathlon$right &lt;- decathlon$tier == decathlon$predict\n\n\nwrong_cases &lt;- decathlon %&gt;% \n  filter(decathlon$right == FALSE)\n\nwrong_cases\n\n# A tibble: 10 × 27\n    rank COMPETITOR         `year of birth`   Age Nationality country  Continent\n   &lt;dbl&gt; &lt;chr&gt;                        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;    \n 1    32 Martin ROE                    1992    27 NOR         Norway   Europe   \n 2    54 Akihiko NAKAMURA              1990    29 JPN         Japan    Asia     \n 3    60 Ludovic BESSON                1998    21 FRA         France   Europe   \n 4    65 Makenson GLETTY               1999    20 FRA         France   Europe   \n 5    70 John LANE                     1989    30 GBR         United … Europe   \n 6    71 Rik TAAM                      1997    22 NED         netherl… Europe   \n 7    72 Nick GUERRANT                 1999    20 USA         United … North am…\n 8    82 Kazuya KAWASAKI               1992    27 JPN         Japan    Asia     \n 9    85 Elmo SAVOLA                   1995    24 FIN         Finland  Europe   \n10    92 Aleksandar GRNOVIC            1996    23 SRB         Serbia   Europe   \n# ℹ 20 more variables: Continent_code &lt;dbl&gt;, continent_G3 &lt;dbl&gt;,\n#   continent_G4 &lt;dbl&gt;, VENUE &lt;chr&gt;, MARK &lt;dbl&gt;, M100 &lt;dbl&gt;,\n#   Hurdles_M100 &lt;dbl&gt;, M400 &lt;dbl&gt;, M1500 &lt;dbl&gt;, long_jump &lt;dbl&gt;,\n#   high_jump &lt;dbl&gt;, pole_vault &lt;dbl&gt;, shot_put &lt;dbl&gt;, discus_thow &lt;dbl&gt;,\n#   javelin_throw &lt;dbl&gt;, tier &lt;chr&gt;, predict &lt;fct&gt;, ld1 &lt;dbl&gt;, ld2 &lt;dbl&gt;,\n#   right &lt;lgl&gt;\n\ndecathlon %&gt;% ggplot(aes(ld1, ld2, col = tier))+\n  geom_point()+\n  geom_point(data = wrong_cases,\n             aes(ld1, ld2),\n             col = \"red\", alpha = 0.6)+\n  ylim(-5,5)+\n  xlim(-5,5)"
  },
  {
    "objectID": "decathlon.html#判别函数得分散点图按类别着色",
    "href": "decathlon.html#判别函数得分散点图按类别着色",
    "title": "十项全能运动员判别分析",
    "section": "判别函数得分散点图，按类别着色",
    "text": "判别函数得分散点图，按类别着色\n\nlibrary(ggord)\nggord(model, decathlon$tier)"
  },
  {
    "objectID": "chap5.html",
    "href": "chap5.html",
    "title": "第5章",
    "section": "",
    "text": "Chap 5 LDA讲义\nLDA R代码\n十项全能运动员LDA R代码\nL5 SVM讲义\nSVM在R中的实现"
  },
  {
    "objectID": "chap5.html#教材p88例题5.2",
    "href": "chap5.html#教材p88例题5.2",
    "title": "第5章",
    "section": "教材P88,例题5.2",
    "text": "教材P88,例题5.2\n要求：\n\n报告教材P88-101的所有输出结果。"
  },
  {
    "objectID": "chap5.html#教材p98例题5.5",
    "href": "chap5.html#教材p98例题5.5",
    "title": "第5章",
    "section": "教材P98,例题5.5",
    "text": "教材P98,例题5.5\n要求：只运用Fisher判别分析方法，不需要用距离判别和贝叶斯判别。报告教材P100-101的所有输出结果。"
  },
  {
    "objectID": "chap5.html#教材p104习题5.3",
    "href": "chap5.html#教材p104习题5.3",
    "title": "第5章",
    "section": "教材P104,习题5.3",
    "text": "教材P104,习题5.3\n注意：本题只需要运用Fisher判别分析\n要求：\n\n报告判别分析模型的输出结果。\n报告预测级别和实际级别的列联表。计算预测正确率。\n绘制单个判别函数得分的直方图。\n绘制判别函数得分两两之间的二维图形。"
  },
  {
    "objectID": "chap5.html#教材p105习题5.5",
    "href": "chap5.html#教材p105习题5.5",
    "title": "第5章",
    "section": "教材P105,习题5.5",
    "text": "教材P105,习题5.5\n要求：\n\n报告判别分析模型的输出结果，一共建立了几个判别函数，各个判别函数的贡献率是多大？\n判别函数预测的正确率是多少？报告预测信用等级和实际信用等级的列联表。\n绘制单个判别函数得分的直方图。\n绘制判别函数得分两两之间的二维图形。"
  },
  {
    "objectID": "quizsolution.html",
    "href": "quizsolution.html",
    "title": "Solutions to Quiz",
    "section": "",
    "text": "library(readxl)\nlibrary(tidyverse)\n\nmetro16 &lt;- read_excel(\"metro16.xlsx\") %&gt;% data.frame()\n\n#给metro16增加行名\nrownames(metro16) &lt;- metro16$城市\n\nmetro16\n\n     城市 线路数量 总里程公里 站点数 运营年数 日均客运量万人次\n广州 广州       14        513    271       23           905.75\n上海 上海       17        705    416       27          1065.03\n北京 北京       23        699    405       49          1241.10\n天津 天津        6        233    143       35           143.85\n杭州 杭州        5        206    120        7           190.00\n南京 南京       10        378    174       15           353.00\n成都 成都        8        358    215        9           382.99\n武汉 武汉        9        339    228       15           305.00\n深圳 深圳       10        284    134       15           486.00\n苏州 苏州        4        166    135        8            99.10\n郑州 郑州        5        146     96        6            79.85\n合肥 合肥        3         90     77        3            49.26\n青岛 青岛        4        176     86        4            51.50\n厦门 厦门        2         72     56        2            38.30\n南宁 南宁        3         81     66        4            58.52\n重庆 重庆       10        329    190       15           300.00\n\n\n\n\n\n\nlibrary(psych)\n\nmetro16 %&gt;% select(2:6) %&gt;% \n  describe() %&gt;% \n  select(mean, sd, median, min, max) \n\n                   mean     sd median  min    max\n线路数量           8.31   5.74    7.0  2.0   23.0\n总里程公里       298.44 199.17  258.5 72.0  705.0\n站点数           175.75 110.14  139.0 56.0  416.0\n运营年数          14.81  13.03   12.0  2.0   49.0\n日均客运量万人次 359.33 383.20  245.0 38.3 1241.1\n\n\n\n\n\n\n\n\n#设置图形排版，2行2列\npar(mfrow = c(2,2))\n\n#定义聚类方法\nmethod &lt;- c(\"complete\",\"single\",\"average\",\"ward.D\")\n\n#对比四种聚类方法的树状图\nlibrary(dendextend)\nfor (i in 1:4) {\n  metro16 %&gt;% \n    select(2:6) %&gt;% \n    scale() %&gt;% \n    dist() %&gt;% \n    hclust(method = method[i]) %&gt;% \n    as.dendrogram() %&gt;% \n    color_branches(k = 3) %&gt;% \n    plot(main = method[i])  \n}\n\n\n\n\n\n\n\n#保存聚类模型\nmetro16.ward &lt;- metro16 %&gt;% \n    select(2:6) %&gt;% \n    scale() %&gt;% \n    dist() %&gt;% \n    hclust(method = method[i])\n\n选择Ward.D方法，该方法下分为三类，个案数量分别为3，6，7，个案数量分布合理。\n\n\n\n\nlibrary(cluster)\nlibrary(factoextra)\n\nmetro16 %&gt;% select(2:6) %&gt;% \n    agnes(stand = TRUE, method = \"ward\") %&gt;% \n    fviz_dend(k = 3,  #分三类\n          cex = 0.6,  # 标签字体\n          k_colors = c(4,5,6), #分支颜色\n          color_labels_by_k = TRUE, #标签上色\n          rect = TRUE,  #添加矩形框\n          lower_rect = -2, \n          main = \"Linkage Method: Ward\")  #矩形框下沿\n\n\n\n\n\n\n\nmetro16.agnes &lt;- metro16 %&gt;% select(2:6) %&gt;% \n    agnes(stand = TRUE, method = \"ward\")\n\n选择了线路数量、总里程、站点数、运营年数和日均客运量五个变量进行聚类分析。采用了系统聚类方法，个案之间的距离用欧氏距离测度，类与类之间的距离用Ward法（离差平方和法）测度。对变量进行了标准化变换。\n\n\n\n\n\n#在metro16中追加变量cluster, 保存聚类结果\nmetro16$cluster &lt;- cutree(metro16.ward, k = 3)\n\n# 罗列各个类别包含的个案数量\ntable(metro16$cluster)\n\n\n1 2 3 \n3 6 7 \n\n#第一类\nmetro16$城市[metro16$cluster == 1]\n\n[1] \"广州\" \"上海\" \"北京\"\n\n#第二类\nmetro16$城市[metro16$cluster == 2]\n\n[1] \"天津\" \"南京\" \"成都\" \"武汉\" \"深圳\" \"重庆\"\n\n#第三类\nmetro16$城市[metro16$cluster == 3]\n\n[1] \"杭州\" \"苏州\" \"郑州\" \"合肥\" \"青岛\" \"厦门\" \"南宁\"\n\n\n\n\n\n\nlibrary(purrr)\n\nmetro16 %&gt;% \n  split(.$cluster) %&gt;% \n  map(summary)\n\n$`1`\n     城市              线路数量      总里程公里      站点数         运营年数 \n Length:3           Min.   :14.0   Min.   :513   Min.   :271.0   Min.   :23  \n Class :character   1st Qu.:15.5   1st Qu.:606   1st Qu.:338.0   1st Qu.:25  \n Mode  :character   Median :17.0   Median :699   Median :405.0   Median :27  \n                    Mean   :18.0   Mean   :639   Mean   :364.0   Mean   :33  \n                    3rd Qu.:20.0   3rd Qu.:702   3rd Qu.:410.5   3rd Qu.:38  \n                    Max.   :23.0   Max.   :705   Max.   :416.0   Max.   :49  \n 日均客运量万人次    cluster \n Min.   : 905.8   Min.   :1  \n 1st Qu.: 985.4   1st Qu.:1  \n Median :1065.0   Median :1  \n Mean   :1070.6   Mean   :1  \n 3rd Qu.:1153.1   3rd Qu.:1  \n Max.   :1241.1   Max.   :1  \n\n$`2`\n     城市              线路数量        总里程公里        站点数     \n Length:6           Min.   : 6.000   Min.   :233.0   Min.   :134.0  \n Class :character   1st Qu.: 8.250   1st Qu.:295.2   1st Qu.:150.8  \n Mode  :character   Median : 9.500   Median :334.0   Median :182.0  \n                    Mean   : 8.833   Mean   :320.2   Mean   :180.7  \n                    3rd Qu.:10.000   3rd Qu.:353.2   3rd Qu.:208.8  \n                    Max.   :10.000   Max.   :378.0   Max.   :228.0  \n    运营年数     日均客运量万人次    cluster \n Min.   : 9.00   Min.   :143.8    Min.   :2  \n 1st Qu.:15.00   1st Qu.:301.2    1st Qu.:2  \n Median :15.00   Median :329.0    Median :2  \n Mean   :17.33   Mean   :328.5    Mean   :2  \n 3rd Qu.:15.00   3rd Qu.:375.5    3rd Qu.:2  \n Max.   :35.00   Max.   :486.0    Max.   :2  \n\n$`3`\n     城市              线路数量       总里程公里        站点数      \n Length:7           Min.   :2.000   Min.   : 72.0   Min.   : 56.00  \n Class :character   1st Qu.:3.000   1st Qu.: 85.5   1st Qu.: 71.50  \n Mode  :character   Median :4.000   Median :146.0   Median : 86.00  \n                    Mean   :3.714   Mean   :133.9   Mean   : 90.86  \n                    3rd Qu.:4.500   3rd Qu.:171.0   3rd Qu.:108.00  \n                    Max.   :5.000   Max.   :206.0   Max.   :135.00  \n    运营年数     日均客运量万人次    cluster \n Min.   :2.000   Min.   : 38.30   Min.   :3  \n 1st Qu.:3.500   1st Qu.: 50.38   1st Qu.:3  \n Median :4.000   Median : 58.52   Median :3  \n Mean   :4.857   Mean   : 80.93   Mean   :3  \n 3rd Qu.:6.500   3rd Qu.: 89.47   3rd Qu.:3  \n Max.   :8.000   Max.   :190.00   Max.   :3  \n\n\n\n\n\n第1类：北京、上海、广州，地铁运营规模最大，线路数量、总里程、站点数、运营年数大约是第2类城市的两倍，日均客运量越是第2类城市的3倍。\n第2类：“天津” “南京” “成都” “武汉” “深圳” “重庆”。第2类城市，线路数量介于6-10条，总里程介于233至378公里，站点数介于134至228个。日均客运量的中位数是329万人。地铁运营规模，在国内处于中等水平。\n第3类：“杭州” “苏州” “郑州” “合肥” “青岛” “厦门” “南宁”。第3类城市，线路数量介于2-5条，总里程介于71至206公里，站点数介于56至135个。运营年数介于2至8年，日均客运量的中位数是59万人。第3类城市的地铁运营规模较小，大约是第2类城市的1/5， 第1类城市1/15。"
  },
  {
    "objectID": "quizsolution.html#导入数据",
    "href": "quizsolution.html#导入数据",
    "title": "Solutions to Quiz",
    "section": "",
    "text": "library(readxl)\nlibrary(tidyverse)\n\nmetro16 &lt;- read_excel(\"metro16.xlsx\") %&gt;% data.frame()\n\n#给metro16增加行名\nrownames(metro16) &lt;- metro16$城市\n\nmetro16\n\n     城市 线路数量 总里程公里 站点数 运营年数 日均客运量万人次\n广州 广州       14        513    271       23           905.75\n上海 上海       17        705    416       27          1065.03\n北京 北京       23        699    405       49          1241.10\n天津 天津        6        233    143       35           143.85\n杭州 杭州        5        206    120        7           190.00\n南京 南京       10        378    174       15           353.00\n成都 成都        8        358    215        9           382.99\n武汉 武汉        9        339    228       15           305.00\n深圳 深圳       10        284    134       15           486.00\n苏州 苏州        4        166    135        8            99.10\n郑州 郑州        5        146     96        6            79.85\n合肥 合肥        3         90     77        3            49.26\n青岛 青岛        4        176     86        4            51.50\n厦门 厦门        2         72     56        2            38.30\n南宁 南宁        3         81     66        4            58.52\n重庆 重庆       10        329    190       15           300.00"
  },
  {
    "objectID": "quizsolution.html#报告描述性统计量",
    "href": "quizsolution.html#报告描述性统计量",
    "title": "Solutions to Quiz",
    "section": "",
    "text": "library(psych)\n\nmetro16 %&gt;% select(2:6) %&gt;% \n  describe() %&gt;% \n  select(mean, sd, median, min, max) \n\n                   mean     sd median  min    max\n线路数量           8.31   5.74    7.0  2.0   23.0\n总里程公里       298.44 199.17  258.5 72.0  705.0\n站点数           175.75 110.14  139.0 56.0  416.0\n运营年数          14.81  13.03   12.0  2.0   49.0\n日均客运量万人次 359.33 383.20  245.0 38.3 1241.1"
  },
  {
    "objectID": "quizsolution.html#聚类分析",
    "href": "quizsolution.html#聚类分析",
    "title": "Solutions to Quiz",
    "section": "",
    "text": "#设置图形排版，2行2列\npar(mfrow = c(2,2))\n\n#定义聚类方法\nmethod &lt;- c(\"complete\",\"single\",\"average\",\"ward.D\")\n\n#对比四种聚类方法的树状图\nlibrary(dendextend)\nfor (i in 1:4) {\n  metro16 %&gt;% \n    select(2:6) %&gt;% \n    scale() %&gt;% \n    dist() %&gt;% \n    hclust(method = method[i]) %&gt;% \n    as.dendrogram() %&gt;% \n    color_branches(k = 3) %&gt;% \n    plot(main = method[i])  \n}\n\n\n\n\n\n\n\n#保存聚类模型\nmetro16.ward &lt;- metro16 %&gt;% \n    select(2:6) %&gt;% \n    scale() %&gt;% \n    dist() %&gt;% \n    hclust(method = method[i])\n\n选择Ward.D方法，该方法下分为三类，个案数量分别为3，6，7，个案数量分布合理。\n\n\n\n\nlibrary(cluster)\nlibrary(factoextra)\n\nmetro16 %&gt;% select(2:6) %&gt;% \n    agnes(stand = TRUE, method = \"ward\") %&gt;% \n    fviz_dend(k = 3,  #分三类\n          cex = 0.6,  # 标签字体\n          k_colors = c(4,5,6), #分支颜色\n          color_labels_by_k = TRUE, #标签上色\n          rect = TRUE,  #添加矩形框\n          lower_rect = -2, \n          main = \"Linkage Method: Ward\")  #矩形框下沿\n\n\n\n\n\n\n\nmetro16.agnes &lt;- metro16 %&gt;% select(2:6) %&gt;% \n    agnes(stand = TRUE, method = \"ward\")\n\n选择了线路数量、总里程、站点数、运营年数和日均客运量五个变量进行聚类分析。采用了系统聚类方法，个案之间的距离用欧氏距离测度，类与类之间的距离用Ward法（离差平方和法）测度。对变量进行了标准化变换。"
  },
  {
    "objectID": "quizsolution.html#报告各类构成",
    "href": "quizsolution.html#报告各类构成",
    "title": "Solutions to Quiz",
    "section": "",
    "text": "#在metro16中追加变量cluster, 保存聚类结果\nmetro16$cluster &lt;- cutree(metro16.ward, k = 3)\n\n# 罗列各个类别包含的个案数量\ntable(metro16$cluster)\n\n\n1 2 3 \n3 6 7 \n\n#第一类\nmetro16$城市[metro16$cluster == 1]\n\n[1] \"广州\" \"上海\" \"北京\"\n\n#第二类\nmetro16$城市[metro16$cluster == 2]\n\n[1] \"天津\" \"南京\" \"成都\" \"武汉\" \"深圳\" \"重庆\"\n\n#第三类\nmetro16$城市[metro16$cluster == 3]\n\n[1] \"杭州\" \"苏州\" \"郑州\" \"合肥\" \"青岛\" \"厦门\" \"南宁\""
  },
  {
    "objectID": "quizsolution.html#报告各组描述性统计量",
    "href": "quizsolution.html#报告各组描述性统计量",
    "title": "Solutions to Quiz",
    "section": "",
    "text": "library(purrr)\n\nmetro16 %&gt;% \n  split(.$cluster) %&gt;% \n  map(summary)\n\n$`1`\n     城市              线路数量      总里程公里      站点数         运营年数 \n Length:3           Min.   :14.0   Min.   :513   Min.   :271.0   Min.   :23  \n Class :character   1st Qu.:15.5   1st Qu.:606   1st Qu.:338.0   1st Qu.:25  \n Mode  :character   Median :17.0   Median :699   Median :405.0   Median :27  \n                    Mean   :18.0   Mean   :639   Mean   :364.0   Mean   :33  \n                    3rd Qu.:20.0   3rd Qu.:702   3rd Qu.:410.5   3rd Qu.:38  \n                    Max.   :23.0   Max.   :705   Max.   :416.0   Max.   :49  \n 日均客运量万人次    cluster \n Min.   : 905.8   Min.   :1  \n 1st Qu.: 985.4   1st Qu.:1  \n Median :1065.0   Median :1  \n Mean   :1070.6   Mean   :1  \n 3rd Qu.:1153.1   3rd Qu.:1  \n Max.   :1241.1   Max.   :1  \n\n$`2`\n     城市              线路数量        总里程公里        站点数     \n Length:6           Min.   : 6.000   Min.   :233.0   Min.   :134.0  \n Class :character   1st Qu.: 8.250   1st Qu.:295.2   1st Qu.:150.8  \n Mode  :character   Median : 9.500   Median :334.0   Median :182.0  \n                    Mean   : 8.833   Mean   :320.2   Mean   :180.7  \n                    3rd Qu.:10.000   3rd Qu.:353.2   3rd Qu.:208.8  \n                    Max.   :10.000   Max.   :378.0   Max.   :228.0  \n    运营年数     日均客运量万人次    cluster \n Min.   : 9.00   Min.   :143.8    Min.   :2  \n 1st Qu.:15.00   1st Qu.:301.2    1st Qu.:2  \n Median :15.00   Median :329.0    Median :2  \n Mean   :17.33   Mean   :328.5    Mean   :2  \n 3rd Qu.:15.00   3rd Qu.:375.5    3rd Qu.:2  \n Max.   :35.00   Max.   :486.0    Max.   :2  \n\n$`3`\n     城市              线路数量       总里程公里        站点数      \n Length:7           Min.   :2.000   Min.   : 72.0   Min.   : 56.00  \n Class :character   1st Qu.:3.000   1st Qu.: 85.5   1st Qu.: 71.50  \n Mode  :character   Median :4.000   Median :146.0   Median : 86.00  \n                    Mean   :3.714   Mean   :133.9   Mean   : 90.86  \n                    3rd Qu.:4.500   3rd Qu.:171.0   3rd Qu.:108.00  \n                    Max.   :5.000   Max.   :206.0   Max.   :135.00  \n    运营年数     日均客运量万人次    cluster \n Min.   :2.000   Min.   : 38.30   Min.   :3  \n 1st Qu.:3.500   1st Qu.: 50.38   1st Qu.:3  \n Median :4.000   Median : 58.52   Median :3  \n Mean   :4.857   Mean   : 80.93   Mean   :3  \n 3rd Qu.:6.500   3rd Qu.: 89.47   3rd Qu.:3  \n Max.   :8.000   Max.   :190.00   Max.   :3"
  },
  {
    "objectID": "quizsolution.html#概括各类特征",
    "href": "quizsolution.html#概括各类特征",
    "title": "Solutions to Quiz",
    "section": "",
    "text": "第1类：北京、上海、广州，地铁运营规模最大，线路数量、总里程、站点数、运营年数大约是第2类城市的两倍，日均客运量越是第2类城市的3倍。\n第2类：“天津” “南京” “成都” “武汉” “深圳” “重庆”。第2类城市，线路数量介于6-10条，总里程介于233至378公里，站点数介于134至228个。日均客运量的中位数是329万人。地铁运营规模，在国内处于中等水平。\n第3类：“杭州” “苏州” “郑州” “合肥” “青岛” “厦门” “南宁”。第3类城市，线路数量介于2-5条，总里程介于71至206公里，站点数介于56至135个。运营年数介于2至8年，日均客运量的中位数是59万人。第3类城市的地铁运营规模较小，大约是第2类城市的1/5， 第1类城市1/15。"
  },
  {
    "objectID": "quizsolution.html#导入数据-1",
    "href": "quizsolution.html#导入数据-1",
    "title": "Solutions to Quiz",
    "section": "导入数据",
    "text": "导入数据\n\nlibrary(readxl)\nbankloan &lt;- read_excel(\"bankloan.xlsx\")"
  },
  {
    "objectID": "quizsolution.html#判别函数的估计",
    "href": "quizsolution.html#判别函数的估计",
    "title": "Solutions to Quiz",
    "section": "判别函数的估计",
    "text": "判别函数的估计\n\nlibrary(MASS)\n\nmodel1.da &lt;- lda(default ~ ., bankloan)\nmodel1.da\n\nCall:\nlda(default ~ ., data = bankloan)\n\nPrior probabilities of groups:\n        0         1 \n0.7385714 0.2614286 \n\nGroup means:\n       age       ed   employ  address   income   debtinc creddebt  othdebt\n0 35.51451 1.659574 9.508704 8.945841 47.15474  8.679304 1.245493 2.773409\n1 33.01093 1.901639 5.224044 6.393443 41.21311 14.727869 2.423865 3.862807\n\nCoefficients of linear discriminants:\n                  LD1\nage       0.015331213\ned        0.078357754\nemploy   -0.124220534\naddress  -0.046452296\nincome    0.004865162\ndebtinc   0.096027989\ncreddebt  0.276338074\nothdebt  -0.057146598"
  },
  {
    "objectID": "quizsolution.html#判别函数的预测正确率",
    "href": "quizsolution.html#判别函数的预测正确率",
    "title": "Solutions to Quiz",
    "section": "判别函数的预测正确率",
    "text": "判别函数的预测正确率\n\n#预测\nmodel1.predict &lt;- predict(model1.da, bankloan)\n\n#预测组别与实际组别的列联表\ntab1 &lt;- table(bankloan$default, model1.predict$class)\ntab1\n\n   \n      0   1\n  0 485  32\n  1  99  84\n\n#预测正确率\nmean(bankloan$default == model1.predict$class)\n\n[1] 0.8128571"
  },
  {
    "objectID": "quizsolution.html#判别函数得分的分组直方图",
    "href": "quizsolution.html#判别函数得分的分组直方图",
    "title": "Solutions to Quiz",
    "section": "判别函数得分的分组直方图",
    "text": "判别函数得分的分组直方图\n\nlibrary(MASS)\nldahist(model1.predict$x,bankloan$default)"
  },
  {
    "objectID": "quizsolution.html#对比两个组别的差异",
    "href": "quizsolution.html#对比两个组别的差异",
    "title": "Solutions to Quiz",
    "section": "对比两个组别的差异",
    "text": "对比两个组别的差异\n\n#两个组别的解释变量的均值的差异\nmodel1.da$means\n\n       age       ed   employ  address   income   debtinc creddebt  othdebt\n0 35.51451 1.659574 9.508704 8.945841 47.15474  8.679304 1.245493 2.773409\n1 33.01093 1.901639 5.224044 6.393443 41.21311 14.727869 2.423865 3.862807\n\n#两个组别的解释变量的箱线图\npar(mfrow = c(2,4),mai = c(0.6,0.6,0.2,0.1),cex = 0.7)\n\nfor (i in 1:8) {\n  y &lt;- bankloan[[i]]\n  boxplot(y ~ bankloan$default, col = c(3,4,5),\n          main = colnames(bankloan)[i])\n}\n\n\n\n\n\n\n\n\n两个组别的差异： 未逾期(default = 0)和有逾期(default = 1)相比，整体而言，未逾期(default = 0)的组别年龄更大，在当前雇主的服务时长更长、在当前居住地居住时间更长、收入更高、债务与收入比更低、信用卡债务和其他债务更低。"
  },
  {
    "objectID": "quizsolution.html#预测新个案",
    "href": "quizsolution.html#预测新个案",
    "title": "Solutions to Quiz",
    "section": "预测新个案",
    "text": "预测新个案\n\n#录入新个案数据\nnew.case &lt;- data.frame(age = 34, \n                       ed = 4, \n                       employ = 6,\n                       address = 3, \n                       income = 27, \n                       debtinc = 35.3, \n                       creddebt = 1.98, \n                       othdebt = 7.55\n  )\n\npredict(model1.da, new.case)\n\n$class\n[1] 1\nLevels: 0 1\n\n$posterior\n           0         1\n1 0.06711165 0.9328884\n\n$x\n       LD1\n1 2.882298\n\n\n根据判别函数预测Lily会发生逾期还款。"
  },
  {
    "objectID": "quizsolution.html#评估数据的相关性",
    "href": "quizsolution.html#评估数据的相关性",
    "title": "Solutions to Quiz",
    "section": "评估数据的相关性",
    "text": "评估数据的相关性\n\nlibrary(factoextra)\nmtcars %&gt;%\n  dplyr::select(mpg, qsec, wt, cyl, disp, hp) %&gt;%\n  KMO()\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = .)\nOverall MSA =  0.81\nMSA for each item = \n mpg qsec   wt  cyl disp   hp \n0.86 0.64 0.73 0.88 0.82 0.88 \n\n\nKMO等于0.814，适于降维处理。"
  },
  {
    "objectID": "quizsolution.html#估计主成分模型",
    "href": "quizsolution.html#估计主成分模型",
    "title": "Solutions to Quiz",
    "section": "估计主成分模型",
    "text": "估计主成分模型\n注意题目3.2需要更正为：你提取了几个主成分，是相关系数矩阵还是协方差矩阵？你为何做出上述选择？\n提取两个主成分，使用的是相关系数矩阵，因为原始变量的数量级别差距较大，采用相关系数矩阵，可以避免观测值较大的原始变量对提取结果的影响。\n\ncar.pr &lt;- mtcars %&gt;% \n  dplyr::select(mpg, qsec, wt, cyl,disp,hp) %&gt;% \n  prcomp(scale = TRUE)\n\ncar.pr\n\nStandard deviations (1, .., p=6):\n[1] 2.1416696 0.9809970 0.4086451 0.3801105 0.2999090 0.2224322\n\nRotation (n x k) = (6 x 6):\n            PC1         PC2         PC3         PC4        PC5         PC6\nmpg  -0.4319266  0.19022095 -0.61557102  0.52590879 -0.0718869  0.34143803\nqsec -0.2804946 -0.79584714  0.06560722  0.26481108  0.4496718 -0.10637755\nwt    0.4024295 -0.47383679  0.03018494  0.08057191 -0.4978411  0.59856530\ncyl   0.4458939  0.03443083 -0.43940446 -0.28406318  0.6477319  0.32660126\ndisp  0.4411470 -0.18033201 -0.51963422  0.20072945 -0.2371697 -0.63742311\nhp    0.4235335  0.26873203  0.39084636  0.72513379  0.2626324  0.02910102"
  },
  {
    "objectID": "quizsolution.html#确定提取的主成分的个数",
    "href": "quizsolution.html#确定提取的主成分的个数",
    "title": "Solutions to Quiz",
    "section": "确定提取的主成分的个数",
    "text": "确定提取的主成分的个数\n\n#查看方差累计贡献率\nsummary(car.pr)\n\nImportance of components:\n                          PC1    PC2     PC3     PC4     PC5     PC6\nStandard deviation     2.1417 0.9810 0.40865 0.38011 0.29991 0.22243\nProportion of Variance 0.7645 0.1604 0.02783 0.02408 0.01499 0.00825\nCumulative Proportion  0.7645 0.9248 0.95268 0.97676 0.99175 1.00000\n\n#绘制scree plot\n\n#标注方差贡献率, 在图中标注方差贡献率\nlibrary(factoextra)\nfviz_eig(car.pr, \n         addlabels = TRUE, geom = c(\"line\"),\n         ylim = c(0, 80))\n\n\n\n\n\n\n\n\n第一主成分的方差贡献率是76%，第二主成分的方差贡献率是16%，前两个主成分的累计方差贡献率达到92%，因此保留前两个主成分即可代表原始变量绝大部分信息。"
  },
  {
    "objectID": "quizsolution.html#概括主成分的含义",
    "href": "quizsolution.html#概括主成分的含义",
    "title": "Solutions to Quiz",
    "section": "概括主成分的含义",
    "text": "概括主成分的含义\n\n# 绘制correlation circle,反映主成分与原始变量的关系\nlibrary(factoextra)\nfviz_pca_var(car.pr, \n             col.var = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\") , \n             repel = TRUE # Avoid text overlapping\n)\n\n\n\n\n\n\n\ncar.pr$rotation[,1:2]\n\n            PC1         PC2\nmpg  -0.4319266  0.19022095\nqsec -0.2804946 -0.79584714\nwt    0.4024295 -0.47383679\ncyl   0.4458939  0.03443083\ndisp  0.4411470 -0.18033201\nhp    0.4235335  0.26873203\n\n\n第一主成分与wt、cyl、disp和hp正相关，与mpg, qsec负相关。其中qsec的系数为-0.28，绝对值最小，其对第一主成分得分的影响较弱 。 当wt、cyl、disp和hp的值越大，也就是汽车的重量、气缸数、排量和马力越大，PC1的值越大。 当mpg的值越小，也就是越耗油，PC1的值越大。 因此，PC1主要反映了汽车在动力、油耗方面的表现，在PC1上得分越高，意味者汽车的动力越强、耗油量大。\n第二主成分的mpg、cyl、hp的系数都为正，但是其数值都较小，其对第2主成分得分的影响较弱。 第二主成分的qsec、wt、disp的系数都为负，其中disp的绝对值较小，因此第二主成分主要代表了qsec、wt的信息。qsec的值越小，1/4英里的耗时越少，第二主成分得分的值越大。wt的值越小，车重越小，第二主成分得分的值越大。 因此，PC2主要反映了汽车在加速快、车重轻巧方面的表现，在PC2上得分越高，意味者汽车重量小、加速快。"
  },
  {
    "objectID": "quizsolution.html#第一主成分和第二主成分得分散点图",
    "href": "quizsolution.html#第一主成分和第二主成分得分散点图",
    "title": "Solutions to Quiz",
    "section": "第一主成分和第二主成分得分散点图",
    "text": "第一主成分和第二主成分得分散点图\n\n# am = 0, 自动挡；am = 1, 手动档\nfviz_pca_ind(car.pr, \n             col.ind = as.factor(mtcars$am),\n             repel = TRUE)\n\n\n\n\n\n\n\n\n自动挡汽车主要分布在第四象限，PC1得分较高表明其动力强、耗油大，PC2得分较低表明汽车重量大，加速慢。\n手动挡汽车主要分布在第二象限，PC1得分较低表明其动力弱、省油，PC2得分较高表明汽车重量轻，加速快。"
  },
  {
    "objectID": "schedule.html#测验答案",
    "href": "schedule.html#测验答案",
    "title": "课程安排和考核",
    "section": "测验答案",
    "text": "测验答案\nR Introduction"
  },
  {
    "objectID": "faR.html",
    "href": "faR.html",
    "title": "7 FA在R中的实现",
    "section": "",
    "text": "本章介绍R中的因子分析。\n# 读取数据\n#P146，例题7.1 52名学生的6科目成绩\nlibrary(readr)\nlibrary(tidyverse)\neg7_1 &lt;- read_csv(\"eg6.1.csv\")\neg7_1 &lt;- eg7_1 %&gt;% rename(数学 = x1,\n                 物理 = x2,\n                 化学 = x3,\n                 语文 = x4,\n                 历史 = x5,\n                 英语 = x6)"
  },
  {
    "objectID": "faR.html#主成分法-principal-component-method",
    "href": "faR.html#主成分法-principal-component-method",
    "title": "7 FA在R中的实现",
    "section": "主成分法 principal component method",
    "text": "主成分法 principal component method\n\n无旋转\n\nlibrary(psych)\n\n#未旋转\nfa.pc.none &lt;- principal(eg7_1, nfactors = 2,\n                       rotate = \"none\")\nfa.pc.none\n\nPrincipal Components Analysis\nCall: principal(r = eg7_1, nfactors = 2, rotate = \"none\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       PC1  PC2   h2   u2 com\n数学 -0.79 0.42 0.81 0.19 1.5\n物理 -0.73 0.40 0.70 0.30 1.5\n化学 -0.64 0.63 0.81 0.19 2.0\n语文  0.89 0.31 0.89 0.11 1.2\n历史  0.81 0.47 0.87 0.13 1.6\n英语  0.83 0.46 0.90 0.10 1.6\n\n                       PC1  PC2\nSS loadings           3.71 1.26\nProportion Var        0.62 0.21\nCumulative Var        0.62 0.83\nProportion Explained  0.75 0.25\nCumulative Proportion 0.75 1.00\n\nMean item complexity =  1.6\nTest of the hypothesis that 2 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.06 \n with the empirical chi square  5.96  with prob &lt;  0.2 \n\nFit based upon off diagonal values = 0.99\n\n# com的含义\n# com : Hoffman's index of complexity for each item，\n#该值越接近于1，代表该原始变量主要由某个因子代表。 \n\n输出结果解读\n\n因子载荷矩阵（loadings）\n\nPC1、PC2：第 1、第 2个公共因子在各变量上的标准化载荷（loading）。载荷实际上是变量在该成分方向上的相关系数（或投影系数），绝对值越大表示该成分对该变量解释力越强。注意载荷的正负只是方向的约定（可以同时乘以 −1），不影响结构本质。\n\nh2（communalities，共同度）\n\n每个变量被这两个公共因子共同解释的方差比例。比如 数学 的 h2 = 0.81，表示两个公共因子可以解释数学 81% 的方差；剩下 19%（u2）是变量的独特方差或噪声。\n\nu2（uniqueness，特有方差）：等于 1 − h2，表示未被提取成分解释的方差比例。\ncom（complexity）: 衡量某个变量在提取的因子/成分上“分布多少”的指标，越接近 1 表示该变量主要加载在单一因子上（结构简单），越接近因子数 m 表示该变量在所有因子上分布得较均匀（结构复杂）。\nSS loadings 就是每个因子的“载荷的平方和”，计算方法是把该因子在所有变量上的载荷取。\nProportion Var 是某个因子解释的“总体方差”的比例。\n\nSS loadings 为 3.71 和 1.26，p = 6（因为用相关矩阵）。\nProportion Var_1 = 3.71 / 6 ≈ 0.6183 → 0.62（输出）\nProportion Var_2 = 1.26 / 6 = 0.21 → 0.21\n\nCumulative Var after 2 = (3.71+1.26)/6 = 0.83\n“Proportion Explained 0.75 0.25” 表示在“提取出的两个公共因子”这部分方差中，PC1 占 75%，PC2 占 25%。\n“Cumulative Proportion 0.75 1.00” 表示按顺序累加：前 1 个因子累计占 75%，前 2 个因子（即两个因子一起）占 100%（因为你只看这两个被提取的因子，所以它们合起来占提取方差的全部）。\nMean item complexity = 1.6\n\n所有变量复杂度（complexity）的平均值，衡量每个变量在提取的成分上“分布得多均匀”。Mean item complexity1.6（m=2时）表示大多数变量较接近简单结构，但也有一些变量在两个成分上都有明显载荷。\n\n“Test of the hypothesis that 2 components are sufficient.”检验：两个成分是否足够，用于评估用两个成分重构相关矩阵是否与观测相关矩阵差异显著。\n\nRMSR = 0.06（残差的均方根）\nRMSR 观测相关矩阵与模型重构相关矩阵（通常只看非对角元素，即变量间相关）的残差的均方根：\n经验判断：RMSR ≈ 0.05 或更低通常认为拟合很好；0.05–0.08 可接受；&gt;0.10 则拟合较差。但这些阈值不是绝对规则，应结合样本量与其他拟合指标一起看。\n\nempirical chi square = 5.96 with prob &lt; 0.2（经验卡方统计与 p 值）\n\n含义：基于残差构造的卡方检验，其原假设 H0：所提取的 2 个成分能在总体上重构观测的相关结构（即模型拟合良好）。检验统计量约为 5.96，对应的 p 值约为 0.2（输出写成 “prob &lt; 0.2”）。结论：p ≈ 0.2（大于常用显著性水平 0.05），因此不能拒绝 H0——没有足够证据表明 2个成分不足以解释相关结构，换句话说模型可以接受。\n\n\n\n#绘制因子载荷系数图\nfa.diagram(fa.pc.none$loadings, digits = 3)\n\n\n\n\n\n\n\n\nPC2上的载荷的绝对值都小于PC1，所以不绘制指向观测变量的箭头。\n\n\nvarimax正交旋转\n\n#varimax正交旋转\nfa.pc.varimax &lt;- principal(eg7_1, nfactors = 2,\n                        rotate = \"varimax\")\nfa.pc.varimax\n\nPrincipal Components Analysis\nCall: principal(r = eg7_1, nfactors = 2, rotate = \"varimax\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       RC1   RC2   h2   u2 com\n数学 -0.32  0.84 0.81 0.19 1.3\n物理 -0.29  0.78 0.70 0.30 1.3\n化学 -0.07  0.90 0.81 0.19 1.0\n语文  0.88 -0.35 0.89 0.11 1.3\n历史  0.92 -0.18 0.87 0.13 1.1\n英语  0.93 -0.20 0.90 0.10 1.1\n\n                       RC1  RC2\nSS loadings           2.66 2.31\nProportion Var        0.44 0.39\nCumulative Var        0.44 0.83\nProportion Explained  0.54 0.46\nCumulative Proportion 0.54 1.00\n\nMean item complexity =  1.2\nTest of the hypothesis that 2 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.06 \n with the empirical chi square  5.96  with prob &lt;  0.2 \n\nFit based upon off diagonal values = 0.99\n\n#按因子载荷系数降序排列\nprint(fa.pc.varimax$loadings, digits = 3, cutoff = 0.5,sort = T)\n\n\nLoadings:\n     RC1    RC2   \n语文  0.876       \n历史  0.917       \n英语  0.925       \n数学         0.839\n物理         0.784\n化学         0.897\n\n                 RC1   RC2\nSS loadings    2.661 2.312\nProportion Var 0.443 0.385\nCumulative Var 0.443 0.829\n\n\n\n#绘制因子载荷系数图\nfa.diagram(fa.pc.varimax$loadings, digits = 3)\n\n\n\n\n\n\n\n\n\n\npromax正交旋转\n\n#promax斜交旋转\nfa.pc.promax &lt;- principal(eg7_1, nfactors = 2,\n                           rotate = \"promax\")\nfa.pc.promax\n\nPrincipal Components Analysis\nCall: principal(r = eg7_1, nfactors = 2, rotate = \"promax\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       RC1   RC2   h2   u2 com\n数学 -0.12  0.83 0.81 0.19 1.0\n物理 -0.10  0.78 0.70 0.30 1.0\n化学  0.18  0.97 0.81 0.19 1.1\n语文  0.87 -0.13 0.89 0.11 1.0\n历史  0.97  0.07 0.87 0.13 1.0\n英语  0.97  0.05 0.90 0.10 1.0\n\n                       RC1  RC2\nSS loadings           2.70 2.27\nProportion Var        0.45 0.38\nCumulative Var        0.45 0.83\nProportion Explained  0.54 0.46\nCumulative Proportion 0.54 1.00\n\n With component correlations of \n      RC1   RC2\nRC1  1.00 -0.49\nRC2 -0.49  1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.06 \n with the empirical chi square  5.96  with prob &lt;  0.2 \n\nFit based upon off diagonal values = 0.99\n\n\n\n#按因子载荷系数降序排列\nprint(fa.pc.promax$loadings, digits = 3, cutoff = 0.5,sort = T)\n\n\nLoadings:\n     RC1    RC2   \n语文  0.874       \n历史  0.967       \n英语  0.971       \n数学         0.834\n物理         0.782\n化学         0.972\n\n                 RC1   RC2\nSS loadings    2.699 2.274\nProportion Var 0.450 0.379\nCumulative Var 0.450 0.829\n\nfa.diagram(fa.pc.promax$loadings, digits = 3)"
  },
  {
    "objectID": "faR.html#极大似然法-maximum-likelihood",
    "href": "faR.html#极大似然法-maximum-likelihood",
    "title": "7 FA在R中的实现",
    "section": "极大似然法 Maximum Likelihood",
    "text": "极大似然法 Maximum Likelihood\n\n#方法一：psych::fa\nfa.ml.none1 &lt;- fa(eg7_1, \n                 nfactors = 2, \n                 fm = \"ml\",\n                 rotate = \"none\")\n\nfa.ml.none1\n\nFactor Analysis using method =  ml\nCall: fa(r = eg7_1, nfactors = 2, rotate = \"none\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       ML1  ML2   h2   u2 com\n数学 -0.68 0.56 0.77 0.23 1.9\n物理 -0.60 0.43 0.54 0.46 1.8\n化学 -0.49 0.66 0.67 0.33 1.8\n语文  0.92 0.10 0.85 0.15 1.0\n历史  0.86 0.24 0.79 0.21 1.2\n英语  0.88 0.27 0.85 0.15 1.2\n\n                       ML1  ML2\nSS loadings           3.40 1.07\nProportion Var        0.57 0.18\nCumulative Var        0.57 0.75\nProportion Explained  0.76 0.24\nCumulative Proportion 0.76 1.00\n\nMean item complexity =  1.5\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  4.28 with Chi Square =  205.97\ndf of  the model are 4  and the objective function was  0.08 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.04 \n\nThe harmonic n.obs is  52 with the empirical chi square  0.62  with prob &lt;  0.96 \nThe total n.obs was  52  with Likelihood Chi Square =  3.64  with prob &lt;  0.46 \n\nTucker Lewis Index of factoring reliability =  1.007\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.203\nBIC =  -12.17\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.97 0.89\nMultiple R square of scores with factors          0.95 0.80\nMinimum correlation of possible factor scores     0.89 0.59\n\n\n\n#方法二：stats::factanal\nfa.ml.none2 &lt;- factanal(eg7_1, \n                 factors = 2,\n                 rotation = \"none\")\nfa.ml.none2\n\n\nCall:\nfactanal(x = eg7_1, factors = 2, rotation = \"none\")\n\nUniquenesses:\n 数学  物理  化学  语文  历史  英语 \n0.228 0.459 0.333 0.148 0.210 0.150 \n\nLoadings:\n     Factor1 Factor2\n数学 -0.676   0.562 \n物理 -0.599   0.427 \n化学 -0.487   0.656 \n语文  0.917   0.104 \n历史  0.856   0.239 \n英语  0.883   0.266 \n\n               Factor1 Factor2\nSS loadings      3.404   1.068\nProportion Var   0.567   0.178\nCumulative Var   0.567   0.745\n\nTest of the hypothesis that 2 factors are sufficient.\nThe chi square statistic is 3.64 on 4 degrees of freedom.\nThe p-value is 0.457"
  },
  {
    "objectID": "faR.html#主因子法-principal-factor",
    "href": "faR.html#主因子法-principal-factor",
    "title": "7 FA在R中的实现",
    "section": "主因子法 principal factor",
    "text": "主因子法 principal factor\n\nvarimax旋转\n\n#函数psych::fa，varimax旋转\nlibrary(psych)\nfa.pa.varimax &lt;- fa(eg7_1, \n                  nfactors = 2, \n                  fm = \"pa\",\n                  rotate = \"varimax\")\n\nfa.pa.varimax\n\nFactor Analysis using method =  pa\nCall: fa(r = eg7_1, nfactors = 2, rotate = \"varimax\", fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       PA1   PA2   h2   u2 com\n数学 -0.32  0.82 0.77 0.23 1.3\n物理 -0.31  0.67 0.54 0.46 1.4\n化学 -0.11  0.81 0.66 0.34 1.0\n语文  0.85 -0.36 0.85 0.15 1.3\n历史  0.86 -0.20 0.78 0.22 1.1\n英语  0.90 -0.20 0.86 0.14 1.1\n\n                       PA1  PA2\nSS loadings           2.49 1.98\nProportion Var        0.41 0.33\nCumulative Var        0.41 0.74\nProportion Explained  0.56 0.44\nCumulative Proportion 0.56 1.00\n\nMean item complexity =  1.2\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  4.28 with Chi Square =  205.97\ndf of  the model are 4  and the objective function was  0.08 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.04 \n\nThe harmonic n.obs is  52 with the empirical chi square  0.58  with prob &lt;  0.96 \nThe total n.obs was  52  with Likelihood Chi Square =  3.7  with prob &lt;  0.45 \n\nTucker Lewis Index of factoring reliability =  1.006\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.204\nBIC =  -12.1\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2\nCorrelation of (regression) scores with factors   0.95 0.91\nMultiple R square of scores with factors          0.91 0.83\nMinimum correlation of possible factor scores     0.82 0.66\n\n\n\n\nquartimax旋转\n\n#函数psych::fa，quartimax旋转\nlibrary(psych)\nfa.pa.quartimax &lt;- fa(eg7_1, \n                    nfactors = 2, \n                    fm = \"pa\",\n                    rotate = \"quartimax\")\n\nfa.pa.quartimax\n\nFactor Analysis using method =  pa\nCall: fa(r = eg7_1, nfactors = 2, rotate = \"quartimax\", fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       PA1   PA2   h2   u2 com\n数学 -0.42  0.77 0.77 0.23 1.5\n物理 -0.39  0.63 0.54 0.46 1.7\n化学 -0.21  0.79 0.66 0.34 1.1\n语文  0.89 -0.25 0.85 0.15 1.2\n历史  0.88 -0.09 0.78 0.22 1.0\n英语  0.92 -0.09 0.86 0.14 1.0\n\n                       PA1  PA2\nSS loadings           2.79 1.68\nProportion Var        0.46 0.28\nCumulative Var        0.46 0.74\nProportion Explained  0.62 0.38\nCumulative Proportion 0.62 1.00\n\nMean item complexity =  1.3\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  4.28 with Chi Square =  205.97\ndf of  the model are 4  and the objective function was  0.08 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.04 \n\nThe harmonic n.obs is  52 with the empirical chi square  0.58  with prob &lt;  0.96 \nThe total n.obs was  52  with Likelihood Chi Square =  3.7  with prob &lt;  0.45 \n\nTucker Lewis Index of factoring reliability =  1.006\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.204\nBIC =  -12.1\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2\nCorrelation of (regression) scores with factors   0.96 0.90\nMultiple R square of scores with factors          0.93 0.82\nMinimum correlation of possible factor scores     0.85 0.63"
  },
  {
    "objectID": "faR.html#主成分分析中的主成分载荷与因子分析中的主成分估计方法下的因子载荷的区别",
    "href": "faR.html#主成分分析中的主成分载荷与因子分析中的主成分估计方法下的因子载荷的区别",
    "title": "7 FA在R中的实现",
    "section": "主成分分析中的主成分载荷与因子分析中的主成分估计方法下的因子载荷的区别",
    "text": "主成分分析中的主成分载荷与因子分析中的主成分估计方法下的因子载荷的区别\n\neg7_1.pr &lt;- prcomp(eg7_1, scale = TRUE)\neg7_1.pr$rotation # 查看主成分载荷矩阵\n\n            PC1       PC2         PC3         PC4        PC5         PC6\n数学  0.4120520 0.3759773  0.21582978 -0.78801362 -0.0205822  0.14450829\n物理  0.3811779 0.3567060 -0.80555264  0.11755209  0.2120360 -0.14061074\n化学  0.3321347 0.5626165  0.46743533  0.58763655 -0.0333622  0.09068468\n语文 -0.4611846 0.2785231 -0.04426879 -0.02783261  0.5990449  0.59003773\n历史 -0.4205876 0.4147836 -0.25039004 -0.03376008 -0.7384344  0.20479353\n英语 -0.4301372 0.4065022  0.14612244 -0.13410793  0.2221800 -0.74902427\n\n#求相关系数矩阵的特征值和特征向量\npc &lt;- eg7_1 %&gt;% cor %&gt;% eigen() %&gt;% .$vectors # 查看主成分载荷矩阵\n\neigen &lt;- eg7_1 %&gt;% cor %&gt;% eigen() %&gt;% .$values # 查看特征值\n\n\nsqrt(eigen[1]) * pc[,1] # 计算第1个公共因子载荷\n\n[1] -0.7936579 -0.7341911 -0.6397283  0.8882928  0.8100985  0.8284920\n\neg7_1.pc &lt;- eg7_1 %&gt;% prcomp(scale = TRUE)\neg7_1.pc$rotation[,1] # 查看第1个主成分载荷\n\n      数学       物理       化学       语文       历史       英语 \n 0.4120520  0.3811779  0.3321347 -0.4611846 -0.4205876 -0.4301372 \n\n#因子分析中的主成分法\nfa.pc.none &lt;- psych::principal(eg7_1, nfactors = 2,\n                       rotate = \"none\")\nfa.pc.none$loadings[,1] # 查看第1个因子公共因子载荷\n\n      数学       物理       化学       语文       历史       英语 \n-0.7936579 -0.7341911 -0.6397283  0.8882928  0.8100985  0.8284920"
  },
  {
    "objectID": "faR.html#因子分析面临的决策提取几个因子因子载荷估计方法旋转方法",
    "href": "faR.html#因子分析面临的决策提取几个因子因子载荷估计方法旋转方法",
    "title": "7 FA在R中的实现",
    "section": "因子分析面临的决策：提取几个因子？因子载荷估计方法？旋转方法？",
    "text": "因子分析面临的决策：提取几个因子？因子载荷估计方法？旋转方法？\n提取的因子个数 特征值大于1 因子的累积贡献达到70%-80%以上\n因子载荷估计方法 主成分法 principal() 极大似然法 fa() 主轴因子法 fa()\n因子旋转方法 正交旋转：varimax, quartimax 因子相互独立的 斜交旋转：oblimin, promax 因子之间是相关的"
  },
  {
    "objectID": "faR.html#因子载荷系数图",
    "href": "faR.html#因子载荷系数图",
    "title": "7 FA在R中的实现",
    "section": "因子载荷系数图",
    "text": "因子载荷系数图\n\n#主成分法 Principal Component Method无旋转\nfa.pc.none &lt;- principal(eg7_1, \n                        nfactors = 2,\n                        rotate = \"none\")\n\nfa.pc.none$loadings \n\n\nLoadings:\n     PC1    PC2   \n数学 -0.794  0.422\n物理 -0.734  0.401\n化学 -0.640  0.632\n语文  0.888  0.313\n历史  0.810  0.466\n英语  0.828  0.457\n\n                 PC1   PC2\nSS loadings    3.710 1.262\nProportion Var 0.618 0.210\nCumulative Var 0.618 0.829\n\nfa.diagram(fa.pc.none$loadings, \n           digits = 3, \n           rsize = 0.8)\n\n\n\n\n\n\n\n\n\n#主成分法 Principal Component Method 正交旋转varimax\nfa.pc.varimax &lt;- principal(eg7_1, \n                        nfactors = 2,\n                        rotate = \"varimax\")\n\nfa.pc.varimax$loadings %&gt;% print(digits = 3,\n                                 cut = 0.5,\n                                 sort = TRUE)\n\n\nLoadings:\n     RC1    RC2   \n语文  0.876       \n历史  0.917       \n英语  0.925       \n数学         0.839\n物理         0.784\n化学         0.897\n\n                 RC1   RC2\nSS loadings    2.661 2.312\nProportion Var 0.443 0.385\nCumulative Var 0.443 0.829\n\nfa.diagram(fa.pc.varimax$loadings, \n           digits = 3, \n           rsize = 0.5)\n\n\n\n\n\n\n\ncolnames(fa.pc.varimax$loadings) &lt;- c(\"文科\", \"理科\")\n\n\n#maximum likelihood 极大似然 斜交旋转promax\nfa.ml.promax &lt;- fa(eg7_1, \n                   nfactors = 2, \n                   fm = \"ml\",\n                   rotate = \"promax\")\n\nfa.ml.promax$loadings %&gt;% print(digits = 3,\n                                 cut = 0.5,\n                                 sort = TRUE)\n\n\nLoadings:\n     ML1    ML2   \n语文  0.847       \n历史  0.911       \n英语  0.956       \n数学         0.833\n物理         0.656\n化学         0.890\n\n                 ML1   ML2\nSS loadings    2.510 1.940\nProportion Var 0.418 0.323\nCumulative Var 0.418 0.742\n\ncolnames(fa.ml.promax$loadings) &lt;- c(\"文科\", \"理科\")\n\nfa.ml.promax %&gt;% fa.diagram(rsize = 0.5,\n                            digits = 3)"
  },
  {
    "objectID": "faR.html#因子载荷和因子得分图",
    "href": "faR.html#因子载荷和因子得分图",
    "title": "7 FA在R中的实现",
    "section": "因子载荷和因子得分图",
    "text": "因子载荷和因子得分图\n\n#主成分法 Principal Component Method无旋转\nfa.pc.none &lt;- principal(eg7_1, \n                        nfactors = 2,\n                        rotate = \"none\")\nbiplot(fa.pc.none,\n       main = \"Principal Component, no rotation\")\n\n\n\n\n\n\n\n\n\n#主成分法 Principal Component 正交旋转varimax\nfa.pc.varimax &lt;- principal(eg7_1, \n                        nfactors = 2,\n                        rotate = \"varimax\")\n\nbiplot(fa.pc.varimax,\n       col = c(5,6),\n       main = \"Principal Component, Varimax\")\n\n\n\n\n\n\n\n#查看个案在原始变量的观测值与因子得分的关系\nfa.pc.varimax$scores %&gt;% cbind(eg7_1,.) %&gt;%\n                         arrange(desc(RC1))\n\n   数学 物理 化学 语文 历史 英语         RC1         RC2\n1    52   62   65  100   96  100  2.37146283 -0.89236422\n2    64   61   49  100   99   95  2.14453514 -1.04994850\n3    72   74   75   88   91   86  1.60312684  0.27088208\n4    72   67   61   92   92   88  1.60089485 -0.36560636\n5    86   78   92   87   87   77  1.39661149  1.34087672\n6    68   85   70   84   89   86  1.36280518  0.20076975\n7    72   68   77   83   92   79  1.24824003  0.09893997\n8    68   74   70   87   87   83  1.19588953 -0.15308336\n9    69   56   67   75   94   80  0.94800759 -0.66986805\n10   87   84  100   74   81   76  0.89505814  1.69379969\n11   81   90   79   73   85   80  0.88689495  0.98857294\n12   69   72   79   89   82   73  0.77761389 -0.03745268\n13   65   61   72   84   81   79  0.66036380 -0.68718464\n14   72   90   73   76   80   79  0.57832578  0.35968112\n15   82   70   83   68   77   85  0.57503687  0.56148305\n16   62   67   83   71   85   77  0.57341472 -0.24629083\n17   56   48   61   85   82   80  0.50709778 -1.73750306\n18   59   75   81   82   77   73  0.35974386 -0.35186206\n19   73   80   64   75   80   78  0.34822485 -0.20507234\n20   62   45   67   78   76   82  0.24184553 -1.45908639\n21   91   85  100   70   65   76  0.12266043  1.63080706\n22   70   72   56   74   82   74  0.09089471 -0.83832115\n23   77   89   80   73   75   70  0.06168574  0.58222335\n24   87   86   88   70   73   70  0.05095722  1.12576308\n25   87   98   87   68   78   64  0.02133066  1.40930087\n26   83   71   81   63   77   73 -0.03532405  0.39989888\n27   85   91   95   63   76   66 -0.04997962  1.41175077\n28   74   74   84   61   80   69 -0.10599059  0.23835843\n29   64   79   64   72   76   74 -0.11143434 -0.68414192\n30   71   58   45   83   77   73 -0.13213293 -1.62997362\n31   60   51   60   78   74   76 -0.15843575 -1.72144006\n32   69   64   60   68   74   80 -0.16973580 -1.00805396\n33   91   74   97   62   71   66 -0.30355745  1.17630966\n34   79   73   69   65   73   73 -0.33882707 -0.17510138\n35   78   68   52   75   74   66 -0.56266669 -0.99490230\n36   90   78   78   59   72   66 -0.59997498  0.58064466\n37   78   84   75   62   71   64 -0.72215827  0.15234085\n38   88  100   85   49   71   66 -0.72960966  1.30734862\n39   66   61   77   62   73   64 -0.77109905 -0.81988047\n40   80   98   83   58   66   66 -0.78496127  0.83027677\n41   67   83   65   68   74   60 -0.79109191 -0.63366342\n42   77   90   80   68   66   60 -0.83830982  0.34763562\n43   84   67   75   60   70   63 -0.89636993 -0.11048745\n44   99  100   99   53   63   60 -0.93655446  2.04025135\n45   77   77   76   64   70   55 -1.07567973 -0.15571837\n46   76   61   73   63   60   70 -1.07908021 -0.69822814\n47   90   83   91   58   60   59 -1.20571398  0.91632299\n48   86   94   97   51   63   55 -1.30641265  1.25308371\n49   67   63   49   65   67   57 -1.60122590 -1.88323054\n50   67   84   53   58   66   56 -1.72435369 -1.21908241\n51   66   71   67   52   65   57 -1.75198210 -1.12791008\n52   83  100   79   41   67   50 -1.84006051  0.63813576\n\n\n\n#极大似然法, 斜交promax旋转  \nfa.ml.promax &lt;- fa(eg7_1, \n                   nfactors = 2, \n                   fm = \"ml\",\n                   rotate = \"promax\")\n\nbiplot(fa.ml.promax,\n       col = c(3,4),\n       main = \"Maximum Likelihood, Promax\")"
  },
  {
    "objectID": "chap7slide.html",
    "href": "chap7slide.html",
    "title": "Chapter 7 因子分析",
    "section": "",
    "text": "注意：本讲义供学习交流使用，请勿用于商业用途"
  },
  {
    "objectID": "ch7case_car.html",
    "href": "ch7case_car.html",
    "title": "汽车性能因子分析",
    "section": "",
    "text": "应用举例\n  点击下载数据文件: car_sales.xlsx \n\n\n\n\n\n\n\n\n\n\nlibrary(readxl)\ncar_sales &lt;- read_excel(\"car_sales.xlsx\") \n\n\nlibrary(tidyverse)\nlibrary(psych)\n\nfa.pc.varimax &lt;- car_sales %&gt;% select(engine_s:mpg) %&gt;% \n  principal(nfactors = 2, \n            rotate = \"varimax\")\n\nfa.pc.varimax\n\nPrincipal Components Analysis\nCall: principal(r = ., nfactors = 2, rotate = \"varimax\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n           RC1   RC2   h2   u2 com\nengine_s  0.88  0.32 0.87 0.13 1.3\nhorsepow  0.89  0.09 0.80 0.20 1.0\nwheelbas  0.19  0.94 0.91 0.09 1.1\nwidth     0.52  0.69 0.75 0.25 1.9\nlength    0.23  0.89 0.84 0.16 1.1\ncurb_wgt  0.72  0.58 0.85 0.15 1.9\nfuel_cap  0.64  0.59 0.76 0.24 2.0\nmpg      -0.80 -0.37 0.78 0.22 1.4\n\n                       RC1  RC2\nSS loadings           3.49 3.06\nProportion Var        0.44 0.38\nCumulative Var        0.44 0.82\nProportion Explained  0.53 0.47\nCumulative Proportion 0.53 1.00\n\nMean item complexity =  1.5\nTest of the hypothesis that 2 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.07 \n with the empirical chi square  38.95  with prob &lt;  2e-04 \n\nFit based upon off diagonal values = 0.99\n\nprint(fa.pc.varimax$loadings, digits = 3, cutoff = 0.5,sort = T)\n\n\nLoadings:\n         RC1    RC2   \nengine_s  0.876       \nhorsepow  0.888       \ncurb_wgt  0.722  0.577\nfuel_cap  0.644  0.586\nmpg      -0.803       \nwheelbas         0.935\nwidth     0.517  0.693\nlength           0.888\n\n                 RC1   RC2\nSS loadings    3.493 3.063\nProportion Var 0.437 0.383\nCumulative Var 0.437 0.819\n\nfa.pc.varimax &lt;- car_sales %&gt;% select(engine_s:mpg) %&gt;% \n  principal(nfactors = 3, \n            rotate = \"varimax\")\n\nfa.pc.varimax\n\nPrincipal Components Analysis\nCall: principal(r = ., nfactors = 3, rotate = \"varimax\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n           RC2   RC1   RC3   h2    u2 com\nengine_s  0.31  0.43  0.80 0.92 0.084 1.9\nhorsepow  0.13  0.26  0.92 0.93 0.066 1.2\nwheelbas  0.88  0.37  0.04 0.91 0.090 1.3\nwidth     0.68  0.35  0.45 0.78 0.216 2.3\nlength    0.91  0.18  0.24 0.91 0.085 1.2\ncurb_wgt  0.43  0.75  0.39 0.90 0.099 2.2\nfuel_cap  0.39  0.84  0.22 0.91 0.085 1.6\nmpg      -0.19 -0.83 -0.41 0.89 0.107 1.6\n\n                       RC2  RC1  RC3\nSS loadings           2.55 2.50 2.12\nProportion Var        0.32 0.31 0.26\nCumulative Var        0.32 0.63 0.90\nProportion Explained  0.36 0.35 0.30\nCumulative Proportion 0.36 0.70 1.00\n\nMean item complexity =  1.7\nTest of the hypothesis that 3 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.03 \n with the empirical chi square  8.66  with prob &lt;  0.28 \n\nFit based upon off diagonal values = 1\n\nprint(fa.pc.varimax$loadings, digits = 3, cutoff = 0.5,sort = T)\n\n\nLoadings:\n         RC2    RC1    RC3   \nwheelbas  0.879              \nwidth     0.680              \nlength    0.908              \ncurb_wgt         0.748       \nfuel_cap         0.842       \nmpg             -0.829       \nengine_s                0.797\nhorsepow                0.922\n\n                 RC2   RC1   RC3\nSS loadings    2.550 2.500 2.119\nProportion Var 0.319 0.312 0.265\nCumulative Var 0.319 0.631 0.896\n\n\n\nlibrary(tidyverse)\ndata &lt;- cbind(car_sales, fa.pc.varimax$scores)\ndata &lt;- data %&gt;% mutate(suv = if_else(type == 1, 1,0)) \n\n# RC1，其值越大，代表车重大、油箱容积大、耗油越高（SUV）\ndata %&gt;% ggplot(aes(RC1, fill = as.factor(suv)))+\n  geom_histogram(col = 1)+\n  facet_wrap(~ suv,ncol = 1)\n\n\n\n\n\n\n\n# RC2，其值越大，代表车子轮距、车宽、车长大\n\ndata %&gt;% ggplot(aes(RC2, fill = as.factor(suv)))+\n  geom_histogram(col = 1)+\n  facet_wrap(~ suv,ncol = 1)\n\n\n\n\n\n\n\n# RC3，动力性能\n\ndata %&gt;% ggplot(aes(RC3, fill = as.factor(suv)))+\n  geom_histogram(col = 1)+\n  facet_wrap(~ suv,ncol = 1)\n\n\n\n\n\n\n\n\n\neq1 &lt;- lm(price ~ RC1 +RC2 +RC3, data)\nsummary(eq1)\n\n\nCall:\nlm(formula = price ~ RC1 + RC2 + RC3, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-21.468  -5.049  -0.936   2.972  36.978 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  27.4646     0.7014  39.156  &lt; 2e-16 ***\nRC1           4.3130     0.6999   6.162 6.47e-09 ***\nRC2          -1.0709     0.7001  -1.530    0.128    \nRC3          10.6574     0.7036  15.148  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.643 on 148 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.6479,    Adjusted R-squared:  0.6407 \nF-statistic: 90.76 on 3 and 148 DF,  p-value: &lt; 2.2e-16\n\neq2 &lt;- lm(resale ~ RC1 +RC2 +RC3, data)\nsummary(eq2)\n\n\nCall:\nlm(formula = resale ~ RC1 + RC2 + RC3, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-14.680  -4.848  -1.442   2.978  30.519 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  18.5900     0.7066  26.310  &lt; 2e-16 ***\nRC1           3.0571     0.7242   4.222  4.9e-05 ***\nRC2          -2.1020     0.6729  -3.124  0.00227 ** \nRC3           7.5295     0.6661  11.303  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.639 on 114 degrees of freedom\n  (39 observations deleted due to missingness)\nMultiple R-squared:  0.5742,    Adjusted R-squared:  0.563 \nF-statistic: 51.25 on 3 and 114 DF,  p-value: &lt; 2.2e-16\n\neq3 &lt;- lm(sales ~ RC1 +RC2 +RC3, data)\nsummary(eq3)\n\n\nCall:\nlm(formula = sales ~ RC1 + RC2 + RC3, data = data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-88.46 -35.92 -18.67  20.10 397.87 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  53.30585    5.08555  10.482  &lt; 2e-16 ***\nRC1           0.05693    5.08494   0.011  0.99108    \nRC2          25.16954    5.09264   4.942 2.05e-06 ***\nRC3         -14.56111    5.11090  -2.849  0.00501 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 62.88 on 149 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.1808,    Adjusted R-squared:  0.1643 \nF-statistic: 10.96 on 3 and 149 DF,  p-value: 1.508e-06\n\nbiplot(fa.pc.varimax)"
  },
  {
    "objectID": "ch7ex.html",
    "href": "ch7ex.html",
    "title": "7 FA习题讲评",
    "section": "",
    "text": "教材P151 案例7.6\n\nlibrary(readr)\nlibrary(tidyverse)\n\ncase7_1 &lt;- read_csv(\"case7.1.csv\") %&gt;% \n  rename(存货周转率 = x1, \n           总资产周转率 = x2, \n           流动资产周转率 = x3, \n           营业利润率 = x4, \n           毛利率 = x5, \n           成本费用利润率 = x6, \n           总资产报酬率 = x7, \n           净资产收益率 = x8, \n           每股收益率 = x9,\n         扣除非经常性损益的每股收益 = x10,\n         每股未分配利润 = x11,\n         每股净资产 = x12\n         )\n\n\n# step 1\nlibrary(psych)\nKMO(case7_1[-1])\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = case7_1[-1])\nOverall MSA =  0.79\nMSA for each item = \n                存货周转率               总资产周转率 \n                      0.82                       0.65 \n            流动资产周转率                 营业利润率 \n                      0.61                       0.80 \n                    毛利率             成本费用利润率 \n                      0.89                       0.77 \n              总资产报酬率               净资产收益率 \n                      0.77                       0.78 \n                每股收益率 扣除非经常性损益的每股收益 \n                      0.79                       0.79 \n            每股未分配利润                 每股净资产 \n                      0.89                       0.88 \n\nlibrary(EFAtools)\nBARTLETT(case7_1[-1])\n\n\n✔ The Bartlett's test of sphericity was significant at an alpha level of .05.\n  These data are probably suitable for factor analysis.\n\n  𝜒²(66) = 1010.1, p &lt; .001\n\n# step 2\n\n#计算特征值和特征向量\nlibrary(tidyverse)\ncase7_1.ev &lt;- case7_1 %&gt;% \n  select(-1) %&gt;% cor() %&gt;% \n  eigen()\ncase7_1.ev\n\neigen() decomposition\n$values\n [1] 6.499533804 2.654940434 1.498015224 0.457112219 0.274204566 0.251019040\n [7] 0.107527371 0.097961610 0.067989899 0.055824591 0.026693650 0.009177591\n\n$vectors\n            [,1]         [,2]        [,3]         [,4]        [,5]\n [1,] 0.09244934 -0.477942255  0.05813051  0.841178011  0.03145094\n [2,] 0.14156255 -0.510840674 -0.24058789 -0.292348983 -0.01653565\n [3,] 0.11396951 -0.524423948 -0.24305043 -0.326001981 -0.23004977\n [4,] 0.31943729  0.092092805 -0.32649716  0.186801205 -0.46156889\n [5,] 0.26320084  0.359901186 -0.20646040  0.001269517 -0.12764452\n [6,] 0.33013418  0.251211794 -0.18956461  0.184085750 -0.15605637\n [7,] 0.34205073  0.132406992 -0.28087340 -0.013460429  0.30932073\n [8,] 0.34921919 -0.077629433 -0.27080622 -0.045567816  0.31120190\n [9,] 0.35203886 -0.016220410  0.33198939 -0.047641358  0.22911864\n[10,] 0.35587756 -0.005797506  0.29858780 -0.035372439  0.21626107\n[11,] 0.33113545 -0.098353749  0.32947303 -0.119334215  0.17254721\n[12,] 0.28095737 -0.030775036  0.48410100 -0.108955477 -0.60873581\n               [,6]        [,7]        [,8]        [,9]       [,10]       [,11]\n [1,] -0.1768332629  0.04573485 -0.03270303 -0.09875414  0.07971144 -0.01808396\n [2,] -0.2808558579 -0.14250773  0.07575002  0.57019837  0.29654994  0.23670175\n [3,] -0.0250653760  0.33986884 -0.12436745 -0.36834886 -0.39212881 -0.26817548\n [4,]  0.4907354140 -0.29243188 -0.17916257  0.25284266  0.04959833 -0.33165214\n [5,] -0.6623872468 -0.02297448 -0.49285071 -0.16465110  0.16926101 -0.05967790\n [6,]  0.0001332728  0.48738638  0.18625489  0.24484958 -0.39198754  0.49024948\n [7,] -0.0177809801  0.26740169  0.53232291 -0.12200012  0.37530228 -0.37541743\n [8,]  0.1836614909 -0.48270097  0.02303125 -0.46759327 -0.07678284  0.43511797\n [9,] -0.0676631801 -0.03966850  0.03201316  0.16744682 -0.18867682 -0.34464400\n[10,] -0.1410113860 -0.24951050 -0.03736233  0.21446362 -0.43964946 -0.12369914\n[11,]  0.3727798520  0.39358992 -0.48947667 -0.01017771  0.38644169  0.18250240\n[12,] -0.1103111084 -0.12350439  0.37699725 -0.26605576  0.20542765  0.14203535\n            [,12]\n [1,]  0.01452807\n [2,] -0.03681929\n [3,]  0.02732101\n [4,]  0.01088018\n [5,] -0.02772321\n [6,] -0.08684279\n [7,]  0.19712367\n [8,] -0.13649776\n [9,] -0.72196255\n[10,]  0.63088779\n[11,]  0.10907353\n[12,]  0.02494923\n\n#绘制碎石图\nlibrary(nFactors)\n\ncase7_1.ev$values %&gt;% nScree() %&gt;% \n  plotnScree(legend = F)\n\n\n\n\n\n\n\n\n\n#未旋转\nfa.pc.none &lt;- principal(case7_1[-1], nfactors = 3,\n                        rotate = \"none\")\nfa.pc.none\n\nPrincipal Components Analysis\nCall: principal(r = case7_1[-1], nfactors = 3, rotate = \"none\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                            PC1   PC2   PC3   h2    u2 com\n存货周转率                 0.24  0.78 -0.07 0.67 0.333 1.2\n总资产周转率               0.36  0.83  0.29 0.91 0.090 1.6\n流动资产周转率             0.29  0.85  0.30 0.90 0.097 1.5\n营业利润率                 0.81 -0.15  0.40 0.85 0.155 1.5\n毛利率                     0.67 -0.59  0.25 0.86 0.142 2.3\n成本费用利润率             0.84 -0.41  0.23 0.93 0.070 1.6\n总资产报酬率               0.87 -0.22  0.34 0.93 0.075 1.4\n净资产收益率               0.89  0.13  0.33 0.92 0.081 1.3\n每股收益率                 0.90  0.03 -0.41 0.97 0.029 1.4\n扣除非经常性损益的每股收益 0.91  0.01 -0.37 0.96 0.043 1.3\n每股未分配利润             0.84  0.16 -0.40 0.90 0.099 1.5\n每股净资产                 0.72  0.05 -0.59 0.87 0.133 1.9\n\n                       PC1  PC2  PC3\nSS loadings           6.50 2.65 1.50\nProportion Var        0.54 0.22 0.12\nCumulative Var        0.54 0.76 0.89\nProportion Explained  0.61 0.25 0.14\nCumulative Proportion 0.61 0.86 1.00\n\nMean item complexity =  1.6\nTest of the hypothesis that 3 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.03 \n with the empirical chi square  9.42  with prob &lt;  1 \n\nFit based upon off diagonal values = 1\n\nfa.pc.varimax &lt;- principal(case7_1[-1], nfactors = 3,\n                           rotate = \"varimax\")\nfa.pc.varimax\n\nPrincipal Components Analysis\nCall: principal(r = case7_1[-1], nfactors = 3, rotate = \"varimax\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                             RC1  RC3   RC2   h2    u2 com\n存货周转率                 -0.15 0.26  0.76 0.67 0.333 1.3\n总资产周转率                0.13 0.07  0.94 0.91 0.090 1.1\n流动资产周转率              0.08 0.02  0.95 0.90 0.097 1.0\n营业利润率                  0.88 0.22  0.16 0.85 0.155 1.2\n毛利率                      0.85 0.21 -0.32 0.86 0.142 1.4\n成本费用利润率              0.89 0.35 -0.12 0.93 0.070 1.3\n总资产报酬率                0.91 0.30  0.10 0.93 0.075 1.2\n净资产收益率                0.79 0.34  0.42 0.92 0.081 1.9\n每股收益率                  0.40 0.89  0.12 0.97 0.029 1.4\n扣除非经常性损益的每股收益  0.43 0.87  0.12 0.96 0.043 1.5\n每股未分配利润              0.31 0.87  0.23 0.90 0.099 1.4\n每股净资产                  0.15 0.92  0.04 0.87 0.133 1.1\n\n                       RC1  RC3  RC2\nSS loadings           4.25 3.64 2.77\nProportion Var        0.35 0.30 0.23\nCumulative Var        0.35 0.66 0.89\nProportion Explained  0.40 0.34 0.26\nCumulative Proportion 0.40 0.74 1.00\n\nMean item complexity =  1.3\nTest of the hypothesis that 3 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.03 \n with the empirical chi square  9.42  with prob &lt;  1 \n\nFit based upon off diagonal values = 1\n\n#按因子载荷系数降序排列\nprint(fa.pc.varimax$loadings, digits = 3, cutoff = 0.5,sort = T)\n\n\nLoadings:\n                           RC1    RC3    RC2   \n营业利润率                  0.877              \n毛利率                      0.845              \n成本费用利润率              0.892              \n总资产报酬率                0.910              \n净资产收益率                0.792              \n每股收益率                         0.894       \n扣除非经常性损益的每股收益         0.869       \n每股未分配利润                     0.866       \n每股净资产                         0.918       \n存货周转率                                0.758\n总资产周转率                              0.942\n流动资产周转率                            0.947\n\n                 RC1   RC3   RC2\nSS loadings    4.246 3.638 2.769\nProportion Var 0.354 0.303 0.231\nCumulative Var 0.354 0.657 0.888\n\n#绘制因子载荷系数图\nfa.diagram(fa.pc.varimax$loadings, digits = 3)\n\n\n\n\n\n\n\nplot(fa.pc.varimax$loadings, type = \"n\")\n\n\n\n\n\n\n\nlibrary(psych)\nfa.ml.varimax &lt;- fa(case7_1[-1], \n                  nfactors = 3, \n                  fm = \"ml\",\n                  rotate = \"varimax\")\n\nfa.ml.varimax\n\nFactor Analysis using method =  ml\nCall: fa(r = case7_1[-1], nfactors = 3, rotate = \"varimax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                             ML3  ML1   ML2   h2     u2 com\n存货周转率                 -0.11 0.23  0.63 0.46 0.5381 1.3\n总资产周转率                0.11 0.09  0.95 0.92 0.0785 1.0\n流动资产周转率              0.06 0.02  0.96 0.92 0.0803 1.0\n营业利润率                  0.86 0.20  0.15 0.80 0.1957 1.2\n毛利率                      0.81 0.22 -0.28 0.79 0.2126 1.4\n成本费用利润率              0.89 0.34 -0.12 0.92 0.0768 1.3\n总资产报酬率                0.90 0.32  0.10 0.92 0.0769 1.3\n净资产收益率                0.77 0.36  0.41 0.90 0.1029 2.0\n每股收益率                  0.39 0.91  0.12 1.00 0.0048 1.4\n扣除非经常性损益的每股收益  0.42 0.88  0.12 0.98 0.0246 1.5\n每股未分配利润              0.31 0.85  0.23 0.87 0.1311 1.4\n每股净资产                  0.16 0.85  0.07 0.76 0.2448 1.1\n\n                       ML3  ML1  ML2\nSS loadings           4.09 3.55 2.59\nProportion Var        0.34 0.30 0.22\nCumulative Var        0.34 0.64 0.85\nProportion Explained  0.40 0.35 0.25\nCumulative Proportion 0.40 0.75 1.00\n\nMean item complexity =  1.3\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  66  with the objective function =  18.65 with Chi Square =  1010.1\ndf of  the model are 33  and the objective function was  1.75 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  60 with the empirical chi square  4.1  with prob &lt;  1 \nThe total n.obs was  60  with Likelihood Chi Square =  91.42  with prob &lt;  2.2e-07 \n\nTucker Lewis Index of factoring reliability =  0.871\nRMSEA index =  0.171  and the 90 % confidence intervals are  0.132 0.216\nBIC =  -43.7\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML3  ML1  ML2\nCorrelation of (regression) scores with factors   0.98 0.99 0.98\nMultiple R square of scores with factors          0.96 0.99 0.96\nMinimum correlation of possible factor scores     0.92 0.97 0.92\n\n#按因子载荷系数降序排列\nprint(fa.ml.varimax$loadings, digits = 3, cutoff = 0.5,sort = T)\n\n\nLoadings:\n                           ML3    ML1    ML2   \n营业利润率                  0.862              \n毛利率                      0.812              \n成本费用利润率              0.892              \n总资产报酬率                0.901              \n净资产收益率                0.771              \n每股收益率                         0.911       \n扣除非经常性损益的每股收益         0.884       \n每股未分配利润                     0.847       \n每股净资产                         0.851       \n存货周转率                                0.628\n总资产周转率                              0.949\n流动资产周转率                            0.957\n\n                 ML3   ML1   ML2\nSS loadings    4.090 3.549 2.594\nProportion Var 0.341 0.296 0.216\nCumulative Var 0.341 0.637 0.853\n\n\n\n#函数psych::fa，varimax旋转\nlibrary(psych)\nfa.pa.varimax &lt;- fa(case7_1[-1], \n                    nfactors = 3, \n                    fm = \"pa\",\n                    rotate = \"varimax\")\n\nprint(fa.pa.varimax$loadings, digits = 3, cutoff = 0.5,sort = T)\n\n\nLoadings:\n                           PA1    PA3    PA2   \n营业利润率                  0.839              \n毛利率                      0.816              \n成本费用利润率              0.896              \n总资产报酬率                0.906              \n净资产收益率                0.780              \n每股收益率                         0.913       \n扣除非经常性损益的每股收益         0.878       \n每股未分配利润                     0.848       \n每股净资产                         0.851       \n存货周转率                                0.640\n总资产周转率                              0.943\n流动资产周转率                            0.944\n\n                 PA1   PA3   PA2\nSS loadings    4.094 3.533 2.594\nProportion Var 0.341 0.294 0.216\nCumulative Var 0.341 0.636 0.852\n\nplot(fa.pc.varimax$loadings[,1], \n     fa.pc.varimax$loadings[,2])\n\ntext(fa.pc.varimax$loadings[,1], \n     fa.pc.varimax$loadings[,2], \n     rownames(fa.pc.varimax$loadings),\n     cex = 0.3)\n\n\n\n\n\n\n\nbiplot(fa.pc.varimax$scores[,1:2],\n       fa.pc.varimax$loadings[,1:2])\n\n\n\n\n\n\n\nlibrary(scatterplot3d)\nscatterplot3d(fa.pc.varimax$loadings, \n              main=\"3D factor loadings\", \n              color=c(rep(1,3), rep(2,5), rep(3,4)),\n              pch=20)\n\n\n\n\n\n\n\nscatterplot3d(fa.pc.varimax$scores, \n              main=\"3D factor scores\",\n              pch=20)\n\n\n\n\n\n\n\n\n\nfa.pc.varimax$Call\n\nprincipal(r = case7_1[-1], nfactors = 3, rotate = \"varimax\")\n\nfa.pc.varimax &lt;- principal(case7_1[-1], nfactors = 3,\n                           rotate = \"varimax\",\n                           method = \"wls\")\n\n\n\nfa.pc.varimax$scores %&gt;% \n  data.frame() %&gt;% \n  cbind(case7_1$证券名称,.) %&gt;% \n  select(1:2) %&gt;% \n  arrange(desc(RC1))%&gt;% \n  head()\n\n  case7_1$证券名称      RC1\n1           新坐标 3.200275\n2         浙江仙通 1.880036\n3         岱美股份 1.622674\n4         继峰股份 1.438485\n5         兆丰股份 1.240185\n6         中原内配 1.169983\n\nfa.pc.varimax$scores %&gt;% \n  data.frame() %&gt;% \n  cbind(case7_1$证券名称,.) %&gt;% \n  select(1,3) %&gt;% \n  arrange(desc(RC3))%&gt;% \n  head()\n\n  case7_1$证券名称      RC3\n1         兆丰股份 4.239737\n2         苏威孚Ｂ 3.316791\n3         华域汽车 2.615909\n4         德尔股份 1.690839\n5         越博动力 1.594501\n6         宁波华翔 1.556167\n\nfa.pc.varimax$scores %&gt;% \n  data.frame() %&gt;% \n  cbind(case7_1$证券名称,.) %&gt;%\n  select(1,4) %&gt;%  \n  arrange(desc(RC2)) %&gt;% \n  head()\n\n  case7_1$证券名称      RC2\n1         东风科技 2.567504\n2         华域汽车 2.314485\n3         亚普股份 2.308875\n4         众泰汽车 1.693966\n5         交运股份 1.556585\n6         凌云股份 1.353060\n\n\n\n\n教材P160 习题7.7\n\nlibrary(readxl)\nlibrary(tidyverse)\nex7_7 &lt;- read_excel(\"ex6.6.xls\") %&gt;% \n  rename(工业废水排放量 = x1, \n         工业化学需氧量 = x2,\n         工业氨氮排放量 = x3, \n         城镇生活污水排放量 = x4, \n         生活化学需氧量排放量 = x5, \n         生活氨氮排放量 = x6\n         )\n\nrownames(ex7_7) &lt;- ex7_7$城市  \n\n\nfa.pc.varimax &lt;- principal(ex7_7[-1], nfactors = 2,\n                          rotate = \"varimax\")\nfa.pc.varimax\n\nPrincipal Components Analysis\nCall: principal(r = ex7_7[-1], nfactors = 2, rotate = \"varimax\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                      RC1  RC2   h2    u2 com\n工业废水排放量       0.77 0.38 0.74 0.257 1.5\n工业化学需氧量       0.53 0.81 0.93 0.068 1.7\n工业氨氮排放量       0.10 0.96 0.93 0.069 1.0\n城镇生活污水排放量   0.94 0.01 0.89 0.114 1.0\n生活化学需氧量排放量 0.85 0.30 0.81 0.185 1.2\n生活氨氮排放量       0.88 0.35 0.91 0.092 1.3\n\n                       RC1  RC2\nSS loadings           3.28 1.93\nProportion Var        0.55 0.32\nCumulative Var        0.55 0.87\nProportion Explained  0.63 0.37\nCumulative Proportion 0.63 1.00\n\nMean item complexity =  1.3\nTest of the hypothesis that 2 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.06 \n with the empirical chi square  1.82  with prob &lt;  0.77 \n\nFit based upon off diagonal values = 0.99\n\nprint(fa.pc.varimax$loadings, digits = 3, cutoff = 0.5,sort = T)\n\n\nLoadings:\n                     RC1   RC2  \n工业废水排放量       0.774      \n城镇生活污水排放量   0.941      \n生活化学需氧量排放量 0.851      \n生活氨氮排放量       0.884      \n工业化学需氧量       0.531 0.806\n工业氨氮排放量             0.960\n\n                 RC1   RC2\nSS loadings    3.283 1.931\nProportion Var 0.547 0.322\nCumulative Var 0.547 0.869\n\nfa.pc.promax &lt;- principal(ex7_7[-1], nfactors = 2,\n                           rotate = \"promax\")\nfa.pc.promax\n\nPrincipal Components Analysis\nCall: principal(r = ex7_7[-1], nfactors = 2, rotate = \"promax\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                       RC1   RC2   h2    u2 com\n工业废水排放量        0.75  0.18 0.74 0.257 1.1\n工业化学需氧量        0.33  0.75 0.93 0.068 1.4\n工业氨氮排放量       -0.22  1.06 0.93 0.069 1.1\n城镇生活污水排放量    1.07 -0.29 0.89 0.114 1.2\n生活化学需氧量排放量  0.87  0.06 0.81 0.185 1.0\n生活氨氮排放量        0.89  0.11 0.91 0.092 1.0\n\n                       RC1  RC2\nSS loadings           3.40 1.82\nProportion Var        0.57 0.30\nCumulative Var        0.57 0.87\nProportion Explained  0.65 0.35\nCumulative Proportion 0.65 1.00\n\n With component correlations of \n     RC1  RC2\nRC1 1.00 0.54\nRC2 0.54 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.06 \n with the empirical chi square  1.82  with prob &lt;  0.77 \n\nFit based upon off diagonal values = 0.99\n\nprint(fa.pc.promax$loadings, digits = 3, cutoff = 0.5,sort = T)\n\n\nLoadings:\n                     RC1    RC2   \n工业废水排放量        0.753       \n城镇生活污水排放量    1.068       \n生活化学需氧量排放量  0.867       \n生活氨氮排放量        0.887       \n工业化学需氧量               0.745\n工业氨氮排放量               1.064\n\n                 RC1   RC2\nSS loadings    3.401 1.823\nProportion Var 0.567 0.304\nCumulative Var 0.567 0.871\n\nbiplot(fa.pc.promax)\n\n\n\n\n\n\n\n\n\nbiplot(fa.pc.promax$scores[,1:2],\n       fa.pc.promax$loadings[,1:2],\n       xlim = c(-3,3),\n       ylim = c(-3,3),\n       xlabs = ex7_7$城市)\n       \nabline(v = 0, h = 0, lty = 2, col = \"grey25\")\n\n\n\n\n\n\n\n\n\nfa.pc.promax$scores %&gt;% \n  round(3) %&gt;% \n  cbind(ex7_7$城市,.) %&gt;% \n  data.frame() %&gt;% \n  arrange(desc(RC1)) %&gt;% \n  head()\n\n    V1   RC1   RC2\n1 重庆 2.169 1.578\n2 上海 1.996 1.167\n3 广州 1.018 0.168\n4 成都 0.265 -0.65\n5 天津 0.195 0.515\n6 杭州 0.124 0.718\n\nfa.pc.promax$scores %&gt;% \n  round(3) %&gt;% \n  cbind(ex7_7$城市,.) %&gt;% \n  data.frame() %&gt;% \n  arrange(desc(RC2)) %&gt;% \n  head()\n\n      V1    RC1   RC2\n1 石家庄 -0.622 2.264\n2   重庆  2.169 1.578\n3   上海  1.996 1.167\n4   杭州  0.124 0.718\n5   天津  0.195 0.515\n6   广州  1.018 0.168"
  },
  {
    "objectID": "chap7.html#习题1-教材p146例题7.1",
    "href": "chap7.html#习题1-教材p146例题7.1",
    "title": "第7章",
    "section": "习题1: 教材P146,例题7.1",
    "text": "习题1: 教材P146,例题7.1\n完成下列要求：\n1.1 采用主成分(principal component)法估计因子载荷，对因子载荷进行旋转，绘制因子得分和因子载荷图。你提取了几个因子？各个因子的方差贡献率是多少？各个因子主要代表哪些原始变量？\n1.2 采用极大似然法估计因子载荷，对因子载荷进行旋转，绘制因子得分和因子载荷图。\n1.3 采用主因子(principal factor)法估计因子载荷，对因子载荷进行旋转，绘制因子得分和因子载荷图。"
  },
  {
    "objectID": "chap7.html#习题2-教材p151-案例7.1",
    "href": "chap7.html#习题2-教材p151-案例7.1",
    "title": "第7章",
    "section": "习题2: 教材P151， 案例7.1**",
    "text": "习题2: 教材P151， 案例7.1**\n要求：\n2.1实现教材P154的表7-3、表7-4中的估计。\n2.2 绘制P157的图7-5.\n2.3 实现P158-159的表7-5，表7-6，表7-7的因子得分的计算，无需报告完整的表7-5，表7-6，表7-7，截取上述三张表格的前6家公司即可。"
  },
  {
    "objectID": "chap7.html#习题3-教材p160-习题7.7",
    "href": "chap7.html#习题3-教材p160-习题7.7",
    "title": "第7章",
    "section": "习题3: 教材P160， 习题7.7 **",
    "text": "习题3: 教材P160， 习题7.7 **\n要求：\n3.1 对习题7.7的进行因子分析，你使用的因子载荷的估计方法是什么？是否对因子载荷进行了旋转？旋转方法是什么？\n3.2 你提取了几个因子？各个因子的方差贡献率是多少？各个因子主要代表哪些原始变量的信息？\n3.3 绘制因子得分和因子载荷图。"
  },
  {
    "objectID": "ch7case_attitude.html",
    "href": "ch7case_attitude.html",
    "title": "主观态度因子分析",
    "section": "",
    "text": "点击下载数据文件: attitude.xlsx \n数据文件变量含义：\nurban=1,城镇；urban=0, 乡村\nmale=1, 男性；female=1, 女性\nEDU=1，文盲半文盲没上小学；EDU=2，小学；EDU=3，初中；EDU=4，高中/中专/高职；EDU=5，大专/本科/硕士\n年龄\n主要工作年收入"
  },
  {
    "objectID": "ch7case_attitude.html#不同组别因子得分均值的比较",
    "href": "ch7case_attitude.html#不同组别因子得分均值的比较",
    "title": "主观态度因子分析",
    "section": "不同组别因子得分均值的比较",
    "text": "不同组别因子得分均值的比较\n\n# 分析男性和女性在各个因子上的得分差异\nfinal_data %&gt;%\n  group_by(male) %&gt;%\n  summarise(across(starts_with(\"RC\"), \n                   mean, na.rm = TRUE))\n\n# A tibble: 2 × 7\n   male     RC1     RC2     RC5     RC4     RC3      RC6\n  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     0  0.0186  0.0622  0.0116  0.0158 -0.0526  0.00344\n2     1 -0.0372 -0.124  -0.0233 -0.0316  0.105  -0.00689"
  },
  {
    "objectID": "ch7case_attitude.html#不同组别因子得分分布的比较",
    "href": "ch7case_attitude.html#不同组别因子得分分布的比较",
    "title": "主观态度因子分析",
    "section": "不同组别因子得分分布的比较",
    "text": "不同组别因子得分分布的比较\n\n# 分析男性和女性在因子1上的得分的分布的直方图\nfinal_data %&gt;%\n  ggplot(aes(RC1, fill = as.factor(male))) +\n  geom_histogram(col = 1, position = \"identity\", alpha = 0.5) +\n  labs(fill = \"Male\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal() +\n  ggtitle(\"Distribution of RC1 by Gender\")\n\n\n\n\n\n\n\n\n\n# 分析不同教育水平在各个因子上的得分差异因1的分布的直方图\n\nfinal_data %&gt;%\n  ggplot(aes(RC1, fill = as.factor(EDU))) +\n  geom_histogram(col = 1, position = \"identity\", alpha = 0.5) +\n  labs(fill = \"EDU\") +\n  theme_minimal() +\n  ggtitle(\"Distribution of RC1 by Education\")"
  },
  {
    "objectID": "chap8slide.html",
    "href": "chap8slide.html",
    "title": "Chapter 8 对应分析",
    "section": "",
    "text": "注意：本讲义供学习交流使用，请勿用于商业用途"
  },
  {
    "objectID": "caR.html",
    "href": "caR.html",
    "title": "8 CA在R中的实现",
    "section": "",
    "text": "本章介绍R中的对应分析。\n# 安装包\ninstall.packages(\"tidyverse\")\ninstall.packages(\"FactoMineR\")\ninstall.packages(\"factoextra\")\ninstall.packages(\"MASS\")\ninstall.packages(\"gplots\")\ninstall.packages(\"corrplot\")\ninstall.packages(\"RColorBrewer\")\n# 加载包\nlibrary(tidyverse)\nlibrary(FactoMineR)\nlibrary(factoextra)\nlibrary(MASS)\nlibrary(gplots)\nlibrary(RColorBrewer)\n#导入数据，修改行名，列名\nlibrary(MASS)\ndata(caith)\n\nrownames(caith) &lt;- c(\"eye.blue\", \"eye.light\", \"eye.medium\", \"eye.dark\")\n\ncolnames(caith) &lt;- c(\"hair.fair\", \"hair.red\", \"hair.medium\",\n                     \"hair.dark\", \"hair.black\")"
  },
  {
    "objectID": "caR.html#碎石图scree-plot",
    "href": "caR.html#碎石图scree-plot",
    "title": "8 CA在R中的实现",
    "section": "碎石图scree plot",
    "text": "碎石图scree plot\n\n#绘制scree plot\nlibrary(factoextra)\nfviz_screeplot(res.ca, addlabels = TRUE, ylim = c(0, 100))\n\nWarning in geom_bar(stat = \"identity\", fill = barfill, color = barcolor, :\nIgnoring empty aesthetic: `width`.\n\n\n\n\n\n\n\n\n\n\n# symmetric plot\nlibrary(factoextra)\nfviz_ca_biplot(res.ca, repel = TRUE)\n\n\n\n\n\n\n\ndimdesc(res.ca)\n\n$`Dim 1`\n$`Dim 1`$row\n                 coord\neye.light  -0.44070764\neye.blue   -0.40029985\neye.medium  0.03361434\neye.dark    0.70273880\n\n$`Dim 1`$col\n                  coord\nhair.fair   -0.54399533\nhair.red    -0.23326097\nhair.medium -0.04202412\nhair.dark    0.58870853\nhair.black   1.09438828\n\n\n$`Dim 2`\n$`Dim 2`$row\n                 coord\neye.medium -0.24500190\neye.light   0.08846303\neye.dark    0.13391383\neye.blue    0.16541100\n\n$`Dim 2`$col\n                  coord\nhair.medium -0.20830421\nhair.red     0.04827895\nhair.dark    0.10395044\nhair.fair    0.17384449\nhair.black   0.28643670\n\n#Rows are represented by blue points and columns by red triangles."
  },
  {
    "objectID": "caR.html#行变量绘图-graph-of-row-variables",
    "href": "caR.html#行变量绘图-graph-of-row-variables",
    "title": "8 CA在R中的实现",
    "section": "行变量绘图 Graph of row variables",
    "text": "行变量绘图 Graph of row variables\n\nrow &lt;- get_ca_row(res.ca)\nrow\n\nCorrespondence Analysis - Results for rows\n ===================================================\n  Name       Description                \n1 \"$coord\"   \"Coordinates for the rows\" \n2 \"$cos2\"    \"Cos2 for the rows\"        \n3 \"$contrib\" \"contributions of the rows\"\n4 \"$inertia\" \"Inertia of the rows\"      \n\n\nrow$coord: coordinates of each row point in each dimension (1, 2 and 3). Used to create the scatter plot.\nrow$cos2: quality of representation of rows.\nvar$contrib: contribution of rows (in %) to the definition of the dimensions.\n\n#Coordinates of row points\n\nrow$coord[,1:2]\n\n                 Dim 1       Dim 2\neye.blue   -0.40029985  0.16541100\neye.light  -0.44070764  0.08846303\neye.medium  0.03361434 -0.24500190\neye.dark    0.70273880  0.13391383\n\nfviz_ca_row(res.ca, repel = TRUE)\n\n\n\n\n\n\n\nfviz_ca_row(res.ca, col.row=\"steelblue\", shape.row = 15, repel = TRUE)\n\n\n\n\n\n\n\n\n\n#Quality of representation of rows\n\n#The quality of representation of the rows on the factor map is called the squared cosine (cos2) or the squared correlations.\n\nrow$cos2\n\n                Dim 1      Dim 2        Dim 3\neye.blue   0.83581532 0.14271455 2.147013e-02\neye.light  0.95648915 0.03853918 4.971671e-03\neye.medium 0.01846682 0.98102924 5.039418e-04\neye.dark   0.96492376 0.03503934 3.689437e-05\n\n# Color by cos2 values: quality on the factor map\nfviz_ca_row(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)\n\n\n\n\n\n\n\n# Change the transparency by cos2 values\nfviz_ca_row(res.ca, alpha.row=\"cos2\")\n\n\n\n\n\n\n\n\n\n#visualize the cos2 of row points on all the dimensions\nlibrary(corrplot)\ncorrplot(row$cos2, is.corr=FALSE)\n\n\n\n\n\n\n\n\n\n# Cos2 of rows on Dim.1\nfviz_cos2(res.ca, choice = \"row\", axes = 1)\n\n\n\n\n\n\n\n# Cos2 of rows on Dim.2\nfviz_cos2(res.ca, choice = \"row\", axes = 2)\n\n\n\n\n\n\n\n# Cos2 of rows on Dim.1 and Dim.2\nfviz_cos2(res.ca, choice = \"row\", axes = 1:2)\n\n\n\n\n\n\n\n\n\n#Coordinates of row points\nrow$contrib\n\n                Dim 1     Dim 2     Dim 3\neye.blue   10.7191765 12.120781 63.831659\neye.light  28.5906733  7.628833 34.450625\neye.medium  0.1867536 65.700687  1.181429\neye.dark   60.5033967 14.549698  0.536287\n\n# Contributions of rows to dimension 1\nfviz_contrib(res.ca, choice = \"row\", axes = 1)\n\n\n\n\n\n\n\n# Contributions of rows to dimension 2\nfviz_contrib(res.ca, choice = \"row\", axes = 2, top = 2)\n\n\n\n\n\n\n\n\n\n#The most important (or, contributing) row points can be highlighted on the scatter plot as follow:\n\nfviz_ca_row(res.ca, col.row = \"contrib\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)"
  },
  {
    "objectID": "caR.html#列变量绘图-graph-of-column-variables",
    "href": "caR.html#列变量绘图-graph-of-column-variables",
    "title": "8 CA在R中的实现",
    "section": "列变量绘图 Graph of column variables",
    "text": "列变量绘图 Graph of column variables\n\nfviz_ca_col(res.ca, col.col = \"cos2\", \n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE)"
  },
  {
    "objectID": "caR.html#筛选画图变量filter-results",
    "href": "caR.html#筛选画图变量filter-results",
    "title": "8 CA在R中的实现",
    "section": "筛选画图变量Filter Results",
    "text": "筛选画图变量Filter Results\n\n# Visualize rows with cos2 &gt;= 0.9\nfviz_ca_row(res.ca, select.row = list(cos2 = 0.9), repel  = T)\n\n\n\n\n\n\n\n# Top 3 active rows  with the highest cos2\nfviz_ca_row(res.ca, select.row = list(cos2 = 3), repel  = T)\n\n\n\n\n\n\n\n# Select by names\nname &lt;- list(name = c(\"eye.dark\", \"eye.medium\"))\nfviz_ca_row(res.ca, select.row = name, repel  = T)\n\n\n\n\n\n\n\n# Top 3 contributing rows and columns\nfviz_ca_biplot(res.ca, select.row = list(contrib = 3), \n               select.col = list(contrib = 3), repel  = T) +\n  theme_minimal()"
  },
  {
    "objectID": "8ex.html",
    "href": "8ex.html",
    "title": "8 对应分析习题答案",
    "section": "",
    "text": "提示：数据请自行录入，可在EXCEL录入好后，再导入R。\n要求： 2.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n2.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n2.3 绘制对应分析图。\n2.4 绘制行变量的contribution、cos2的图像。\n2.5 绘制列变量的contribution、cos2的图像。\n2.6 从图中可以发现哪些组别关系紧密？\n\n\n\n#创建列联表的数据框\nex2 &lt;- data.frame(\n  very_dissatisfied = c(42,35,13,7,3),\n  somewhat_dissatified = c(82,62,28,18,7),\n  somewhat_satisfied = c(67,165,92,54,32),\n  very_satisfied = c(55, 118,81,75,54)\n)\n\n#给ex2添加行名，以便在图中能添加标签\nrownames(ex2) &lt;- c(\"less than 10k\", \"10k-30k\",\n                   \"30k-50k\", \"50k-100k\", \"more than 100k\")\nex2\n\n               very_dissatisfied somewhat_dissatified somewhat_satisfied\nless than 10k                 42                   82                 67\n10k-30k                       35                   62                165\n30k-50k                       13                   28                 92\n50k-100k                       7                   18                 54\nmore than 100k                 3                    7                 32\n               very_satisfied\nless than 10k              55\n10k-30k                   118\n30k-50k                    81\n50k-100k                   75\nmore than 100k             54\n\n\n\n\n\n\n#2.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n\nchisq.test(ex2)\n\n\n    Pearson's Chi-squared test\n\ndata:  ex2\nX-squared = 118.1, df = 12, p-value &lt; 2.2e-16\n\n#卡方检验统计量是118.1, P值接近于0。在0.01的显著性水平下，拒绝“收入等级和满意度等级相互独立”的原假设。\n\n\n\n\n\n#2.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n\nlibrary(FactoMineR)\nres.ca &lt;- CA(ex2, graph = FALSE)\n\n#绘制scree plot\nlibrary(factoextra)\nfviz_screeplot(res.ca, addlabels = TRUE, ylim = c(0, 100))\n\nWarning in geom_bar(stat = \"identity\", fill = barfill, color = barcolor, :\nIgnoring empty aesthetic: `width`.\n\n\n\n\n\n\n\n\n#提取两个维度，维度1的贡献是86.8%， 维度2的贡献是13.0%. \n\n\n\n\n\n#2.3 绘制对应分析图\nCA(ex2)\n\n\n\n\n\n\n\n\n**Results of the Correspondence Analysis (CA)**\nThe row variable has  5  categories; the column variable has 4 categories\nThe chi square of independence between the two variables is equal to 118.0959 (p-value =  1.48029e-19 ).\n*The results are available in the following objects:\n\n   name              description                   \n1  \"$eig\"            \"eigenvalues\"                 \n2  \"$col\"            \"results for the columns\"     \n3  \"$col$coord\"      \"coord. for the columns\"      \n4  \"$col$cos2\"       \"cos2 for the columns\"        \n5  \"$col$contrib\"    \"contributions of the columns\"\n6  \"$row\"            \"results for the rows\"        \n7  \"$row$coord\"      \"coord. for the rows\"         \n8  \"$row$cos2\"       \"cos2 for the rows\"           \n9  \"$row$contrib\"    \"contributions of the rows\"   \n10 \"$call\"           \"summary called parameters\"   \n11 \"$call$marge.col\" \"weights of the columns\"      \n12 \"$call$marge.row\" \"weights of the rows\"         \n\n\n\n\n\n\n#2.4 绘制行变量的contribution的图像。\n\n#行变量对维度1的贡献\nfviz_contrib(res.ca, choice = \"row\", axes = 1)\n\n\n\n\n\n\n\n#行变量对维度2的贡献\nfviz_contrib(res.ca, choice = \"row\", axes = 2)\n\n\n\n\n\n\n\n\n\n#2.4 绘制行变量的cos2的图像。\nrow &lt;- get_ca_row(res.ca)\nrow$cos2\n\n                     Dim 1      Dim 2        Dim 3\nless than 10k  0.969960339 0.03003387 5.791844e-06\n10k-30k        0.005022974 0.98842064 6.556387e-03\n30k-50k        0.848488225 0.14144329 1.006848e-02\n50k-100k       0.828708215 0.16984574 1.446041e-03\nmore than 100k 0.823408163 0.17415844 2.433397e-03\n\n#维度对行变量的代表性cos2（representation）\nfviz_ca_row(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n#2.5 绘制列变量的contribution的图像。\n\n#列变量对维度1的贡献\nfviz_contrib(res.ca, choice = \"col\", axes = 1)\n\n\n\n\n\n\n\n#列变量对维度2的贡献\nfviz_contrib(res.ca, choice = \"col\", axes = 2)\n\n\n\n\n\n\n\n\n\n#2.5 绘制列变量的cos2的图像。\ncol &lt;- get_ca_col(res.ca)\ncol$cos2\n\n                         Dim 1        Dim 2        Dim 3\nvery_dissatisfied    0.9950893 0.0002326784 4.677993e-03\nsomewhat_dissatified 0.9786700 0.0199298451 1.400105e-03\nsomewhat_satisfied   0.3068527 0.6930317994 1.155260e-04\nvery_satisfied       0.8349172 0.1650352038 4.757035e-05\n\n#维度对列变量的代表性cos2（representation）\nfviz_ca_col(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n从图中可以发现哪些组别关系紧密？\n\nCA(ex2)\n\n\n\n\n\n\n\n\n**Results of the Correspondence Analysis (CA)**\nThe row variable has  5  categories; the column variable has 4 categories\nThe chi square of independence between the two variables is equal to 118.0959 (p-value =  1.48029e-19 ).\n*The results are available in the following objects:\n\n   name              description                   \n1  \"$eig\"            \"eigenvalues\"                 \n2  \"$col\"            \"results for the columns\"     \n3  \"$col$coord\"      \"coord. for the columns\"      \n4  \"$col$cos2\"       \"cos2 for the columns\"        \n5  \"$col$contrib\"    \"contributions of the columns\"\n6  \"$row\"            \"results for the rows\"        \n7  \"$row$coord\"      \"coord. for the rows\"         \n8  \"$row$cos2\"       \"cos2 for the rows\"           \n9  \"$row$contrib\"    \"contributions of the rows\"   \n10 \"$call\"           \"summary called parameters\"   \n11 \"$call$marge.col\" \"weights of the columns\"      \n12 \"$call$marge.row\" \"weights of the rows\"         \n\n\n收入介于5万至10万与非常满意关系紧密。\n收入小于1万与有些不满意关系紧密。\n收入介于1万至3万与有些满意关系紧密。"
  },
  {
    "objectID": "8ex.html#创建列联表的数据框",
    "href": "8ex.html#创建列联表的数据框",
    "title": "8 对应分析习题答案",
    "section": "",
    "text": "#创建列联表的数据框\nex2 &lt;- data.frame(\n  very_dissatisfied = c(42,35,13,7,3),\n  somewhat_dissatified = c(82,62,28,18,7),\n  somewhat_satisfied = c(67,165,92,54,32),\n  very_satisfied = c(55, 118,81,75,54)\n)\n\n#给ex2添加行名，以便在图中能添加标签\nrownames(ex2) &lt;- c(\"less than 10k\", \"10k-30k\",\n                   \"30k-50k\", \"50k-100k\", \"more than 100k\")\nex2\n\n               very_dissatisfied somewhat_dissatified somewhat_satisfied\nless than 10k                 42                   82                 67\n10k-30k                       35                   62                165\n30k-50k                       13                   28                 92\n50k-100k                       7                   18                 54\nmore than 100k                 3                    7                 32\n               very_satisfied\nless than 10k              55\n10k-30k                   118\n30k-50k                    81\n50k-100k                   75\nmore than 100k             54"
  },
  {
    "objectID": "8ex.html#独立性检验",
    "href": "8ex.html#独立性检验",
    "title": "8 对应分析习题答案",
    "section": "",
    "text": "#2.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n\nchisq.test(ex2)\n\n\n    Pearson's Chi-squared test\n\ndata:  ex2\nX-squared = 118.1, df = 12, p-value &lt; 2.2e-16\n\n#卡方检验统计量是118.1, P值接近于0。在0.01的显著性水平下，拒绝“收入等级和满意度等级相互独立”的原假设。"
  },
  {
    "objectID": "8ex.html#绘制碎石图",
    "href": "8ex.html#绘制碎石图",
    "title": "8 对应分析习题答案",
    "section": "",
    "text": "#2.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n\nlibrary(FactoMineR)\nres.ca &lt;- CA(ex2, graph = FALSE)\n\n#绘制scree plot\nlibrary(factoextra)\nfviz_screeplot(res.ca, addlabels = TRUE, ylim = c(0, 100))\n\nWarning in geom_bar(stat = \"identity\", fill = barfill, color = barcolor, :\nIgnoring empty aesthetic: `width`.\n\n\n\n\n\n\n\n\n#提取两个维度，维度1的贡献是86.8%， 维度2的贡献是13.0%."
  },
  {
    "objectID": "8ex.html#绘制对应分析图",
    "href": "8ex.html#绘制对应分析图",
    "title": "8 对应分析习题答案",
    "section": "",
    "text": "#2.3 绘制对应分析图\nCA(ex2)\n\n\n\n\n\n\n\n\n**Results of the Correspondence Analysis (CA)**\nThe row variable has  5  categories; the column variable has 4 categories\nThe chi square of independence between the two variables is equal to 118.0959 (p-value =  1.48029e-19 ).\n*The results are available in the following objects:\n\n   name              description                   \n1  \"$eig\"            \"eigenvalues\"                 \n2  \"$col\"            \"results for the columns\"     \n3  \"$col$coord\"      \"coord. for the columns\"      \n4  \"$col$cos2\"       \"cos2 for the columns\"        \n5  \"$col$contrib\"    \"contributions of the columns\"\n6  \"$row\"            \"results for the rows\"        \n7  \"$row$coord\"      \"coord. for the rows\"         \n8  \"$row$cos2\"       \"cos2 for the rows\"           \n9  \"$row$contrib\"    \"contributions of the rows\"   \n10 \"$call\"           \"summary called parameters\"   \n11 \"$call$marge.col\" \"weights of the columns\"      \n12 \"$call$marge.row\" \"weights of the rows\""
  },
  {
    "objectID": "8ex.html#绘制行变量的contributioncos2图像",
    "href": "8ex.html#绘制行变量的contributioncos2图像",
    "title": "8 对应分析习题答案",
    "section": "",
    "text": "#2.4 绘制行变量的contribution的图像。\n\n#行变量对维度1的贡献\nfviz_contrib(res.ca, choice = \"row\", axes = 1)\n\n\n\n\n\n\n\n#行变量对维度2的贡献\nfviz_contrib(res.ca, choice = \"row\", axes = 2)\n\n\n\n\n\n\n\n\n\n#2.4 绘制行变量的cos2的图像。\nrow &lt;- get_ca_row(res.ca)\nrow$cos2\n\n                     Dim 1      Dim 2        Dim 3\nless than 10k  0.969960339 0.03003387 5.791844e-06\n10k-30k        0.005022974 0.98842064 6.556387e-03\n30k-50k        0.848488225 0.14144329 1.006848e-02\n50k-100k       0.828708215 0.16984574 1.446041e-03\nmore than 100k 0.823408163 0.17415844 2.433397e-03\n\n#维度对行变量的代表性cos2（representation）\nfviz_ca_row(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)"
  },
  {
    "objectID": "8ex.html#绘制列变量的contributioncos2图像",
    "href": "8ex.html#绘制列变量的contributioncos2图像",
    "title": "8 对应分析习题答案",
    "section": "",
    "text": "#2.5 绘制列变量的contribution的图像。\n\n#列变量对维度1的贡献\nfviz_contrib(res.ca, choice = \"col\", axes = 1)\n\n\n\n\n\n\n\n#列变量对维度2的贡献\nfviz_contrib(res.ca, choice = \"col\", axes = 2)\n\n\n\n\n\n\n\n\n\n#2.5 绘制列变量的cos2的图像。\ncol &lt;- get_ca_col(res.ca)\ncol$cos2\n\n                         Dim 1        Dim 2        Dim 3\nvery_dissatisfied    0.9950893 0.0002326784 4.677993e-03\nsomewhat_dissatified 0.9786700 0.0199298451 1.400105e-03\nsomewhat_satisfied   0.3068527 0.6930317994 1.155260e-04\nvery_satisfied       0.8349172 0.1650352038 4.757035e-05\n\n#维度对列变量的代表性cos2（representation）\nfviz_ca_col(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)"
  },
  {
    "objectID": "8ex.html#结论",
    "href": "8ex.html#结论",
    "title": "8 对应分析习题答案",
    "section": "",
    "text": "从图中可以发现哪些组别关系紧密？\n\nCA(ex2)\n\n\n\n\n\n\n\n\n**Results of the Correspondence Analysis (CA)**\nThe row variable has  5  categories; the column variable has 4 categories\nThe chi square of independence between the two variables is equal to 118.0959 (p-value =  1.48029e-19 ).\n*The results are available in the following objects:\n\n   name              description                   \n1  \"$eig\"            \"eigenvalues\"                 \n2  \"$col\"            \"results for the columns\"     \n3  \"$col$coord\"      \"coord. for the columns\"      \n4  \"$col$cos2\"       \"cos2 for the columns\"        \n5  \"$col$contrib\"    \"contributions of the columns\"\n6  \"$row\"            \"results for the rows\"        \n7  \"$row$coord\"      \"coord. for the rows\"         \n8  \"$row$cos2\"       \"cos2 for the rows\"           \n9  \"$row$contrib\"    \"contributions of the rows\"   \n10 \"$call\"           \"summary called parameters\"   \n11 \"$call$marge.col\" \"weights of the columns\"      \n12 \"$call$marge.row\" \"weights of the rows\"         \n\n\n收入介于5万至10万与非常满意关系紧密。\n收入小于1万与有些不满意关系紧密。\n收入介于1万至3万与有些满意关系紧密。"
  },
  {
    "objectID": "8ex.html#创建列联表的数据框-1",
    "href": "8ex.html#创建列联表的数据框-1",
    "title": "8 对应分析习题答案",
    "section": "创建列联表的数据框",
    "text": "创建列联表的数据框\n\n#创建列联表的数据框\nex3 &lt;- data.frame(\n  American = c(37,52,33,6),\n  European = c(14,15,15,1),\n  Japanese = c(51,44,63,8)\n)\n\n#给ex2添加行名，以便在图中能添加标签\nrownames(ex3) &lt;- c(\"Married\", \"Married with Kids\",\n                   \"Single\", \"Single with Kids\")\nex3\n\n                  American European Japanese\nMarried                 37       14       51\nMarried with Kids       52       15       44\nSingle                  33       15       63\nSingle with Kids         6        1        8"
  },
  {
    "objectID": "8ex.html#独立性检验-1",
    "href": "8ex.html#独立性检验-1",
    "title": "8 对应分析习题答案",
    "section": "3.1 独立性检验",
    "text": "3.1 独立性检验\n\n#3.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n\nchisq.test(ex3)\n\n\n    Pearson's Chi-squared test\n\ndata:  ex3\nX-squared = 8.3495, df = 6, p-value = 0.2136\n\nchisq.test(ex3)$expected\n\n                   American European  Japanese\nMarried           38.513274 13.53982 49.946903\nMarried with Kids 41.911504 14.73451 54.353982\nSingle            41.911504 14.73451 54.353982\nSingle with Kids   5.663717  1.99115  7.345133\n\n#卡方检验统计量是8.3495, P值等于0.2136。在0.10的显著性水平下，不拒绝“婚姻状况和汽车类型相互独立”的原假设。\n\n\n#3.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n\nfisher.test(ex3, workspace = 2e7)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  ex3\np-value = 0.2145\nalternative hypothesis: two.sided\n\n#卡方检验统计量是118.1, P值接近于0。在0.01的显著性水平下，拒绝“收入等级和满意度等级相互独立”的原假设。"
  },
  {
    "objectID": "8ex.html#绘制碎石图-1",
    "href": "8ex.html#绘制碎石图-1",
    "title": "8 对应分析习题答案",
    "section": "3.2 绘制碎石图",
    "text": "3.2 绘制碎石图\n\n#3.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n\nlibrary(FactoMineR)\nres.ca &lt;- CA(ex3, graph = FALSE)\n\n#绘制scree plot\nlibrary(factoextra)\nfviz_screeplot(res.ca, addlabels = TRUE, ylim = c(0, 100))\n\nWarning in geom_bar(stat = \"identity\", fill = barfill, color = barcolor, :\nIgnoring empty aesthetic: `width`.\n\n\n\n\n\n\n\n\n#提取两个维度，维度1的贡献是92.8%， 维度2的贡献是7.2%."
  },
  {
    "objectID": "8ex.html#绘制对应分析图-1",
    "href": "8ex.html#绘制对应分析图-1",
    "title": "8 对应分析习题答案",
    "section": "3.3 绘制对应分析图",
    "text": "3.3 绘制对应分析图\n\n#2.3 绘制对应分析图\nCA(ex3)\n\n\n\n\n\n\n\n\n**Results of the Correspondence Analysis (CA)**\nThe row variable has  4  categories; the column variable has 3 categories\nThe chi square of independence between the two variables is equal to 8.349475 (p-value =  0.2136014 ).\n*The results are available in the following objects:\n\n   name              description                   \n1  \"$eig\"            \"eigenvalues\"                 \n2  \"$col\"            \"results for the columns\"     \n3  \"$col$coord\"      \"coord. for the columns\"      \n4  \"$col$cos2\"       \"cos2 for the columns\"        \n5  \"$col$contrib\"    \"contributions of the columns\"\n6  \"$row\"            \"results for the rows\"        \n7  \"$row$coord\"      \"coord. for the rows\"         \n8  \"$row$cos2\"       \"cos2 for the rows\"           \n9  \"$row$contrib\"    \"contributions of the rows\"   \n10 \"$call\"           \"summary called parameters\"   \n11 \"$call$marge.col\" \"weights of the columns\"      \n12 \"$call$marge.row\" \"weights of the rows\""
  },
  {
    "objectID": "8ex.html#绘制行变量的contributioncos2图像-1",
    "href": "8ex.html#绘制行变量的contributioncos2图像-1",
    "title": "8 对应分析习题答案",
    "section": "3.4 绘制行变量的contribution/cos2图像",
    "text": "3.4 绘制行变量的contribution/cos2图像\n\n#3.4 绘制行变量的contribution的图像。\n\n#行变量对维度1的贡献\nfviz_contrib(res.ca, choice = \"row\", axes = 1)\n\n\n\n\n\n\n\n#行变量对维度2的贡献\nfviz_contrib(res.ca, choice = \"row\", axes = 2)\n\n\n\n\n\n\n\n\n\n#3.4 绘制行变量的cos2的图像。\nrow &lt;- get_ca_row(res.ca)\nrow$cos2\n\n                        Dim 1       Dim 2\nMarried           0.812065457 0.187934543\nMarried with Kids 0.998972772 0.001027228\nSingle            0.998031174 0.001968826\nSingle with Kids  0.005440686 0.994559314\n\n#维度对行变量的代表性cos2（representation）\nfviz_ca_row(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)"
  },
  {
    "objectID": "8ex.html#绘制列变量的contributioncos2图像-1",
    "href": "8ex.html#绘制列变量的contributioncos2图像-1",
    "title": "8 对应分析习题答案",
    "section": "3.5 绘制列变量的contribution/cos2图像",
    "text": "3.5 绘制列变量的contribution/cos2图像\n\n#3.5 绘制列变量的contribution的图像。\n\n#列变量对维度1的贡献\nfviz_contrib(res.ca, choice = \"col\", axes = 1)\n\n\n\n\n\n\n\n#列变量对维度2的贡献\nfviz_contrib(res.ca, choice = \"col\", axes = 2)\n\n\n\n\n\n\n\n\n\n#3.5 绘制列变量的cos2的图像。\ncol &lt;- get_ca_col(res.ca)\ncol$cos2\n\n                Dim 1       Dim 2\nAmerican 0.9919873782 0.008012622\nEuropean 0.0001441929 0.999855807\nJapanese 0.9871383541 0.012861646\n\n#维度对列变量的代表性cos2（representation）\nfviz_ca_col(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)"
  },
  {
    "objectID": "8ex.html#结论-1",
    "href": "8ex.html#结论-1",
    "title": "8 对应分析习题答案",
    "section": "3.6 结论",
    "text": "3.6 结论\n从图中可以发现哪些组别关系紧密？\n\n\n\n\n\n\n\n\n\n**Results of the Correspondence Analysis (CA)**\nThe row variable has  4  categories; the column variable has 3 categories\nThe chi square of independence between the two variables is equal to 8.349475 (p-value =  0.2136014 ).\n*The results are available in the following objects:\n\n   name              description                   \n1  \"$eig\"            \"eigenvalues\"                 \n2  \"$col\"            \"results for the columns\"     \n3  \"$col$coord\"      \"coord. for the columns\"      \n4  \"$col$cos2\"       \"cos2 for the columns\"        \n5  \"$col$contrib\"    \"contributions of the columns\"\n6  \"$row\"            \"results for the rows\"        \n7  \"$row$coord\"      \"coord. for the rows\"         \n8  \"$row$cos2\"       \"cos2 for the rows\"           \n9  \"$row$contrib\"    \"contributions of the rows\"   \n10 \"$call\"           \"summary called parameters\"   \n11 \"$call$marge.col\" \"weights of the columns\"      \n12 \"$call$marge.row\" \"weights of the rows\"         \n\n\n单身与日系车关系紧密。\n已婚有孩子与美系车关系紧密。\n已婚、单身有孩子的购车倾向不明显。"
  },
  {
    "objectID": "caR.html#习题1-发色和眼球颜色-教材p165例题8.1",
    "href": "caR.html#习题1-发色和眼球颜色-教材p165例题8.1",
    "title": "8 CA在R中的实现",
    "section": "习题1: 发色和眼球颜色 教材P165,例题8.1",
    "text": "习题1: 发色和眼球颜色 教材P165,例题8.1\n要求：\n1.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n1.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n1.3 绘制对应分析图。\n1.4 绘制行变量的contribution、cos2的图像。\n1.5 绘制列变量的contribution、cos2的图像。列变量的哪几个组别是相对重要的组别？\n1.6 从图中可以发现哪些组别关系紧密？"
  },
  {
    "objectID": "caR.html#习题2-收入满意度",
    "href": "caR.html#习题2-收入满意度",
    "title": "8 CA在R中的实现",
    "section": "习题2: 收入&满意度",
    "text": "习题2: 收入&满意度\n\n提示：数据请自行录入，可在EXCEL录入好后，再导入R。\n要求： 2.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n2.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n2.3 绘制对应分析图。\n2.4 绘制行变量的contribution、cos2的图像。\n2.5 绘制列变量的contribution、cos2的图像。\n2.6 从图中可以发现哪些组别关系紧密？"
  },
  {
    "objectID": "caR.html#习题3-婚姻状况汽车偏好",
    "href": "caR.html#习题3-婚姻状况汽车偏好",
    "title": "8 CA在R中的实现",
    "section": "习题3: 婚姻状况&汽车偏好",
    "text": "习题3: 婚姻状况&汽车偏好\n\n提示：数据请自行录入，可在EXCEL录入好后，再导入R。\n要求： 3.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n3.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n3.3 绘制对应分析图。\n3.4 绘制行变量的contribution、cos2的图像。\n3.5 绘制列变量的contribution、cos2的图像。\n3.6 从图中可以发现哪些组别关系紧密？"
  },
  {
    "objectID": "chap8.html#习题1-发色和眼球颜色-教材p165例题8.1",
    "href": "chap8.html#习题1-发色和眼球颜色-教材p165例题8.1",
    "title": "第8章",
    "section": "习题1: 发色和眼球颜色 教材P165,例题8.1",
    "text": "习题1: 发色和眼球颜色 教材P165,例题8.1\n要求：\n1.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n1.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n1.3 绘制对应分析图。\n1.4 绘制行变量的contribution、cos2的图像。\n1.5 绘制列变量的contribution、cos2的图像。列变量的哪几个组别是相对重要的组别？\n1.6 从图中可以发现哪些组别关系紧密？"
  },
  {
    "objectID": "chap8.html#习题2-收入满意度",
    "href": "chap8.html#习题2-收入满意度",
    "title": "第8章",
    "section": "习题2: 收入&满意度",
    "text": "习题2: 收入&满意度\n\n提示：数据请自行录入，可在EXCEL录入好后，再导入R。\n要求： 2.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n2.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n2.3 绘制对应分析图。\n2.4 绘制行变量的contribution、cos2的图像。\n2.5 绘制列变量的contribution、cos2的图像。\n2.6 从图中可以发现哪些组别关系紧密？"
  },
  {
    "objectID": "chap8.html#习题3-婚姻状况汽车偏好",
    "href": "chap8.html#习题3-婚姻状况汽车偏好",
    "title": "第8章",
    "section": "习题3: 婚姻状况&汽车偏好",
    "text": "习题3: 婚姻状况&汽车偏好\n\n提示：数据请自行录入，可在EXCEL录入好后，再导入R。\n要求： 3.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n3.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n3.3 绘制对应分析图。\n3.4 绘制行变量的contribution、cos2的图像。\n3.5 绘制列变量的contribution、cos2的图像。\n3.6 从图中可以发现哪些组别关系紧密？"
  },
  {
    "objectID": "caR.html#factominerca",
    "href": "caR.html#factominerca",
    "title": "8 CA在R中的实现",
    "section": "FactoMineR:CA()",
    "text": "FactoMineR:CA()\n\nlibrary(FactoMineR)\n\nres.ca &lt;- CA(caith, graph = FALSE)\n\nres.ca %&gt;% summary()\n\n\nCall:\nCA(X = caith, graph = FALSE) \n\nThe chi square of independence between the two variables is equal to 1240.039 (p-value =  4.123993e-258 ).\n\nEigenvalues\n                       Dim.1   Dim.2   Dim.3\nVariance               0.199   0.030   0.001\n% of var.             86.556  13.070   0.373\nCumulative % of var.  86.556  99.627 100.000\n\nRows\n              Iner*1000     Dim.1     ctr    cos2     Dim.2     ctr    cos2  \neye.blue    |    25.553 |  -0.400  10.719   0.836 |   0.165  12.121   0.143 |\neye.light   |    59.557 |  -0.441  28.591   0.956 |   0.088   7.629   0.039 |\neye.medium  |    20.149 |   0.034   0.187   0.018 |  -0.245  65.701   0.981 |\neye.dark    |   124.932 |   0.703  60.503   0.965 |   0.134  14.550   0.035 |\n              Dim.3     ctr    cos2  \neye.blue     -0.064  63.832   0.021 |\neye.light     0.032  34.451   0.005 |\neye.medium   -0.006   1.181   0.001 |\neye.dark      0.004   0.536   0.000 |\n\nColumns\n              Iner*1000    Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3\nhair.fair   |    88.134 | -0.544 40.116  0.907 |  0.174 27.131  0.093 | -0.013\nhair.red    |     3.752 | -0.233  1.450  0.770 |  0.048  0.411  0.033 |  0.118\nhair.medium |    17.918 | -0.042  0.352  0.039 | -0.208 57.211  0.961 | -0.003\nhair.dark   |    92.308 |  0.589 44.915  0.969 |  0.104  9.274  0.030 | -0.010\nhair.black  |    28.079 |  1.094 13.167  0.934 |  0.286  5.973  0.064 |  0.046\n               ctr   cos2  \nhair.fair    4.928  0.000 |\nhair.red    86.090  0.197 |\nhair.medium  0.483  0.000 |\nhair.dark    3.075  0.000 |\nhair.black   5.425  0.002 |\n\n\n\n\n\n\n\n\n\nres.ca\n\n**Results of the Correspondence Analysis (CA)**\nThe row variable has  4  categories; the column variable has 5 categories\nThe chi square of independence between the two variables is equal to 1240.039 (p-value =  4.123993e-258 ).\n*The results are available in the following objects:\n\n   name              description                   \n1  \"$eig\"            \"eigenvalues\"                 \n2  \"$col\"            \"results for the columns\"     \n3  \"$col$coord\"      \"coord. for the columns\"      \n4  \"$col$cos2\"       \"cos2 for the columns\"        \n5  \"$col$contrib\"    \"contributions of the columns\"\n6  \"$row\"            \"results for the rows\"        \n7  \"$row$coord\"      \"coord. for the rows\"         \n8  \"$row$cos2\"       \"cos2 for the rows\"           \n9  \"$row$contrib\"    \"contributions of the rows\"   \n10 \"$call\"           \"summary called parameters\"   \n11 \"$call$marge.col\" \"weights of the columns\"      \n12 \"$call$marge.row\" \"weights of the rows\"         \n\n\n\n#查看特征值、维度贡献率、累积贡献率\nres.ca$eig\n\n        eigenvalue percentage of variance cumulative percentage of variance\ndim 1 0.1992447520             86.5562709                          86.55627\ndim 2 0.0300867741             13.0703516                          99.62662\ndim 3 0.0008594814              0.3733775                         100.00000\n\n\n\n#查看过渡矩阵Z的奇异值分解\nres.ca$svd\n\n$vs\n[1] 0.44636840 0.17345540 0.02931691\n\n$U\n            [,1]       [,2]       [,3]\n[1,] -0.89679252  0.9536227 -2.1884132\n[2,] -0.98731818  0.5100045  1.0837859\n[3,]  0.07530627 -1.4124778 -0.1894089\n[4,]  1.57434710  0.7720361  0.1482208\n\n$V\n            [,1]       [,2]       [,3]\n[1,] -1.21871379  1.0022432 -0.4271282\n[2,] -0.52257500  0.2783364  4.0268545\n[3,] -0.09414671 -1.2009094 -0.1103959\n[4,]  1.31888486  0.5992920 -0.3450676\n[5,]  2.45176017  1.6513565  1.5736976\n\n\n\n#查看行变量的坐标、贡献、cos2(the quality of each dimension for each point)\nres.ca$row\n\n$coord\n                 Dim 1       Dim 2        Dim 3\neye.blue   -0.40029985  0.16541100 -0.064157519\neye.light  -0.44070764  0.08846303  0.031773257\neye.medium  0.03361434 -0.24500190 -0.005552885\neye.dark    0.70273880  0.13391383  0.004345377\n\n$contrib\n                Dim 1     Dim 2     Dim 3\neye.blue   10.7191765 12.120781 63.831659\neye.light  28.5906733  7.628833 34.450625\neye.medium  0.1867536 65.700687  1.181429\neye.dark   60.5033967 14.549698  0.536287\n\n$cos2\n                Dim 1      Dim 2        Dim 3\neye.blue   0.83581532 0.14271455 2.147013e-02\neye.light  0.95648915 0.03853918 4.971671e-03\neye.medium 0.01846682 0.98102924 5.039418e-04\neye.dark   0.96492376 0.03503934 3.689437e-05\n\n$inertia\n[1] 0.02555277 0.05955678 0.02014947 0.12493199"
  },
  {
    "objectID": "chap9slide.html",
    "href": "chap9slide.html",
    "title": "Chapter 9 典型相关分析",
    "section": "",
    "text": "注意：本讲义供学习交流使用，请勿用于商业用途"
  },
  {
    "objectID": "ccaR.html",
    "href": "ccaR.html",
    "title": "9 典型相关分析在R中的实现",
    "section": "",
    "text": "本章介绍R中的典型相关分析（Canonical Correlation Analysis）。\n#安装和加载包\n#install.packages(\"CCA\")\n#install.packages(\"yacca\")\n点击下载数据文件: eg9.1.xls"
  },
  {
    "objectID": "ccaR.html#factominerca",
    "href": "ccaR.html#factominerca",
    "title": "8 CA在R中的实现",
    "section": "FactoMineR:CA()",
    "text": "FactoMineR:CA()\n\nlibrary(FactoMineR)\n\nres.ca &lt;- CA(caith, graph = FALSE)\n\nres.ca %&gt;% summary()\n\n\nCall:\nCA(X = caith, graph = FALSE) \n\nThe chi square of independence between the two variables is equal to 1240.039 (p-value =  4.123993e-258 ).\n\nEigenvalues\n                       Dim.1   Dim.2   Dim.3\nVariance               0.199   0.030   0.001\n% of var.             86.556  13.070   0.373\nCumulative % of var.  86.556  99.627 100.000\n\nRows\n              Iner*1000     Dim.1     ctr    cos2     Dim.2     ctr    cos2  \neye.blue    |    25.553 |  -0.400  10.719   0.836 |   0.165  12.121   0.143 |\neye.light   |    59.557 |  -0.441  28.591   0.956 |   0.088   7.629   0.039 |\neye.medium  |    20.149 |   0.034   0.187   0.018 |  -0.245  65.701   0.981 |\neye.dark    |   124.932 |   0.703  60.503   0.965 |   0.134  14.550   0.035 |\n              Dim.3     ctr    cos2  \neye.blue     -0.064  63.832   0.021 |\neye.light     0.032  34.451   0.005 |\neye.medium   -0.006   1.181   0.001 |\neye.dark      0.004   0.536   0.000 |\n\nColumns\n              Iner*1000    Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3\nhair.fair   |    88.134 | -0.544 40.116  0.907 |  0.174 27.131  0.093 | -0.013\nhair.red    |     3.752 | -0.233  1.450  0.770 |  0.048  0.411  0.033 |  0.118\nhair.medium |    17.918 | -0.042  0.352  0.039 | -0.208 57.211  0.961 | -0.003\nhair.dark   |    92.308 |  0.589 44.915  0.969 |  0.104  9.274  0.030 | -0.010\nhair.black  |    28.079 |  1.094 13.167  0.934 |  0.286  5.973  0.064 |  0.046\n               ctr   cos2  \nhair.fair    4.928  0.000 |\nhair.red    86.090  0.197 |\nhair.medium  0.483  0.000 |\nhair.dark    3.075  0.000 |\nhair.black   5.425  0.002 |\n\nres.ca\n\n**Results of the Correspondence Analysis (CA)**\nThe row variable has  4  categories; the column variable has 5 categories\nThe chi square of independence between the two variables is equal to 1240.039 (p-value =  4.123993e-258 ).\n*The results are available in the following objects:\n\n   name              description                   \n1  \"$eig\"            \"eigenvalues\"                 \n2  \"$col\"            \"results for the columns\"     \n3  \"$col$coord\"      \"coord. for the columns\"      \n4  \"$col$cos2\"       \"cos2 for the columns\"        \n5  \"$col$contrib\"    \"contributions of the columns\"\n6  \"$row\"            \"results for the rows\"        \n7  \"$row$coord\"      \"coord. for the rows\"         \n8  \"$row$cos2\"       \"cos2 for the rows\"           \n9  \"$row$contrib\"    \"contributions of the rows\"   \n10 \"$call\"           \"summary called parameters\"   \n11 \"$call$marge.col\" \"weights of the columns\"      \n12 \"$call$marge.row\" \"weights of the rows\"         \n\n\n\n#查看特征值、维度贡献率、累积贡献率\nres.ca$eig\n\n        eigenvalue percentage of variance cumulative percentage of variance\ndim 1 0.1992447520             86.5562709                          86.55627\ndim 2 0.0300867741             13.0703516                          99.62662\ndim 3 0.0008594814              0.3733775                         100.00000\n\n\n\n#查看过渡矩阵Z的奇异值分解\nres.ca$svd\n\n$vs\n[1] 0.44636840 0.17345540 0.02931691\n\n$U\n            [,1]       [,2]       [,3]\n[1,] -0.89679252  0.9536227 -2.1884132\n[2,] -0.98731818  0.5100045  1.0837859\n[3,]  0.07530627 -1.4124778 -0.1894089\n[4,]  1.57434710  0.7720361  0.1482208\n\n$V\n            [,1]       [,2]       [,3]\n[1,] -1.21871379  1.0022432 -0.4271282\n[2,] -0.52257500  0.2783364  4.0268545\n[3,] -0.09414671 -1.2009094 -0.1103959\n[4,]  1.31888486  0.5992920 -0.3450676\n[5,]  2.45176017  1.6513565  1.5736976\n\n\n\n#查看行变量的坐标、贡献、cos2(the quality of each dimension for each point)\nres.ca$row\n\n$coord\n                 Dim 1       Dim 2        Dim 3\neye.blue   -0.40029985  0.16541100 -0.064157519\neye.light  -0.44070764  0.08846303  0.031773257\neye.medium  0.03361434 -0.24500190 -0.005552885\neye.dark    0.70273880  0.13391383  0.004345377\n\n$contrib\n                Dim 1     Dim 2     Dim 3\neye.blue   10.7191765 12.120781 63.831659\neye.light  28.5906733  7.628833 34.450625\neye.medium  0.1867536 65.700687  1.181429\neye.dark   60.5033967 14.549698  0.536287\n\n$cos2\n                Dim 1      Dim 2        Dim 3\neye.blue   0.83581532 0.14271455 2.147013e-02\neye.light  0.95648915 0.03853918 4.971671e-03\neye.medium 0.01846682 0.98102924 5.039418e-04\neye.dark   0.96492376 0.03503934 3.689437e-05\n\n$inertia\n[1] 0.02555277 0.05955678 0.02014947 0.12493199\n\n## calculate 第1个行变量的contribution\n#计算对应矩阵correspondence matrix ——P\nP &lt;- as.matrix(caith/sum(caith))\nP %&gt;% round(3)\n\n           hair.fair hair.red hair.medium hair.dark hair.black\neye.blue       0.061    0.007       0.045     0.020      0.001\neye.light      0.128    0.022       0.108     0.035      0.001\neye.medium     0.064    0.016       0.169     0.076      0.005\neye.dark       0.018    0.009       0.075     0.126      0.016\n\n#计算边缘概率、独立性假定下的期望概率\npi. &lt;- rowSums(P)\npi.\n\n  eye.blue  eye.light eye.medium   eye.dark \n 0.1332838  0.2932987  0.3293113  0.2441062 \n\npj. &lt;- colSums(P)\npj.\n\n  hair.fair    hair.red hair.medium   hair.dark  hair.black \n 0.27009467  0.05309077  0.39669575  0.25821422  0.02190459 \n\n(res.ca$row$coord[,1]^2 * pi.)/sum(res.ca$row$coord[,1]^2 * pi.)\n\n   eye.blue   eye.light  eye.medium    eye.dark \n0.107191765 0.285906733 0.001867536 0.605033967 \n\n## calculate 第1个行变量的cos2\n(res.ca$row$coord[1,]^2 )/sum(res.ca$row$coord[1,]^2)\n\n     Dim 1      Dim 2      Dim 3 \n0.83581532 0.14271455 0.02147013 \n\n\n\n#查看列变量的坐标、贡献、cos2(the quality of each dimension for each point)\nres.ca$col\n\n$coord\n                  Dim 1       Dim 2        Dim 3\nhair.fair   -0.54399533  0.17384449 -0.012522082\nhair.red    -0.23326097  0.04827895  0.118054940\nhair.medium -0.04202412 -0.20830421 -0.003236468\nhair.dark    0.58870853  0.10395044 -0.010116315\nhair.black   1.09438828  0.28643670  0.046135954\n\n$contrib\n                 Dim 1      Dim 2      Dim 3\nhair.fair   40.1161707 27.1307783  4.9275678\nhair.red     1.4498275  0.4113003 86.0896470\nhair.medium  0.3516154 57.2108003  0.4834635\nhair.dark   44.9152601  9.2737881  3.0745985\nhair.black  13.1671264  5.9733330  5.4247232\n\n$cos2\n                Dim 1      Dim 2        Dim 3\nhair.fair   0.9069022 0.09261727 0.0004805329\nhair.red    0.7698335 0.03297830 0.1971882209\nhair.medium 0.0390998 0.96066829 0.0002319103\nhair.dark   0.9694868 0.03022692 0.0002862767\nhair.black  0.9343341 0.06400541 0.0016604979\n\n$inertia\n[1] 0.088134492 0.003752377 0.017917615 0.092307908 0.028078616\n\n## calculate 第1个列变量的cos2\nres.ca$col$coord[1,]^2/sum(res.ca$col$coord[1,]^2)\n\n       Dim 1        Dim 2        Dim 3 \n0.9069021982 0.0926172689 0.0004805329"
  },
  {
    "objectID": "ccaR.html#碎石图scree-plot",
    "href": "ccaR.html#碎石图scree-plot",
    "title": "8 CA在R中的实现",
    "section": "碎石图scree plot",
    "text": "碎石图scree plot\n\n#绘制scree plot\nlibrary(factoextra)\nfviz_screeplot(res.ca, addlabels = TRUE, ylim = c(0, 100))\n\nWarning in geom_bar(stat = \"identity\", fill = barfill, color = barcolor, :\nIgnoring empty aesthetic: `width`.\n\n\n\n\n\n\n\n\n\n\n# symmetric plot\nlibrary(factoextra)\nfviz_ca_biplot(res.ca, repel = TRUE)\n\n\n\n\n\n\n\ndimdesc(res.ca)\n\n$`Dim 1`\n$`Dim 1`$row\n                 coord\neye.light  -0.44070764\neye.blue   -0.40029985\neye.medium  0.03361434\neye.dark    0.70273880\n\n$`Dim 1`$col\n                  coord\nhair.fair   -0.54399533\nhair.red    -0.23326097\nhair.medium -0.04202412\nhair.dark    0.58870853\nhair.black   1.09438828\n\n\n$`Dim 2`\n$`Dim 2`$row\n                 coord\neye.medium -0.24500190\neye.light   0.08846303\neye.dark    0.13391383\neye.blue    0.16541100\n\n$`Dim 2`$col\n                  coord\nhair.medium -0.20830421\nhair.red     0.04827895\nhair.dark    0.10395044\nhair.fair    0.17384449\nhair.black   0.28643670\n\n#Rows are represented by blue points and columns by red triangles."
  },
  {
    "objectID": "ccaR.html#行变量绘图-graph-of-row-variables",
    "href": "ccaR.html#行变量绘图-graph-of-row-variables",
    "title": "8 CA在R中的实现",
    "section": "行变量绘图 Graph of row variables",
    "text": "行变量绘图 Graph of row variables\n\nrow &lt;- get_ca_row(res.ca)\nrow\n\nCorrespondence Analysis - Results for rows\n ===================================================\n  Name       Description                \n1 \"$coord\"   \"Coordinates for the rows\" \n2 \"$cos2\"    \"Cos2 for the rows\"        \n3 \"$contrib\" \"contributions of the rows\"\n4 \"$inertia\" \"Inertia of the rows\"      \n\n\nrow$coord: coordinates of each row point in each dimension (1, 2 and 3). Used to create the scatter plot.\nrow$cos2: quality of representation of rows.\nvar$contrib: contribution of rows (in %) to the definition of the dimensions.\n\n#Coordinates of row points\n\nrow$coord[,1:2]\n\n                 Dim 1       Dim 2\neye.blue   -0.40029985  0.16541100\neye.light  -0.44070764  0.08846303\neye.medium  0.03361434 -0.24500190\neye.dark    0.70273880  0.13391383\n\nfviz_ca_row(res.ca, repel = TRUE)\n\n\n\n\n\n\n\nfviz_ca_row(res.ca, col.row=\"steelblue\", shape.row = 15, repel = TRUE)\n\n\n\n\n\n\n\n\n\n#Quality of representation of rows\n\n#The quality of representation of the rows on the factor map is called the squared cosine (cos2) or the squared correlations.\n\nrow$cos2\n\n                Dim 1      Dim 2        Dim 3\neye.blue   0.83581532 0.14271455 2.147013e-02\neye.light  0.95648915 0.03853918 4.971671e-03\neye.medium 0.01846682 0.98102924 5.039418e-04\neye.dark   0.96492376 0.03503934 3.689437e-05\n\n# Color by cos2 values: quality on the factor map\nfviz_ca_row(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)\n\n\n\n\n\n\n\n# Change the transparency by cos2 values\nfviz_ca_row(res.ca, alpha.row=\"cos2\")\n\n\n\n\n\n\n\n\n\n#visualize the cos2 of row points on all the dimensions\nlibrary(corrplot)\ncorrplot(row$cos2, is.corr=FALSE)\n\n\n\n\n\n\n\n\n\n# Cos2 of rows on Dim.1\nfviz_cos2(res.ca, choice = \"row\", axes = 1)\n\n\n\n\n\n\n\n# Cos2 of rows on Dim.2\nfviz_cos2(res.ca, choice = \"row\", axes = 2)\n\n\n\n\n\n\n\n# Cos2 of rows on Dim.1 and Dim.2\nfviz_cos2(res.ca, choice = \"row\", axes = 1:2)\n\n\n\n\n\n\n\n\n\n#Coordinates of row points\nrow$contrib\n\n                Dim 1     Dim 2     Dim 3\neye.blue   10.7191765 12.120781 63.831659\neye.light  28.5906733  7.628833 34.450625\neye.medium  0.1867536 65.700687  1.181429\neye.dark   60.5033967 14.549698  0.536287\n\n# Contributions of rows to dimension 1\nfviz_contrib(res.ca, choice = \"row\", axes = 1)\n\n\n\n\n\n\n\n# Contributions of rows to dimension 2\nfviz_contrib(res.ca, choice = \"row\", axes = 2, top = 2)\n\n\n\n\n\n\n\n\n\n#The most important (or, contributing) row points can be highlighted on the scatter plot as follow:\n\nfviz_ca_row(res.ca, col.row = \"contrib\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)"
  },
  {
    "objectID": "ccaR.html#列变量绘图-graph-of-column-variables",
    "href": "ccaR.html#列变量绘图-graph-of-column-variables",
    "title": "8 CA在R中的实现",
    "section": "列变量绘图 Graph of column variables",
    "text": "列变量绘图 Graph of column variables\n\nfviz_ca_col(res.ca, col.col = \"cos2\", \n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE)"
  },
  {
    "objectID": "ccaR.html#筛选画图变量filter-results",
    "href": "ccaR.html#筛选画图变量filter-results",
    "title": "8 CA在R中的实现",
    "section": "筛选画图变量Filter Results",
    "text": "筛选画图变量Filter Results\n\n# Visualize rows with cos2 &gt;= 0.9\nfviz_ca_row(res.ca, select.row = list(cos2 = 0.9), repel  = T)\n\n\n\n\n\n\n\n# Top 3 active rows  with the highest cos2\nfviz_ca_row(res.ca, select.row = list(cos2 = 3), repel  = T)\n\n\n\n\n\n\n\n# Select by names\nname &lt;- list(name = c(\"eye.dark\", \"eye.medium\"))\nfviz_ca_row(res.ca, select.row = name, repel  = T)\n\n\n\n\n\n\n\n# Top 3 contributing rows and columns\nfviz_ca_biplot(res.ca, select.row = list(contrib = 3), \n               select.col = list(contrib = 3), repel  = T) +\n  theme_minimal()"
  },
  {
    "objectID": "ccaR.html#习题1-发色和眼球颜色-教材p165例题8.1",
    "href": "ccaR.html#习题1-发色和眼球颜色-教材p165例题8.1",
    "title": "8 CA在R中的实现",
    "section": "习题1: 发色和眼球颜色 教材P165,例题8.1",
    "text": "习题1: 发色和眼球颜色 教材P165,例题8.1\n要求：\n1.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n1.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n1.3 绘制对应分析图。\n1.4 绘制行变量的contribution、cos2的图像。\n1.5 绘制列变量的contribution、cos2的图像。列变量的哪几个组别是相对重要的组别？\n1.6 从图中可以发现哪些组别关系紧密？"
  },
  {
    "objectID": "ccaR.html#习题2-收入满意度",
    "href": "ccaR.html#习题2-收入满意度",
    "title": "8 CA在R中的实现",
    "section": "习题2: 收入&满意度",
    "text": "习题2: 收入&满意度\n\n提示：数据请自行录入，可在EXCEL录入好后，再导入R。\n要求： 2.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n2.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n2.3 绘制对应分析图。\n2.4 绘制行变量的contribution、cos2的图像。\n2.5 绘制列变量的contribution、cos2的图像。\n2.6 从图中可以发现哪些组别关系紧密？"
  },
  {
    "objectID": "ccaR.html#习题3-婚姻状况汽车偏好",
    "href": "ccaR.html#习题3-婚姻状况汽车偏好",
    "title": "8 CA在R中的实现",
    "section": "习题3: 婚姻状况&汽车偏好",
    "text": "习题3: 婚姻状况&汽车偏好\n\n提示：数据请自行录入，可在EXCEL录入好后，再导入R。\n要求： 3.1 对行变量和列变量进行独立性检验，独立性检验的卡方检验统计量是多少？P值是什么，你的检验结论是什么？\n3.2 绘制碎石图。你提取几个维度？每个维度的贡献分别是多少？\n3.3 绘制对应分析图。\n3.4 绘制行变量的contribution、cos2的图像。\n3.5 绘制列变量的contribution、cos2的图像。\n3.6 从图中可以发现哪些组别关系紧密？"
  },
  {
    "objectID": "chap8.html#第3-4-7章讨论课-第10-11周",
    "href": "chap8.html#第3-4-7章讨论课-第10-11周",
    "title": "第8章",
    "section": "第3, 4, 7章讨论课 (第10-11周)",
    "text": "第3, 4, 7章讨论课 (第10-11周)\n\n在Excel中整理好收集的数据。\n运用第3, 4, 7章方法分析数据\n\n图表工具\n选取一个定量变量绘制频数分布表\n选取一个定量变量绘制直方图\n选取一个定量变量绘制累积百分比折线图\n选取一个定量变量绘制箱线图\n选取一个定性变量绘制频数分布表\n选取一个定性变量绘制帕累托图\n选取一个定性变量绘制饼图\n选取一个定性变量绘制瀑布图\n选取两个定性变量绘制树状图\n描述性统计量的报告\n报告均值、标准差、中位数、最小值、最大值、偏度、峰度等描述性统计量\n参数估计方法的运用\n选取一个定量变量对其总体均值进行区间估计\n选取一个定量变量对其总体方差进行区间估计\n\n准备的文件\nExcel数据文件,将上述分析存放在不同的表单中\nPPT文件(15-20页)\n\n数据来源\n变量含义\nExcel的输出结果\n主要结论"
  },
  {
    "objectID": "ccaR.html#方法一ccacc",
    "href": "ccaR.html#方法一ccacc",
    "title": "9 典型相关分析在R中的实现",
    "section": "方法一：CCA::cc",
    "text": "方法一：CCA::cc\n\nlibrary(CCA)\nres.cc &lt;- cc(physical, train)\n\n#查看典型相关系数\nres.cc$cor\n\n[1] 0.79560815 0.20055604 0.07257029\n\n#查看典型变量与原始变量的关系\nres.cc$xcoef\n\n               [,1]        [,2]         [,3]\nweight  0.031404688  0.07631951 -0.007735047\nwaist  -0.493241676 -0.36872299  0.158033647\npulse   0.008199315  0.03205199  0.145732242\n\nres.cc$ycoef\n\n              [,1]         [,2]         [,3]\nchinup  0.06611399  0.071041211 -0.245275347\nsitup   0.01684623 -0.001973745  0.019767637\njump   -0.01397157 -0.020714106 -0.008167472"
  },
  {
    "objectID": "ccaR.html#方法二yaccacca",
    "href": "ccaR.html#方法二yaccacca",
    "title": "9 典型相关分析在R中的实现",
    "section": "方法二：yacca::cca",
    "text": "方法二：yacca::cca\n\nlibrary(yacca)\nres.cca &lt;- cca(physical, train)\n\n#查看结果\nres.cca\n\n\nCanonical Correlation Analysis\n\nCanonical Correlations:\n      CV 1       CV 2       CV 3 \n0.79560815 0.20055604 0.07257029 \n\nX Coefficients:\n               CV 1        CV 2         CV 3\nweight -0.031404688 -0.07631951 -0.007735047\nwaist   0.493241676  0.36872299  0.158033647\npulse  -0.008199315 -0.03205199  0.145732242\n\nY Coefficients:\n              CV 1         CV 2         CV 3\nchinup -0.06611399 -0.071041211 -0.245275347\nsitup  -0.01684623  0.001973745  0.019767637\njump    0.01397157  0.020714106 -0.008167472\n\nStructural Correlations (Loadings) - X Vars:\n             CV 1       CV 2        CV 3\nweight  0.6206424 -0.7723919 -0.13495886\nwaist   0.9254249 -0.3776614 -0.03099486\npulse  -0.3328481  0.0414842  0.94206752\n\nStructural Correlations (Loadings) - Y Vars:\n             CV 1      CV 2        CV 3\nchinup -0.7276254 0.2369522 -0.64375064\nsitup  -0.8177285 0.5730231  0.05444915\njump   -0.1621905 0.9586280 -0.23393722\n\nAggregate Redundancy Coefficients (Total Variance Explained):\n    X | Y: 0.2968779 \n    Y | X: 0.2766555"
  },
  {
    "objectID": "ccaR.html#典型变量u1和典型变量v1的散点图",
    "href": "ccaR.html#典型变量u1和典型变量v1的散点图",
    "title": "9 典型相关分析在R中的实现",
    "section": "典型变量u1和典型变量v1的散点图",
    "text": "典型变量u1和典型变量v1的散点图\n\nlibrary(CCA)\nres.cc &lt;- cc(physical, train)\n\nres.cc.score &lt;- data.frame(\n  physical_u1 = res.cc$scores$xscores[,1], \n  train_v1 = res.cc$scores$yscores[,1])\n\nres.cc.score %&gt;% \n  ggplot(aes(physical_u1,train_v1)) +\n  geom_point()"
  },
  {
    "objectID": "ccaR.html#helio-plot",
    "href": "ccaR.html#helio-plot",
    "title": "9 典型相关分析在R中的实现",
    "section": "helio plot",
    "text": "helio plot\n\n#典型变量与原始变量的相关系数\nlibrary(yacca)\nres.cca &lt;- cca(physical, train)\n\nhelio.plot(res.cca, x.name=\"Physical Variables\",\n           y.name=\"Train Variables\")\n\n\n\n\n\n\n\n\n\n#Show variances on first canonical variate\nhelio.plot(res.cca, x.name=\"Physical Variables\",\n           y.name=\"Train Variables\", \n           type = \"variance\")"
  },
  {
    "objectID": "caR.html#计算行变量的contribution和cos2",
    "href": "caR.html#计算行变量的contribution和cos2",
    "title": "8 CA在R中的实现",
    "section": "计算行变量的contribution和cos2",
    "text": "计算行变量的contribution和cos2\n\n# 计算第1个行变量的contribution\n\n#计算对应矩阵correspondence matrix ——P\nP &lt;- as.matrix(caith/sum(caith))\nP %&gt;% round(3)\n\n           hair.fair hair.red hair.medium hair.dark hair.black\neye.blue       0.061    0.007       0.045     0.020      0.001\neye.light      0.128    0.022       0.108     0.035      0.001\neye.medium     0.064    0.016       0.169     0.076      0.005\neye.dark       0.018    0.009       0.075     0.126      0.016\n\n#计算边缘概率、独立性假定下的期望概率\npi. &lt;- rowSums(P)\npi.\n\n  eye.blue  eye.light eye.medium   eye.dark \n 0.1332838  0.2932987  0.3293113  0.2441062 \n\npj. &lt;- colSums(P)\npj.\n\n  hair.fair    hair.red hair.medium   hair.dark  hair.black \n 0.27009467  0.05309077  0.39669575  0.25821422  0.02190459 \n\n# 第1个行变量的contribution\n(res.ca$row$coord[,1]^2 * pi.)/sum(res.ca$row$coord[,1]^2 * pi.)\n\n   eye.blue   eye.light  eye.medium    eye.dark \n0.107191765 0.285906733 0.001867536 0.605033967 \n\n# 第1个行变量的cos2(quality of representation)\n(res.ca$row$coord[1,]^2 )/sum(res.ca$row$coord[1,]^2)\n\n     Dim 1      Dim 2      Dim 3 \n0.83581532 0.14271455 0.02147013 \n\n\n\n#查看列变量的坐标、贡献、cos2(the quality of each dimension for each point)\nres.ca$col\n\n$coord\n                  Dim 1       Dim 2        Dim 3\nhair.fair   -0.54399533  0.17384449 -0.012522082\nhair.red    -0.23326097  0.04827895  0.118054940\nhair.medium -0.04202412 -0.20830421 -0.003236468\nhair.dark    0.58870853  0.10395044 -0.010116315\nhair.black   1.09438828  0.28643670  0.046135954\n\n$contrib\n                 Dim 1      Dim 2      Dim 3\nhair.fair   40.1161707 27.1307783  4.9275678\nhair.red     1.4498275  0.4113003 86.0896470\nhair.medium  0.3516154 57.2108003  0.4834635\nhair.dark   44.9152601  9.2737881  3.0745985\nhair.black  13.1671264  5.9733330  5.4247232\n\n$cos2\n                Dim 1      Dim 2        Dim 3\nhair.fair   0.9069022 0.09261727 0.0004805329\nhair.red    0.7698335 0.03297830 0.1971882209\nhair.medium 0.0390998 0.96066829 0.0002319103\nhair.dark   0.9694868 0.03022692 0.0002862767\nhair.black  0.9343341 0.06400541 0.0016604979\n\n$inertia\n[1] 0.088134492 0.003752377 0.017917615 0.092307908 0.028078616\n\n## calculate 第1个列变量的cos2\nres.ca$col$coord[1,]^2/sum(res.ca$col$coord[1,]^2)\n\n       Dim 1        Dim 2        Dim 3 \n0.9069021982 0.0926172689 0.0004805329"
  },
  {
    "objectID": "ch8MCA.html",
    "href": "ch8MCA.html",
    "title": "多重对应分析",
    "section": "",
    "text": "MCA 是对应分析（Correspondence Analysis, CA）在“多变量分类数据”上的推广，主要用于对多项（名义）分类变量集合进行降维和可视化。\n目标：把高维的分类变量（每个变量有若干类别）映射到低维空间（通常 2 或 3 维），便于发现变量类别之间、样本（个体）之间以及变量与个体间的关联结构。\n\nMCA 示例：UCBAdmissions 数据集\n\n# UCBAdmissions 示例 —— 表示院系、性别与是否录取（含频数）\nlibrary(FactoMineR)\nlibrary(factoextra)\n\ndata(UCBAdmissions)\nhead(as.data.frame(UCBAdmissions))\n\n     Admit Gender Dept Freq\n1 Admitted   Male    A  512\n2 Rejected   Male    A  313\n3 Admitted Female    A   89\n4 Rejected Female    A   19\n5 Admitted   Male    B  353\n6 Rejected   Male    B  207\n\n# 展开频数表\ndf_tab2 &lt;- as.data.frame(UCBAdmissions)    # Admit, Gender, Dept, Freq\ndf2 &lt;- df_tab2[rep(1:nrow(df_tab2), df_tab2$Freq), 1:3]\n\n\n# MCA 需要输入每一行为一个观测（个体），每列为一个分类变量（factor 或 character）\n# 运行 MCA\nres.mca &lt;- MCA(df2, graph = FALSE)\n\n# 特征值 / 惯性\nprint(res.mca$eig)\n\n      eigenvalue percentage of variance cumulative percentage of variance\ndim 1  0.5593567              23.972432                          23.97243\ndim 2  0.3836385              16.441651                          40.41408\ndim 3  0.3333333              14.285714                          54.69980\ndim 4  0.3333333              14.285714                          68.98551\ndim 5  0.3333333              14.285714                          83.27123\ndim 6  0.2365865              10.139423                          93.41065\ndim 7  0.1537515               6.589351                         100.00000\n\n# 类别坐标与贡献\nres.mca$var$coord\n\n              Dim 1       Dim 2         Dim 3         Dim 4         Dim 5\nAdmitted -0.8044382  0.60388898  1.893874e-14 -2.715055e-14  1.595259e-14\nRejected  0.5094872 -0.38247028 -1.310537e-14  1.678796e-14 -9.647836e-15\nMale     -0.5994764 -0.33206778 -9.675829e-15  7.223627e-15 -3.701573e-14\nFemale    0.8791232  0.48697242  1.504986e-14 -9.906237e-15  5.399450e-14\nA        -1.1285105  0.10364920 -1.303601e+00 -4.705919e-01  4.364633e-01\nB        -1.2651063 -0.36898236  2.019112e+00  5.820911e-01  8.587992e-02\nC         0.5961997  1.06360652  6.139759e-01 -1.263117e+00 -1.449487e-01\nD         0.2416198  0.05485516 -4.830139e-01  9.782696e-01 -1.855346e+00\nE         0.8469566  0.56263177 -2.008690e-01  1.644655e+00  1.626523e+00\nF         0.7838806 -1.72165693 -4.019014e-02 -6.683306e-01  2.733150e-01\n\nres.mca$var$contrib\n\n              Dim 1       Dim 2        Dim 3        Dim 4        Dim 5\nAdmitted 14.9533277 12.28664503 1.390800e-26 2.858380e-26 9.867907e-27\nRejected  9.4706208  7.78168965 1.051527e-26 1.725512e-26 5.698779e-27\nMale     12.7330727  5.69651377 5.566414e-27 3.102486e-27 8.146514e-26\nFemale   18.6728603  8.35385207 9.183033e-27 3.978679e-27 1.182009e-25\nA        15.6447341  0.19242238 3.503133e+01 4.565160e+00 3.927014e+00\nB        12.3277907  1.52900553 5.269410e+01 4.379487e+00 9.532889e-02\nC         4.2963676 19.93639553 7.645938e+00 3.236050e+01 4.261443e-01\nD         0.6087871  0.04575116 4.082535e+00 1.674664e+01 6.023657e+01\nE         5.5158255  3.54897822 5.206239e-01 3.490183e+01 3.413650e+01\nF         5.7766134 40.62874664 2.548137e-02 7.046385e+00 1.178448e+00\n\n\n\n\n\n对应分析/通过多个维度捕捉数据中分类变量之间的结构。\n特征值表示信息量，坐标表示类别在维度上的位置，贡献度表示哪些类别主导了维度的解释。\n\n\n多重对应分析（MCA, Multiple Correspondence Analysis） 的类别散点图\n\n# 绘制各类别在第1维度和第2维度的位置\n# 颜色代表类别的贡献\nfviz_mca_var(res.mca, \n             repel = TRUE, \n             col.var = \"contrib\")\n\n\n\n\n\n\n\n\n\n\n# 绘制各类别在第3维度和第4维度的位置\nfviz_mca_var(res.mca, \n             axes = c(3, 4),\n             repel = TRUE, col.var = \"contrib\")\n\n\n\n\n\n\n\n\n\n\n多重对应分析（MCA, Multiple Correspondence Analysis） 的个体散点图\n\nfviz_mca_ind(res.mca, \n             geom = \"point\", \n             habillage = interaction(df2$Gender, df2$Admit),  \n             palette = RColorBrewer::brewer.pal(4, \"Set3\"),\n             repel = TRUE)\n\n\n\n\n\n\n\n\nDim1 方向：\n大体上，未录取个体（紫色、橙色）分布在右侧（Dim1 &gt; 0），而录取个体（绿色、黄色）多在左侧（Dim1 &lt; 0）。\n说明 Dim1 可能与“录取结果”相关，是区分录取与未录取的主要维度。\nDim2 方向：\n男性和女性在 Dim2 上有轻微分离：男性（绿色/紫色）偏下，女性（黄色/橙色）偏上。\n说明 Dim2 可能与“性别”相关，但区分度没有 Dim1 明显。\n\nfviz_mca_ind(res.mca, \n             geom = \"point\", \n             habillage = interaction(df2$Gender, df2$Admit,\n                                     df2$Dept),     \n             palette = colorRampPalette(RColorBrewer::brewer.pal(9, \"Blues\"))(24), \n             repel = TRUE)\n\n\n\n\n\n\n\n\n右上象限主要由 C、D、E 等系的组合组成，且以女性组居多，这些组沿第一维度倾向于和“被拒/系 C–E” 相关（图中在 Dim1 的正侧），在第二维度上也表现为正向（与 C 类系的特征一致）。\n左上象限以“被录取（Admitted）”的组为主，尤其集中在系 A、B（以及部分在其他系的 admitted 男性），表明第一维度的负侧与“录取 / A、B 系”相关联。\n左下象限主要包含男性组（集中在 A、B，以及一些 F 的 admitted），这些组在第二维度为负（受 Dept F 或男性模式影响），在第一维度又在负侧或接近负侧，呈现与 II 象限不同的男性/系别混合模式。\n右下象限由系 F（以及部分 B/D/E）的组主导，Dim1 为正（接近“Rejected”侧），Dim2 为负（强烈受 Dept F 的负向特征影响），因此这一象限总体上表现出强烈的 F 系特征并包含较多被拒的组合。"
  },
  {
    "objectID": "ccaR.html#helio-plot-放射状图",
    "href": "ccaR.html#helio-plot-放射状图",
    "title": "9 典型相关分析在R中的实现",
    "section": "helio plot 放射状图",
    "text": "helio plot 放射状图\n\n#典型变量与原始变量的相关系数\nlibrary(yacca)\nres.cca &lt;- cca(physical, train)\n\nhelio.plot(res.cca, x.name=\"Physical Variables\",\n           y.name=\"Train Variables\")\n\n\n\n\n\n\n\n\n\n#Show variances on first canonical variate\nhelio.plot(res.cca, x.name=\"Physical Variables\",\n           y.name=\"Train Variables\", \n           type = \"variance\")"
  },
  {
    "objectID": "deepseek.html",
    "href": "deepseek.html",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "",
    "text": "🏠 Home"
  },
  {
    "objectID": "deepseek.html#大纲",
    "href": "deepseek.html#大纲",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "大纲",
    "text": "大纲\n\n1 DeepSeek助力：重塑统计学习方式\n2 DeepSeek辅助统计方法学习和运用\n3 DeepSeek辅助论文统计分析写作\n4 DeepSeek辅助统计分析和R运用"
  },
  {
    "objectID": "deepseek.html#与deepseek协作重塑统计学习方式",
    "href": "deepseek.html#与deepseek协作重塑统计学习方式",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "1.1 与DeepSeek协作：重塑统计学习方式",
    "text": "1.1 与DeepSeek协作：重塑统计学习方式\n\n不知道该用什么统计方法？\n看不懂输出结果\n为写论文而发愁\n\n💡 理念重塑: 从“工具”到“伙伴”:\n\n“我不会统计方法” ➡️ “我会提问”\n“我不会用R/STATA/Python” ➡ “在AI辅助下我能”\n“我写不好论文中的统计部分” ➡ “我能借助 AI表达、优化”"
  },
  {
    "objectID": "deepseek.html#deepseek辅助统计方法学习和运用",
    "href": "deepseek.html#deepseek辅助统计方法学习和运用",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "2 DeepSeek辅助统计方法学习和运用",
    "text": "2 DeepSeek辅助统计方法学习和运用\n\n重构统计学习方式\n\n互动式\n针对性\n不要撒网式学习"
  },
  {
    "objectID": "deepseek.html#deepseek如何助力统计学习",
    "href": "deepseek.html#deepseek如何助力统计学习",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "2.1 DeepSeek如何助力统计学习？",
    "text": "2.1 DeepSeek如何助力统计学习？\n\n统计学习的重心\n\n基础知识(本科课程已涵盖)\n\n变量类型: 定性(无序/有序), 定量(离散/连续)\n参数估计: 置信水平，置信区间\n假设检验: 双/单侧检验，显著性水平, p值, 临界值, 检验统计量\n\n方法选择\n结果解读"
  },
  {
    "objectID": "deepseek.html#统计基础知识补遗",
    "href": "deepseek.html#统计基础知识补遗",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "2.2 统计基础知识补遗",
    "text": "2.2 统计基础知识补遗\n🎯 提问句式\n\n🧭 提示语: 请用最通俗的方式解释“统计术语”\n\n\n🧭 提示语: 请用数值模拟解释“统计术语”，并提供 R 代码与详细解释，以便更直观地理解。"
  },
  {
    "objectID": "deepseek.html#重构统计学习方式从被动学习到主动建构",
    "href": "deepseek.html#重构统计学习方式从被动学习到主动建构",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "2.3 重构统计学习方式：从被动学习到主动建构",
    "text": "2.3 重构统计学习方式：从被动学习到主动建构\n💡 不再是“学完了才能用”，而是“在用中学习，在问中学”\n📕️ 传统模式：教科书主导，学生被动接受\n\n教材编什么，读者学什么\n\n顺着教材目录走，忽视了统计思维的培养、“统计写作”能力的训练\n\n🚀 DeepSeek模式：需求驱动，Prompt引导学习\n\n先有问题，后找方法\n不再强调公式/计算/软件操作，而是围绕科研任务主动构建统计能力\n\n\n📌 统计学习的未来，不是依靠更全面系统的教材，而是善于利用AI工具的引导。"
  },
  {
    "objectID": "deepseek.html#从统计学习者到提问专家如何与-deepseek-高效对话",
    "href": "deepseek.html#从统计学习者到提问专家如何与-deepseek-高效对话",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "2.4 从统计学习者到提问专家：如何与 DeepSeek 高效对话？",
    "text": "2.4 从统计学习者到提问专家：如何与 DeepSeek 高效对话？\n\nDeepSeek可以回答”如何做”\n选择方法, 解释结果, 润色语言\nDeepSeek无法判断统计分析结论的“现实意义”\n① 它不了解社会经济语境\n\n无法判断1.2%的收入增长是否有社会学意义\n无法判断失业率降低3%是否足以推动政策调整\n无法判断某项干预措施对社会群体是否“可感知”\n\n② 它无法识别研究的局限\n\n样本的代表性\n数据质量\n研究全貌"
  },
  {
    "objectID": "deepseek.html#从工具到能力构建ai辅助统计思维",
    "href": "deepseek.html#从工具到能力构建ai辅助统计思维",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "从工具到能力，构建AI辅助统计思维",
    "text": "从工具到能力，构建AI辅助统计思维\n\n统计学习不只是掌握方法，更是形成解决问题的思维方式。\nDeepSeek不只是工具，更可以成为统计学习与科研写作的智能伙伴。\n借助 AI，可以加速理解、提升效率，但不能替代判断与思考。\n真正有效的统计学习，应注重：\n\n明确目标（用AI解决具体问题）；\n精准提问（提升与AI对话质量）；\n灵活应用（将建议转化为科研能力）。\n\n\n\n📌 从“学习统计”到“用统计解决问题”"
  },
  {
    "objectID": "deepseek.html#deepseek辅助统计方法的学习和运用",
    "href": "deepseek.html#deepseek辅助统计方法的学习和运用",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "2.5 DeepSeek辅助统计方法的学习和运用",
    "text": "2.5 DeepSeek辅助统计方法的学习和运用\n\n统计方法全景图\nDeepSeek如何辅助统计方法选择？\nDeepSeek如何辅助结果解读？"
  },
  {
    "objectID": "deepseek.html#统计方法全景图",
    "href": "deepseek.html#统计方法全景图",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "统计方法全景图",
    "text": "统计方法全景图"
  },
  {
    "objectID": "deepseek.html#deepseek如何辅助选择统计方法",
    "href": "deepseek.html#deepseek如何辅助选择统计方法",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "DeepSeek如何辅助选择统计方法？",
    "text": "DeepSeek如何辅助选择统计方法？\n✅ 研究目的: 描述/推断/比较/预测/因果推断\n✅ 数据结构: 横截面/纵向/分层/RCT/生存数据等\n✅ 变量类型: 定性变量(无序/有序), 定量变量(离散/连续)\n✅ 变量地位：结局变量/自变量/协变量\n✅ 变量分布：正态/非正态/泊松分布等\n✅ 样本容量"
  },
  {
    "objectID": "deepseek.html#deepseek辅助深入学习统计方法",
    "href": "deepseek.html#deepseek辅助深入学习统计方法",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "deepseek辅助深入学习统计方法",
    "text": "deepseek辅助深入学习统计方法\n\n追问统计分析过程细节\n追问检验方法的细节\n追问图形工具的细节\n追问如何评估模型拟合效果"
  },
  {
    "objectID": "deepseek.html#deepseek辅助统计方法的学习和运用-1",
    "href": "deepseek.html#deepseek辅助统计方法的学习和运用-1",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "DeepSeek辅助统计方法的学习和运用",
    "text": "DeepSeek辅助统计方法的学习和运用\n\n将“现实问题”转换为“统计问题”\n\n提问句式：研究目的 + 研究对象 + 自变量 + 因变量 + 特殊说明\n\n追问统计分析过程的细节\n\n方法/模型，还可以做哪些检验或者绘制可视化图形？请参考学术文献的主流做法，回答上述问题。\n\n追问检验方法的细节\n追问图形工具的细节\n追问如何评估模型拟合效果\n关于输出结果的解读\n\n统计学意义：P值、效应量、置信区间\n临床学意义：临床相关性、实际应用价值\n\n优化统计分析的建议\n\n样本数据、选用的变量、估计方法是否存在局限性？请提出改进建议"
  },
  {
    "objectID": "deepseek.html#deepseek辅助统计写作",
    "href": "deepseek.html#deepseek辅助统计写作",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "3 DeepSeek辅助统计写作",
    "text": "3 DeepSeek辅助统计写作\n\n建立自己的提示词库\n建立自己的范文库\n不要忙于统计分析，而疏于写作\n\n💡 统计写作不是“最后一步”，而是每一步统计分析的记录、反馈与构建。"
  },
  {
    "objectID": "deepseek.html#deepseek辅助r运用",
    "href": "deepseek.html#deepseek辅助r运用",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4 DeepSeek辅助R运用",
    "text": "4 DeepSeek辅助R运用"
  },
  {
    "objectID": "deepseek.html#deepseek辅助r语言快速入门",
    "href": "deepseek.html#deepseek辅助r语言快速入门",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.1 DeepSeek辅助R语言快速入门",
    "text": "4.1 DeepSeek辅助R语言快速入门\n\n4.1.1 为什么用DeepSeek学R？\n4.1.2 人人都能用R了！一个简单的示例\n4.1.3 DeepSeek教不会什么？这几点你得自己掌握"
  },
  {
    "objectID": "deepseek.html#为什么用deepseek学r",
    "href": "deepseek.html#为什么用deepseek学r",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.1.1 为什么用DeepSeek学R",
    "text": "4.1.1 为什么用DeepSeek学R\n\nR语言是一门强大但语法灵活的编程语言，对初学者有一定门槛。\nDeepSeek具备自然语言理解与代码生成能力：\n\n快速生成代码\n解释代码, 报错寻因, 解读结果\n扩展功能包、实现复杂流程\n\n进入“AI辅助编程”时代，将改变R语言的学习方式，从”查命令”转为”提问题”。"
  },
  {
    "objectID": "deepseek.html#人人都能用r了一个简单的示例",
    "href": "deepseek.html#人人都能用r了一个简单的示例",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.1.2 人人都能用R了！一个简单的示例",
    "text": "4.1.2 人人都能用R了！一个简单的示例\n\n🧭 提示语: 用iris数据，进行方差分析，给出R代码。"
  },
  {
    "objectID": "deepseek.html#deepseek教不会什么这几点你得自己掌握",
    "href": "deepseek.html#deepseek教不会什么这几点你得自己掌握",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.1.3 DeepSeek教不会什么？这几点你得自己掌握",
    "text": "4.1.3 DeepSeek教不会什么？这几点你得自己掌握\n\nRStudio主界面\n如何高效管理文件？\n\n项目project\n\n在写R代码的实践中积累的“经验”\n\n📚 如何读懂 R 的帮助文档\n📚 如何写一段”漂亮聪明”的代码\n\n简洁/可复制性\n美观/易读(代码注释、分节)\n\n📚 如何用最少的代码完成最多的任务\n\n编程思维的形成\n学习高手写的代码"
  },
  {
    "objectID": "deepseek.html#r语言编程特点优势",
    "href": "deepseek.html#r语言编程特点优势",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.2 R语言编程特点–优势",
    "text": "4.2 R语言编程特点–优势\n\n免费\n可重复性\n扩展包\n\n按任务浏览R包：https://cran.r-project.org/web/views/\nR包下载排行榜: https://www.r-pkg.org/\n\n学术前沿"
  },
  {
    "objectID": "deepseek.html#r语言编程特点挑战",
    "href": "deepseek.html#r语言编程特点挑战",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.2 R语言编程特点–挑战",
    "text": "4.2 R语言编程特点–挑战\n\n入门难\n代码容易忘\n\n注释/R自带的提示性键入\n\n包太多/难以选择\n\n问DeepSeek：R中能做XXX的有哪些包？比较这些包？哪个更好用？\n🎯 专为 R 用户定制的搜索引擎 https://rseek.org\n\n📚 快速找到函数用法、R 包文档、代码示例\n✅ 搜索结果只与 R 有关，不混杂其他语言\n\n\n报错\n\nAI可以帮你分析报错信息"
  },
  {
    "objectID": "deepseek.html#deepseek辅助r语言统计分析",
    "href": "deepseek.html#deepseek辅助r语言统计分析",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.3 DeepSeek辅助R语言统计分析",
    "text": "4.3 DeepSeek辅助R语言统计分析\n4.3.1 先看看R能做什么？\n4.3.2 绘图\n4.3.3 检验\n4.3.4 建模\n4.3.5 表格化输出\n4.3.6 如何让DeepSeek分析自己的数据？"
  },
  {
    "objectID": "deepseek.html#先看看r能做什么",
    "href": "deepseek.html#先看看r能做什么",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.3.1 先看看R能做什么？",
    "text": "4.3.1 先看看R能做什么？\n\n🧭 提示语：利用iris数据，可以开展哪些统计分析，写出R代码。"
  },
  {
    "objectID": "deepseek.html#绘图",
    "href": "deepseek.html#绘图",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.3.2 绘图",
    "text": "4.3.2 绘图\n\n🧭 绘图提示语\n\n\n用R绘制iris的箱线图\n按species定性变量分组，绘制petal.length的箱线图。\n按species分组，绘制箱线图，用ggplot2绘制。\n让上述多个个图形显示在同一窗口。\n绘制具有学术期刊风格的分组箱线图。\n用ggpubr绘制分组箱线图。"
  },
  {
    "objectID": "deepseek.html#检验",
    "href": "deepseek.html#检验",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.3.3 检验",
    "text": "4.3.3 检验\n检验：目的/数据容量/数据类型和分布/原假设和备择假设/局限/结论\n\n🧭 提示语\n\n\n按species分组，检验不同组别的petal.length的均值是否相等？。\n该数据满足ANOVA检验的适用条件吗？\n每个组别内的petal.length观测值是否近似正态分布？\n如何进行方差齐性检验是什么？\nbartlett.test()函数的结果如何看？\n若不同组别之间的petal.length观测值方差不等，还能用ANOVA检验吗？\nWelch’s ANOVA的命令是什么？"
  },
  {
    "objectID": "deepseek.html#建模",
    "href": "deepseek.html#建模",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.3.4 建模",
    "text": "4.3.4 建模\n模型：目的/数据容量/数据类型和分布/估计结果的解释/可视化工具/评估\n\n🧭 提示语\n\n\n描述判别函数适合的研究场景？\n利用iris数据，开展判别分析，写出R代码，并添加注释。\n判别分析中需要做哪些检验？\n判别分析中有哪些可视化工具？\n如何评估判别分析模型？\n有哪些前沿方法可以替代判别分析？R中有哪些包可以实现这类前沿方法？"
  },
  {
    "objectID": "deepseek.html#表格化输出",
    "href": "deepseek.html#表格化输出",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.3.5 表格化输出",
    "text": "4.3.5 表格化输出\n\n🧭 提示语\n\n\n利用iris数据，如何输出学术论文中的表1（描述性统计表）？\n利用mpg数据，如何输出学术论文中的回归估计结果的表格？\n利用survival包中的数据lung，输出学术论文中的基线特征表？\n利用survival包中的数据lung，用表格报告Cox比例风险模型的估计结果？\n用别的更简便的方法吗？用专门的包实现表格化输出吗？"
  },
  {
    "objectID": "deepseek.html#如何让deepseek分析自己的数据",
    "href": "deepseek.html#如何让deepseek分析自己的数据",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.3.6 如何让DeepSeek分析自己的数据？",
    "text": "4.3.6 如何让DeepSeek分析自己的数据？\n\n生成模拟数据\n\n\n🧭 提示语: 我有实验组和对照组各10人的服药后7天，14天和21天的血压数据，可以开展什么统计分析，来判断药物是否有效？\n\n\n🧭 提示语: 请在R中生成上述模拟数据，及实现Repeated Measures ANOVA的代码？\n\n\n数据脱敏\n\n数据扰动: 给定量变量增加一个5%的随机扰动\n\n=C2 * (1 + (RAND() - 0.5) * 0.1) (Excel公式)\n\n随机抽样 30% ~ 70%： =rand() 然后排序 (Excel)\n点击下载数据脱敏练习文件: stroke.xlsx"
  },
  {
    "objectID": "deepseek.html#deepseek辅助r语言学习",
    "href": "deepseek.html#deepseek辅助r语言学习",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.4 DeepSeek辅助R语言学习",
    "text": "4.4 DeepSeek辅助R语言学习\n4.4.1 理解消化代码\n4.4.2 代码细节的追问\n4.4.3 解决报错\n4.4.4 简化/美化代码\n4.4.5 整理代码/重复利用"
  },
  {
    "objectID": "deepseek.html#理解消化代码",
    "href": "deepseek.html#理解消化代码",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.4.1 理解消化代码",
    "text": "4.4.1 理解消化代码\n\n逐行阅读代码并理解每个函数\n逐步运行代码, 理解输出结果\n理解复杂符号，如管道符, [[]], 占位符.等\n测试不同的参数"
  },
  {
    "objectID": "deepseek.html#代码细节的追问",
    "href": "deepseek.html#代码细节的追问",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.4.2 代码细节的追问",
    "text": "4.4.2 代码细节的追问\n\n让DeepSeek辅助理解函数帮助\n赋值符&lt;- 和 等于= 的区别？\n%&gt;% 和 ｜&gt; 的区别？\n\nR语言两种形式的管道符 %&gt;% 和 |&gt;：二者的区别和该用哪种？"
  },
  {
    "objectID": "deepseek.html#解决报错",
    "href": "deepseek.html#解决报错",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.4.3 解决报错",
    "text": "4.4.3 解决报错\n\n典型报错错：“未找到函数”、“对象未定义”、“无法读取文件”等\n\n查看环境：确保对象存在\n加载相关包\n\n函数输入的参数的类型错误\n复制Console中的代码及报错, 发送给DeepSeek"
  },
  {
    "objectID": "deepseek.html#简化美化代码",
    "href": "deepseek.html#简化美化代码",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "4.4.4 简化/美化代码",
    "text": "4.4.4 简化/美化代码\n\n使用适当的命名\n\n可以包含字母, 数字,下划线_和小圆点., 但不能以数字开头，不能有中划线-，特殊符号$,@等\n\n避免使用不必要的中间变量\n\n管道符\n\n避免重复代码\n\n优化数据结构/循环语句\n\n格式化和缩进\n把代码发送给AI，简化我的代码？"
  },
  {
    "objectID": "deepseek.html#总结",
    "href": "deepseek.html#总结",
    "title": "DeepSeek辅助统计分析和R运用",
    "section": "总结",
    "text": "总结\n\nAI助力，让R语言学习变得简单、高效、充满乐趣！\n\n\nAI助力, 形成编程思维, 独立实践才是用好R的关键。\n\n\n高质量的提问，源自对R的深度使用。"
  }
]